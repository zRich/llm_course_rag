# 实验2：检索优化与融合实验（Lesson 7-10）

## 实验概述

本实验聚焦“检索效果与结果质量”维度，严格覆盖课程第 7-10 课：关键词检索优化、混合检索融合策略、元数据过滤与重排序（Rerank）接入。你将基于最小可运行系统完成从候选生成到融合、过滤与重排的完整链路，并用一致的指标评估改进。

> 边界说明：为避免与实验3（Lesson 11-14，系统性能与切块策略）重复，本实验不包含切块重构、并发与缓存优化；这些内容将在实验3完成。

## 涉及课程
- Lesson 7：关键词检索优化（BM25/TF-IDF、分词与同义词处理）
- Lesson 8：混合检索融合策略（RRF、线性加权与分数归一化）
- Lesson 9：元数据过滤（字段匹配、范围与日期、空值约定）
- Lesson 10：重排序（Cross-Encoder 接入、稳定排序与多信号融合）

## 实验目标
- 构建“候选生成 → 融合 → 过滤 → 重排”的端到端检索管线
- 系统性调优关键词与混合检索，提升 Top-K 相关性
- 设计并实现至少 2 种融合策略（RRF、线性加权）
- 落地统一的元数据过滤 DSL，覆盖常见算子与错误处理
- 接入 Cross-Encoder 重排并评估 nDCG / MRR / Recall@K

## 技术栈与依赖
- 语言：Python 3.10+（建议 3.12）
- 关键词检索：`Whoosh` / `Elasticsearch` / `Postgres FTS`（任选其一）
- 向量检索（可选）：`FAISS` / `Qdrant`
- 嵌入模型：`sentence-transformers`（如 `all-MiniLM-L6-v2`）
- 重排模型：`cross-encoder/ms-marco-MiniLM-L-6-v2` 或同类
- Web 层（可选）：`FastAPI` / `Flask`

## 前置条件
- 完成实验1的环境与基础数据准备
- 如需运行向量检索，准备最小向量索引（1k-10k 文档）
- 本实验不包含切块重构、缓存与并发优化（统一在实验3）

## 实验步骤（建议分阶段实施）

### 阶段 1：关键词检索优化（Lesson 7）
- 构建基础索引与查询接口，选择中文分词器（`jieba`/`hanlp` 等）
- 调整 BM25 参数 `k1`、`b` 与停用词，观察 `Recall@K` 与 `nDCG@K` 的变化
- 引入同义词词典与简繁体处理，评估对召回与排序的影响

### 阶段 2：混合检索与融合（Lesson 8）
- 关键词候选与向量候选合并，设计统一候选结构
- 实现 RRF（Reciprocal Rank Fusion）与线性加权融合
- 设计分数归一化与去重策略，确保稳定排序与一致性

### 阶段 3：元数据过滤（Lesson 9）
- 设计统一过滤 DSL：`==`、`in`、`range`、`date`、`exists` 等
- 明确空列表、空字符串与缺失字段的约定与错误处理
- 在融合前/后分别施加过滤，比较指标与延迟差异

### 阶段 4：重排序接入（Lesson 10）
- 选用 Cross-Encoder 模型，对融合后的 Top-M 进行重排
- 比较“仅融合”与“融合+重排”的指标差异（`nDCG@10` / `MRR@10`）
- 探索分数融合（重排分数与融合分数的线性或学习加权）

## 实验任务（必须完成）
- 任务 A：实现关键词检索与 BM25 调优，提交参数与效果报告
- 任务 B：实现 RRF 与线性加权融合，提交对比评估与可复现实验脚本
- 任务 C：落地统一元数据过滤 DSL，覆盖至少 5 种算子
- 任务 D：接入 Cross-Encoder 重排，提交前后指标对比与分析
- 任务 E：以 2 套不同查询集（术语型/语义型）验证鲁棒性

## 评估指标与度量
- 相关性：`nDCG@K`、`MRR@K`、`Recall@K`（至少报告 @10）
- 质量一致性：融合后稳定排序与重复项处理
- 过滤正确性：算子覆盖、边界约定、异常处理的一致性
- 延迟：候选生成、融合与重排的端到端延迟（不做并发优化）

## 数据与基准
- 最小数据集：1k-10k 文档（领域可自选：FAQ、技术文档、条例）
- 标注：自制或半自动标注 100-300 条查询-相关文档对
- 模型基线：`all-MiniLM-L6-v2`（嵌入），`cross-encoder/ms-marco-MiniLM-L-6-v2`（重排）

## 提交与验收
- 代码：包含可重复的实验脚本与配置（Seed、参数、数据路径）
- 报告：结构化呈现实验设置、结果、分析与结论（建议 Markdown）
- 指标：统一报告 `nDCG@10`、`MRR@10`、`Recall@10` 与延迟
- 复现：他人可在 README 指令下复现主要结论（±5% 误差）

## 常见问题与提示
- 分数尺度不一致会导致融合偏差，需进行归一化
- 过滤的空值与缺失字段处理要明确并一致
- 重排只对 Top-M 进行；M 过大将显著增加延迟
- 关键词与向量候选的去重要以文档 ID 为准

## 参考与对齐
- 课程目录：
  - `courses/11_rag/lesson07_关键词检索优化/`
  - `courses/11_rag/lesson08_混合检索融合策略/`
  - `courses/11_rag/lesson09_元数据过滤/`
  - `courses/11_rag/lesson10_重排序Rerank接入/`
- 示例参考：
  - `lesson08_混合检索融合策略/examples/fusion_demo.py`
  - `lesson09_元数据过滤/examples/metadata_filter_demo.py`
  - `lesson10_重排序Rerank接入/examples/rerank_demo.py`

## 时间建议
- 总时长：6-8 小时（可分两次完成）
- 里程碑：阶段 2 完成后先做一次小结与指标对比

## 后续实验
- 实验3将覆盖 Lesson 11-14（切块、并发、缓存与可观测性），与本实验解耦；请以本实验产出的候选集与评估脚本为输入继续优化系统性能。