# 实验 3 详细答案（RAG 系统）

本文件为实验 3 的参考答案与验证标准，覆盖 Embedding、检索、重排、问答与缓存等核心功能，并给出接口示例、代码定位与指标期望。请结合同目录的《实验3_操作手册.md》和《RAG系统技术设计文档.md》一起使用。

## 1. 实验目标与达成标准
- 构建端到端 RAG 流程：文档处理 → 嵌入 → 向量存储 → 检索 → 重排 → 生成回答。
- 提供可溯源回答：返回引用来源（chunk/document）与必要的评分信息。
- 引入分层缓存：Embedding、Vector Search、Rerank、QA 层具备可配置 TTL 与失效策略，热门查询延迟显著下降。
- 验收指标（建议范围，用于自测）：
  - 单次向量检索延迟：≤ 100–300ms（本地模型与数据量相关）
  - 混合检索融合后 NDCG@10：较仅向量检索提升 5–15%
  - Rerank Top-10 质量提升：MAP 或点击率提升 3–10%
  - 缓存命中率（热门查询场景）：≥ 60–80%，缓存命中后查询延迟下降 ≥ 40–70%

## 2. 环境与服务
- 启动方式：`uv run rag-server`（参见学生版 README 与操作手册）
- 服务文档：`/docs`、`/redoc`；API 前缀参考学生版：`/qa`、`/vectors`、`/retrieval`
- 向量维度（默认本地模型）：`384`；API 模型（豆包）根据 `.env` 或配置文件动态选择。

## 3. 功能答案与接口示例

### 3.1 向量化（Embedding & Vectorize）
- 路由：`POST /vectors/vectorize`
- 请求示例：
```json
{
  "document_ids": ["1", "2"],
  "force_revectorize": false
}
```
- 响应示例（关键字段）：
```json
{
  "success": true,
  "message": "向量化完成，处理了 2 个文档，40 个分块",
  "processed_documents": 2,
  "processed_chunks": 40,
  "processing_time": 3.42,
  "failed_documents": []
}
```
- 参考实现位置：`labs/student/lab03/src/services/embedding_service.py`
  - 批量接口与缓存接入点：`get_embeddings_batch` / `_process_batch`（含 `TODO(lab03-lesson14)`）
  - 维度与模型：通过配置项选择本地或 API 模型；本地维度一般为 `384`。

### 3.2 纯向量检索（Vector Search）
- 路由：`POST /vectors/search`（亦支持 `GET /vectors/search`）
- 请求示例：
```json
{
  "query": "RAG 系统的核心组件有哪些？",
  "document_ids": [1, 2],
  "limit": 10,
  "score_threshold": 0.5
}
```
- 响应示例（关键字段）：
```json
{
  "success": true,
  "message": "搜索完成，找到 10 个相关结果",
  "query": "RAG 系统的核心组件有哪些？",
  "results": [
    {
      "chunk_id": "c_001",
      "document_id": "1",
      "document_filename": "rag_design.pdf",
      "document_title": "RAG 系统设计",
      "chunk_index": 12,
      "content": "RAG 系统包含检索、增强、生成三大核心模块……",
      "score": 0.82,
      "start_position": 2340,
      "end_position": 2580,
      "metadata": {"section": "overview"}
    }
  ],
  "total_found": 10,
  "processing_time": 0.12
}
```
- 参考实现位置：`labs/student/lab03/src/services/vector_service.py`
  - 检索入口：`search_similar_chunks`（含 `TODO(lab03-lesson14)` 缓存接入，键设计与 TTL 建议）
  - 文本分块语义质量影响检索表现，参见 `text_splitter.py`。

### 3.3 混合检索与融合（Hybrid Retrieval + Fusion）
- 路由：`POST /retrieval/search`
- 请求模型：`HybridSearchRequest`（见 `schemas_hybrid.py`）
- 请求示例：
```json
{
  "query": "如何评估 RAG 检索质量？",
  "top_k": 10,
  "score_threshold": 0.2,
  "document_ids": [1, 2],
  "fusion": {"strategy": "rrf", "k": 60},
  "filters": [{"op": "eq", "field": "section", "value": "evaluation"}],
  "rerank_top_m": 10
}
```
- 响应示例（关键字段）：与 `SearchResponse` 兼容（字段同上 `results` 列表）。
- 参考实现位置：`labs/student/lab03/src/api/routes/retrieval.py`
  - 向量检索（VectorService）与关键词检索（KeywordSearchService）融合：`rrf_fuse` 或 `linear_fuse`
  - 过滤 DSL：`apply_filters`
  - 重排：`rerank_service.rerank`（失败降级保持原排序）

### 3.4 重排（Rerank）
- 目标：提升候选排序质量，优先返回更相关、覆盖更丰富的上下文。
- 参考位置：`labs/student/lab03/src/services/rerank_service.py`
  - 缓存接入点与键建议：在 `rerank(query, candidates, top_m)` 前后加入读取与写入（`TODO(lab03-lesson14)`）。
  - 验收：在检索评估集上，Top-10 的 NDCG 或 MAP 提升显著（建议 ≥3–10%）。

### 3.5 问答（QA with Citations）
- 路由：`POST /qa/ask`（亦支持 `GET /qa/ask`）、`POST /qa/batch`、`POST /qa/conversation`
- 请求示例：
```json
{
  "question": "企业级 RAG 部署需要考虑哪些因素？",
  "document_ids": [1, 2],
  "top_k": 10,
  "score_threshold": 0.7,
  "context_size": 2
}
```
- 响应示例（关键字段）：
```json
{
  "success": true,
  "message": "问答完成",
  "question": "企业级 RAG 部署需要考虑哪些因素？",
  "answer": "需要考虑数据安全、性能、成本、可扩展性与运维……",
  "sources": [
    {
      "document_id": "1",
      "document_filename": "rag_deployment.pdf",
      "document_title": "企业部署指南",
      "chunk_id": "c_045",
      "chunk_index": 45,
      "score": 0.86,
      "content_preview": "企业部署需要考虑性能、安全、成本控制、可扩展性……"
    }
  ],
  "context_used": 2,
  "processing_time": 0.58,
  "model_used": "doubao-seed-1-6-250615",
  "generation_info": {"temperature": 0.7}
}
```
- 参考实现位置：`labs/student/lab03/src/services/qa_service.py`
  - 引用与可溯源输出：`answer_question`、`_build_system_prompt`、`_generate_answer`（含 `TODO(lab03-lesson13)`）
  - QA 结果缓存：在最终返回前接入缓存（`TODO(lab03-lesson14)`），键包含 `layer+provider/model+normalized_question+doc_scope+params_hash`。

## 4. 文本分块策略（Lesson 11 答案要点）
- 入口：`labs/student/lab03/src/services/text_splitter.py`
- 建议实现：
  - 语义分块（`SplitStrategy.SEMANTIC`，`split_by_semantic`）：
    - 先按句子/段落初分块 → 计算相邻块 embedding 相似度 → 相似度 > 阈值时合并；
    - 控制最小/最大分块大小（字符与 token 双约束），优先边界（句号、标题等）。
  - Token 估算（`estimate_tokens`）：近似方法（按字符比率或轻量分词），用于约束。
  - 参数化阈值与最小/最大分块尺寸，暴露到配置或函数参数以便调参。
- 验收：
  - 语义相近句子能聚合到同一块，平均块大小与 token 数在设定范围内；
  - 长文示例中分块质量对检索召回和排序质量有正向影响。

## 5. 并行与容错（Lesson 12 答案要点）
- 入口：`labs/student/lab03/src/services/document_processor.py`
- 建议实现：
  - 并发：为长文分块处理启用线程池/协程，边界不跨线程（分块内同步）。
  - 重试：解析失败按指数退避重试（如 3 次），记录失败文档列表。
  - 降级：出现异常时回退到简化清洗与固定分块策略，保证整体流程不中断。
- 验收：批量（N>50）处理时间显著优于串行；失败不影响整体收敛；统计输出（处理数、失败数、耗时）完整。

## 6. 引用与结构化输出（Lesson 13 答案要点）
- 入口：`labs/student/lab03/src/services/qa_service.py`
- 建议实现：
  - 在生成回答中嵌入引用标号 `[1], [2]...`，并与 `sources` 字段的 `chunk_id/document_id` 一一对应；
  - 扩展系统提示词，约束模型输出 JSON 或带可解析标记，包含 `citations` 与 `confidence`；
  - `confidence` 可基于检索分数分布、重排分数、生成一致性等综合计算。
- 验收：引用标号与 `sources` 一致，且能追溯到具体 chunk；不同问题的 `confidence` 能给出可解释差异（如上下文覆盖度、分数稀疏度）。

## 7. 分层缓存（Lesson 14 答案要点）
- 入口：
  - Embedding：`embedding_service.get_embedding(s)` / `get_embeddings_batch`
  - Vector：`vector_service.search_similar_chunks`
  - Rerank：`rerank_service.rerank`
  - QA：`qa_service.answer_question` 最终返回前
- 键设计（建议）：
  - 统一前缀：`rag:<layer>:<provider|model>:`
  - Embedding：`rag:emb:<model>:<lang>:<norm_text_hash>`
  - Vector：`rag:vec:<model>:<doc_scope_hash>:<norm_query_hash>:<top_k>:<thresh>`
  - Rerank：`rag:rrk:<model>:<cand_ids_hash>:<norm_query_hash>`
  - QA：`rag:qa:<model>:<norm_question_hash>:<doc_scope_hash>:<params_hash>`
- TTL 建议：
  - Embedding：7–30 天；Vector/Rerank：15–120 分钟；QA：30–120 分钟；加 5–15% 抖动避免雪崩。
- 失效策略：
  - 文档更新/索引重建后，按 `doc_scope_hash` 定位并失效相关键；批量失效可维护倒排映射或统一命名空间。
- 验收：热门查询命中率显著提升；缓存命中后端到端延迟明显降低；命中率与延迟在日志或统计接口可观测。

## 8. 代码定位与参考
- 路由：
  - QA：`labs/student/lab03/src/api/routes/qa.py`（`/qa/ask`, `/qa/batch`, `/qa/conversation`, `/qa/evaluate`, `/qa/stats`）
  - 向量：`labs/student/lab03/src/api/routes/vectors.py`（`/vectors/vectorize`, `/vectors/search`, `/vectors/reindex`, `/vectors/stats`）
  - 混合检索：`labs/student/lab03/src/api/routes/retrieval.py`（`/retrieval/search`）
- 服务：
  - 文本切分：`src/services/text_splitter.py`
  - 文档处理：`src/services/document_processor.py`
  - 向量：`src/services/vector_service.py`
  - 重排：`src/services/rerank_service.py`
  - 问答：`src/services/qa_service.py`
  - 嵌入：`src/services/embedding_service.py`

## 9. 验收清单（建议）
- 分块质量：统计平均块长度、token 数分布，人工抽样审查若干段。
- 检索效果：构造 20–50 条查询，比较向量检索 vs 混合检索的 NDCG@10。
- 重排收益：在融合后候选上评估重排对 Top-10 MAP 的提升。
- QA 可溯源：随机抽 10 条问答，核对 `sources` 与答案中的引用标号一致。
- 缓存收益：
  - 预热前后延迟与命中率对比；
  - 长尾查询不受缓存污染；
  - 失效后能及时更新结果。

## 10. 常见问题与偏差纠正
- 分块过细或过粗：调节语义合并阈值与最小/最大块尺寸；确保边界优先。
- 检索阈值不当：过高丢召回，过低噪声多；建议 0.2–0.7 结合具体模型调参。
- 重排模型首次加载慢：加缓存与懒加载，首次失败降级不阻塞主流程。
- 缓存击穿与雪崩：设置多级 TTL 与抖动，热门查询预热，必要时使用互斥锁或单飞保护。
- 引用错位：在生成前构建明确的 `citations` 映射，并在提示词中要求严格对应。

## 11. 附：API cURL 示例
- QA（POST）：
```bash
curl -X POST 'http://localhost:8000/qa/ask' \
  -H 'Content-Type: application/json' \
  -d '{
    "question": "RAG 系统的核心组件有哪些？",
    "top_k": 10,
    "score_threshold": 0.7,
    "context_size": 2
  }'
```
- 向量搜索（POST）：
```bash
curl -X POST 'http://localhost:8000/vectors/search' \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "如何评估 RAG 检索质量？",
    "limit": 10,
    "score_threshold": 0.5
  }'
```
- 混合检索（POST）：
```bash
curl -X POST 'http://localhost:8000/retrieval/search' \
  -H 'Content-Type: application/json' \
  -d '{
    "query": "如何评估 RAG 检索质量？",
    "top_k": 10,
    "fusion": {"strategy": "rrf", "k": 60},
    "rerank_top_m": 10
  }'
```

---

说明：上述响应内容为参考示例，实际数值（如分数、耗时、命中率）会随模型、数据与环境而变化。请按本答案的结构与字段核对功能的正确性与输出的一致性。