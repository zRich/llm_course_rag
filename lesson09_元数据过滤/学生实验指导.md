# 第九节课：元数据过滤 - 学生实验指导

## 实验目标
通过本实验，学生将掌握：
1. 扩展PostgreSQL数据库，添加元数据字段和索引
2. 实现动态元数据过滤服务
3. 构建复合查询条件
4. 监控和优化查询性能

## 实验环境准备
- 基于lesson08的代码基础
- PostgreSQL数据库
- Python环境（已安装必要依赖）

## 实验任务

### 任务1：数据库扩展（10分钟）

#### 1.1 扩展documents表结构
创建数据库迁移脚本 `migrations/add_metadata_fields.sql`：

```sql
-- 添加元数据字段
ALTER TABLE documents ADD COLUMN IF NOT EXISTS category VARCHAR(50);
ALTER TABLE documents ADD COLUMN IF NOT EXISTS author VARCHAR(100);
ALTER TABLE documents ADD COLUMN IF NOT EXISTS created_at TIMESTAMP DEFAULT NOW();
ALTER TABLE documents ADD COLUMN IF NOT EXISTS updated_at TIMESTAMP DEFAULT NOW();
ALTER TABLE documents ADD COLUMN IF NOT EXISTS tags TEXT[];
ALTER TABLE documents ADD COLUMN IF NOT EXISTS department VARCHAR(50);
ALTER TABLE documents ADD COLUMN IF NOT EXISTS access_level VARCHAR(20) DEFAULT 'public';

-- 创建索引
CREATE INDEX IF NOT EXISTS idx_documents_category ON documents(category);
CREATE INDEX IF NOT EXISTS idx_documents_author ON documents(author);
CREATE INDEX IF NOT EXISTS idx_documents_created_at ON documents(created_at);
CREATE INDEX IF NOT EXISTS idx_documents_updated_at ON documents(updated_at);
CREATE INDEX IF NOT EXISTS idx_documents_tags ON documents USING GIN(tags);
CREATE INDEX IF NOT EXISTS idx_documents_department ON documents(department);
CREATE INDEX IF NOT EXISTS idx_documents_access_level ON documents(access_level);

-- 创建复合索引（常用查询组合）
CREATE INDEX IF NOT EXISTS idx_documents_category_author ON documents(category, author);
CREATE INDEX IF NOT EXISTS idx_documents_department_created_at ON documents(department, created_at);
```

#### 1.2 插入测试数据
创建 `scripts/insert_metadata_test_data.py`：

```python
#!/usr/bin/env python3
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.database import get_db_connection
from datetime import datetime, timedelta
import random

def insert_test_data():
    """插入带有元数据的测试文档"""
    conn = get_db_connection()
    cursor = conn.cursor()
    
    # 测试数据
    categories = ['AI', '技术', '商业', '研究', '产品']
    authors = ['张三', '李四', '王五', '赵六', '钱七']
    departments = ['研发部', '产品部', '市场部', '技术部', '运营部']
    access_levels = ['public', 'internal', 'confidential']
    
    test_documents = [
        {
            'content': '人工智能技术在金融领域的应用越来越广泛，包括风险控制、智能投顾、反欺诈等方面。',
            'category': 'AI',
            'author': '张三',
            'department': '研发部',
            'tags': ['人工智能', '金融', '风控'],
            'access_level': 'public'
        },
        {
            'content': '机器学习算法在推荐系统中的优化策略，包括协同过滤、深度学习等方法。',
            'category': '技术',
            'author': '李四',
            'department': '技术部',
            'tags': ['机器学习', '推荐系统', '算法'],
            'access_level': 'internal'
        },
        {
            'content': '企业数字化转型的关键要素和实施路径，包括技术架构、组织变革等。',
            'category': '商业',
            'author': '王五',
            'department': '产品部',
            'tags': ['数字化转型', '企业管理', '架构'],
            'access_level': 'confidential'
        },
        {
            'content': '自然语言处理技术在客服系统中的应用，提高客户服务效率和质量。',
            'category': 'AI',
            'author': '赵六',
            'department': '研发部',
            'tags': ['NLP', '客服', '自动化'],
            'access_level': 'public'
        },
        {
            'content': '云计算平台的安全架构设计，包括身份认证、数据加密、访问控制等。',
            'category': '技术',
            'author': '钱七',
            'department': '技术部',
            'tags': ['云计算', '安全', '架构'],
            'access_level': 'internal'
        }
    ]
    
    for i, doc in enumerate(test_documents):
        # 随机生成创建时间（最近30天内）
        created_at = datetime.now() - timedelta(days=random.randint(1, 30))
        updated_at = created_at + timedelta(hours=random.randint(1, 24))
        
        cursor.execute("""
            INSERT INTO documents (content, category, author, department, tags, access_level, created_at, updated_at)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            doc['content'],
            doc['category'],
            doc['author'],
            doc['department'],
            doc['tags'],
            doc['access_level'],
            created_at,
            updated_at
        ))
    
    conn.commit()
    cursor.close()
    conn.close()
    print(f"成功插入 {len(test_documents)} 条测试数据")

if __name__ == "__main__":
    insert_test_data()
```

### 任务2：实现元数据过滤服务（15分钟）

#### 2.1 创建元数据过滤服务
创建 `app/services/metadata_filter.py`：

```python
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import logging
from app.database import get_db_connection

logger = logging.getLogger(__name__)

class MetadataFilterService:
    """元数据过滤服务"""
    
    def __init__(self):
        self.supported_operators = {
            'eq': '=',           # 等于
            'ne': '!=',          # 不等于
            'gt': '>',           # 大于
            'gte': '>=',         # 大于等于
            'lt': '<',           # 小于
            'lte': '<=',         # 小于等于
            'in': 'IN',          # 包含于
            'not_in': 'NOT IN',  # 不包含于
            'contains': '@>',    # 数组包含
            'like': 'LIKE',      # 模糊匹配
            'ilike': 'ILIKE'     # 不区分大小写模糊匹配
        }
    
    def build_filter_conditions(self, filters: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """构建过滤条件
        
        Args:
            filters: 过滤条件字典
            格式: {
                'category': 'AI',
                'author': {'operator': 'in', 'value': ['张三', '李四']},
                'created_at': {'operator': 'gte', 'value': '2024-01-01'},
                'tags': {'operator': 'contains', 'value': ['人工智能']}
            }
        
        Returns:
            Tuple[str, Dict]: (WHERE子句, 参数字典)
        """
        if not filters:
            return "", {}
        
        conditions = []
        params = {}
        param_counter = 1
        
        for field, condition in filters.items():
            if isinstance(condition, dict):
                operator = condition.get('operator', 'eq')
                value = condition.get('value')
            else:
                operator = 'eq'
                value = condition
            
            if operator not in self.supported_operators:
                logger.warning(f"不支持的操作符: {operator}")
                continue
            
            param_name = f"param_{param_counter}"
            sql_operator = self.supported_operators[operator]
            
            if operator in ['in', 'not_in']:
                if isinstance(value, list) and value:
                    placeholders = ','.join([f"%({param_name}_{i})s" for i in range(len(value))])
                    conditions.append(f"{field} {sql_operator} ({placeholders})")
                    for i, v in enumerate(value):
                        params[f"{param_name}_{i}"] = v
            elif operator == 'contains':
                # 用于数组字段
                conditions.append(f"{field} {sql_operator} %({param_name})s")
                params[param_name] = value if isinstance(value, list) else [value]
            elif operator in ['like', 'ilike']:
                conditions.append(f"{field} {sql_operator} %({param_name})s")
                params[param_name] = f"%{value}%"
            else:
                conditions.append(f"{field} {sql_operator} %({param_name})s")
                params[param_name] = value
            
            param_counter += 1
        
        where_clause = " AND ".join(conditions) if conditions else ""
        return where_clause, params
    
    def filter_documents(self, 
                        base_query: str, 
                        base_params: Dict[str, Any],
                        filters: Dict[str, Any],
                        limit: int = 10) -> List[Dict[str, Any]]:
        """执行带元数据过滤的文档查询
        
        Args:
            base_query: 基础查询SQL
            base_params: 基础查询参数
            filters: 元数据过滤条件
            limit: 结果限制数量
        
        Returns:
            List[Dict]: 查询结果列表
        """
        start_time = datetime.now()
        
        try:
            # 构建过滤条件
            filter_clause, filter_params = self.build_filter_conditions(filters)
            
            # 合并查询和过滤条件
            if filter_clause:
                if "WHERE" in base_query.upper():
                    final_query = f"{base_query} AND {filter_clause}"
                else:
                    final_query = f"{base_query} WHERE {filter_clause}"
            else:
                final_query = base_query
            
            # 添加LIMIT
            final_query += f" LIMIT {limit}"
            
            # 合并参数
            final_params = {**base_params, **filter_params}
            
            # 执行查询
            conn = get_db_connection()
            cursor = conn.cursor()
            
            cursor.execute(final_query, final_params)
            columns = [desc[0] for desc in cursor.description]
            results = [dict(zip(columns, row)) for row in cursor.fetchall()]
            
            cursor.close()
            conn.close()
            
            # 记录查询性能
            execution_time = (datetime.now() - start_time).total_seconds()
            logger.info(f"元数据过滤查询执行时间: {execution_time:.3f}秒, 结果数量: {len(results)}")
            
            return results
            
        except Exception as e:
            logger.error(f"元数据过滤查询失败: {str(e)}")
            raise
    
    def get_metadata_stats(self) -> Dict[str, Any]:
        """获取元数据统计信息"""
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            
            stats = {}
            
            # 分类统计
            cursor.execute("SELECT category, COUNT(*) FROM documents WHERE category IS NOT NULL GROUP BY category")
            stats['categories'] = dict(cursor.fetchall())
            
            # 作者统计
            cursor.execute("SELECT author, COUNT(*) FROM documents WHERE author IS NOT NULL GROUP BY author")
            stats['authors'] = dict(cursor.fetchall())
            
            # 部门统计
            cursor.execute("SELECT department, COUNT(*) FROM documents WHERE department IS NOT NULL GROUP BY department")
            stats['departments'] = dict(cursor.fetchall())
            
            # 访问级别统计
            cursor.execute("SELECT access_level, COUNT(*) FROM documents WHERE access_level IS NOT NULL GROUP BY access_level")
            stats['access_levels'] = dict(cursor.fetchall())
            
            # 总文档数
            cursor.execute("SELECT COUNT(*) FROM documents")
            stats['total_documents'] = cursor.fetchone()[0]
            
            cursor.close()
            conn.close()
            
            return stats
            
        except Exception as e:
            logger.error(f"获取元数据统计失败: {str(e)}")
            return {}
```

#### 2.2 集成到RAG查询接口
修改 `app/api/rag.py`，添加元数据过滤支持：

```python
# 在现有的/rag/query接口中添加metadata_filters参数

@router.post("/query")
async def query_documents(
    query: str,
    strategy: str = "vector",  # vector, keyword, hybrid
    limit: int = 5,
    metadata_filters: Optional[Dict[str, Any]] = None  # 新增参数
):
    """查询文档（支持元数据过滤）"""
    try:
        from app.services.metadata_filter import MetadataFilterService
        
        metadata_service = MetadataFilterService()
        
        if strategy == "vector":
            from app.services.vector_search import VectorSearchService
            vector_service = VectorSearchService()
            
            # 基础向量查询
            base_query = """
                SELECT id, content, category, author, department, tags, created_at,
                       1 - (embedding <=> %s) as similarity
                FROM documents
                ORDER BY embedding <=> %s
            """
            base_params = {'embedding': vector_service.get_embedding(query), 'embedding2': vector_service.get_embedding(query)}
            
            # 应用元数据过滤
            results = metadata_service.filter_documents(
                base_query, base_params, metadata_filters or {}, limit
            )
            
        elif strategy == "keyword":
            # 基础关键词查询
            base_query = """
                SELECT id, content, category, author, department, tags, created_at,
                       ts_rank(search_vector, plainto_tsquery('chinese', %s)) as rank
                FROM documents
                WHERE search_vector @@ plainto_tsquery('chinese', %s)
                ORDER BY rank DESC
            """
            base_params = {'query': query, 'query2': query}
            
            # 应用元数据过滤
            results = metadata_service.filter_documents(
                base_query, base_params, metadata_filters or {}, limit
            )
            
        elif strategy == "hybrid":
            # 混合检索（结合元数据过滤）
            from app.services.hybrid_search import HybridSearchFusion
            hybrid_service = HybridSearchFusion()
            
            # 在混合检索中应用元数据过滤
            results = hybrid_service.search_with_metadata_filter(
                query, metadata_filters or {}, limit
            )
        
        return {
            "query": query,
            "strategy": strategy,
            "metadata_filters": metadata_filters,
            "results": results,
            "count": len(results)
        }
        
    except Exception as e:
        logger.error(f"查询失败: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
```

### 任务3：创建测试脚本（10分钟）

创建 `test_metadata_filter.py`：

```python
#!/usr/bin/env python3
"""
第九节课：元数据过滤测试脚本

测试功能：
1. 数据库扩展和索引创建
2. 元数据过滤查询
3. 复合条件查询
4. 查询性能测试
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.metadata_filter import MetadataFilterService
from app.database import get_db_connection
import time
import json
from datetime import datetime, timedelta

def test_database_extension():
    """测试数据库扩展"""
    print("\n=== 测试1: 数据库扩展 ===")
    
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # 检查新增字段是否存在
        cursor.execute("""
            SELECT column_name 
            FROM information_schema.columns 
            WHERE table_name = 'documents' 
            AND column_name IN ('category', 'author', 'tags', 'department', 'access_level')
        """)
        
        columns = [row[0] for row in cursor.fetchall()]
        print(f"✓ 新增字段: {columns}")
        
        # 检查索引是否存在
        cursor.execute("""
            SELECT indexname 
            FROM pg_indexes 
            WHERE tablename = 'documents' 
            AND indexname LIKE 'idx_documents_%'
        """)
        
        indexes = [row[0] for row in cursor.fetchall()]
        print(f"✓ 创建索引: {indexes}")
        
        cursor.close()
        conn.close()
        
        print("✓ 数据库扩展测试通过")
        
    except Exception as e:
        print(f"✗ 数据库扩展测试失败: {e}")

def test_basic_filtering():
    """测试基础过滤功能"""
    print("\n=== 测试2: 基础过滤功能 ===")
    
    try:
        service = MetadataFilterService()
        
        # 测试1: 按分类过滤
        print("\n测试按分类过滤:")
        base_query = "SELECT id, content, category, author FROM documents"
        filters = {'category': 'AI'}
        
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ AI分类文档数量: {len(results)}")
        for result in results[:2]:
            print(f"  - {result['category']}: {result['content'][:50]}...")
        
        # 测试2: 按作者过滤
        print("\n测试按作者过滤:")
        filters = {'author': '张三'}
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ 张三的文档数量: {len(results)}")
        
        # 测试3: 按标签过滤（数组包含）
        print("\n测试按标签过滤:")
        filters = {'tags': {'operator': 'contains', 'value': ['人工智能']}}
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ 包含'人工智能'标签的文档数量: {len(results)}")
        
        print("✓ 基础过滤功能测试通过")
        
    except Exception as e:
        print(f"✗ 基础过滤功能测试失败: {e}")

def test_complex_filtering():
    """测试复合过滤条件"""
    print("\n=== 测试3: 复合过滤条件 ===")
    
    try:
        service = MetadataFilterService()
        base_query = "SELECT id, content, category, author, department, created_at FROM documents"
        
        # 测试1: 多字段AND条件
        print("\n测试多字段AND条件:")
        filters = {
            'category': 'AI',
            'department': '研发部'
        }
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ AI分类且研发部的文档数量: {len(results)}")
        
        # 测试2: IN操作符
        print("\n测试IN操作符:")
        filters = {
            'author': {'operator': 'in', 'value': ['张三', '李四']}
        }
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ 张三或李四的文档数量: {len(results)}")
        
        # 测试3: 时间范围查询
        print("\n测试时间范围查询:")
        week_ago = datetime.now() - timedelta(days=7)
        filters = {
            'created_at': {'operator': 'gte', 'value': week_ago.strftime('%Y-%m-%d')}
        }
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ 最近7天创建的文档数量: {len(results)}")
        
        # 测试4: 模糊匹配
        print("\n测试模糊匹配:")
        filters = {
            'content': {'operator': 'ilike', 'value': '人工智能'}
        }
        results = service.filter_documents(base_query, {}, filters, 10)
        print(f"✓ 内容包含'人工智能'的文档数量: {len(results)}")
        
        print("✓ 复合过滤条件测试通过")
        
    except Exception as e:
        print(f"✗ 复合过滤条件测试失败: {e}")

def test_performance():
    """测试查询性能"""
    print("\n=== 测试4: 查询性能测试 ===")
    
    try:
        service = MetadataFilterService()
        
        # 测试无索引查询性能（模拟）
        print("\n测试有索引的查询性能:")
        base_query = "SELECT id, content, category, author FROM documents"
        filters = {'category': 'AI'}
        
        start_time = time.time()
        results = service.filter_documents(base_query, {}, filters, 100)
        end_time = time.time()
        
        print(f"✓ 查询时间: {(end_time - start_time)*1000:.2f}ms")
        print(f"✓ 结果数量: {len(results)}")
        
        # 测试复杂查询性能
        print("\n测试复杂查询性能:")
        filters = {
            'category': {'operator': 'in', 'value': ['AI', '技术']},
            'department': '研发部',
            'tags': {'operator': 'contains', 'value': ['人工智能']}
        }
        
        start_time = time.time()
        results = service.filter_documents(base_query, {}, filters, 100)
        end_time = time.time()
        
        print(f"✓ 复杂查询时间: {(end_time - start_time)*1000:.2f}ms")
        print(f"✓ 结果数量: {len(results)}")
        
        print("✓ 查询性能测试通过")
        
    except Exception as e:
        print(f"✗ 查询性能测试失败: {e}")

def test_metadata_stats():
    """测试元数据统计"""
    print("\n=== 测试5: 元数据统计 ===")
    
    try:
        service = MetadataFilterService()
        stats = service.get_metadata_stats()
        
        print("✓ 元数据统计信息:")
        print(f"  总文档数: {stats.get('total_documents', 0)}")
        print(f"  分类分布: {stats.get('categories', {})}")
        print(f"  作者分布: {stats.get('authors', {})}")
        print(f"  部门分布: {stats.get('departments', {})}")
        print(f"  访问级别分布: {stats.get('access_levels', {})}")
        
        print("✓ 元数据统计测试通过")
        
    except Exception as e:
        print(f"✗ 元数据统计测试失败: {e}")

def test_api_integration():
    """测试API集成"""
    print("\n=== 测试6: API集成测试 ===")
    
    try:
        import requests
        
        # 测试带元数据过滤的查询
        url = "http://localhost:8000/rag/query"
        
        # 测试1: 向量检索 + 元数据过滤
        payload = {
            "query": "人工智能",
            "strategy": "vector",
            "limit": 5,
            "metadata_filters": {
                "category": "AI",
                "department": "研发部"
            }
        }
        
        response = requests.post(url, json=payload)
        if response.status_code == 200:
            result = response.json()
            print(f"✓ 向量检索+元数据过滤: {len(result['results'])}个结果")
        else:
            print(f"✗ API请求失败: {response.status_code}")
        
        # 测试2: 关键词检索 + 元数据过滤
        payload["strategy"] = "keyword"
        response = requests.post(url, json=payload)
        if response.status_code == 200:
            result = response.json()
            print(f"✓ 关键词检索+元数据过滤: {len(result['results'])}个结果")
        
        print("✓ API集成测试通过")
        
    except Exception as e:
        print(f"✗ API集成测试失败: {e}")
        print("  提示: 请确保API服务正在运行")

def main():
    """主测试函数"""
    print("第九节课：元数据过滤 - 功能测试")
    print("=" * 50)
    
    # 执行所有测试
    test_database_extension()
    test_basic_filtering()
    test_complex_filtering()
    test_performance()
    test_metadata_stats()
    test_api_integration()
    
    print("\n" + "=" * 50)
    print("测试完成！")
    print("\n实验总结:")
    print("1. ✓ 数据库扩展：成功添加元数据字段和索引")
    print("2. ✓ 基础过滤：支持单字段过滤查询")
    print("3. ✓ 复合条件：支持多字段、多操作符组合")
    print("4. ✓ 查询性能：索引优化提升查询速度")
    print("5. ✓ 统计信息：提供元数据分布统计")
    print("6. ✓ API集成：与现有检索策略无缝集成")

if __name__ == "__main__":
    main()
```

### 任务4：交互式查询工具（10分钟）

创建 `interactive_metadata_query.py`：

```python
#!/usr/bin/env python3
"""
交互式元数据查询工具
允许用户通过命令行界面测试不同的元数据过滤条件
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from app.services.metadata_filter import MetadataFilterService
import json
from datetime import datetime

def print_menu():
    """打印菜单"""
    print("\n" + "=" * 50)
    print("交互式元数据查询工具")
    print("=" * 50)
    print("1. 查看元数据统计")
    print("2. 按分类查询")
    print("3. 按作者查询")
    print("4. 按部门查询")
    print("5. 按标签查询")
    print("6. 时间范围查询")
    print("7. 复合条件查询")
    print("8. 自定义查询")
    print("0. 退出")
    print("=" * 50)

def show_metadata_stats(service):
    """显示元数据统计"""
    print("\n=== 元数据统计信息 ===")
    stats = service.get_metadata_stats()
    
    print(f"总文档数: {stats.get('total_documents', 0)}")
    
    print("\n分类分布:")
    for category, count in stats.get('categories', {}).items():
        print(f"  {category}: {count}")
    
    print("\n作者分布:")
    for author, count in stats.get('authors', {}).items():
        print(f"  {author}: {count}")
    
    print("\n部门分布:")
    for dept, count in stats.get('departments', {}).items():
        print(f"  {dept}: {count}")

def query_by_category(service):
    """按分类查询"""
    print("\n=== 按分类查询 ===")
    category = input("请输入分类名称 (如: AI, 技术, 商业): ")
    
    base_query = "SELECT id, content, category, author, created_at FROM documents"
    filters = {'category': category}
    
    results = service.filter_documents(base_query, {}, filters, 10)
    
    print(f"\n找到 {len(results)} 个结果:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. [{result['category']}] {result['author']}")
        print(f"   {result['content'][:100]}...")
        print(f"   创建时间: {result['created_at']}")

def query_by_tags(service):
    """按标签查询"""
    print("\n=== 按标签查询 ===")
    tag = input("请输入标签名称 (如: 人工智能, 机器学习): ")
    
    base_query = "SELECT id, content, category, author, tags FROM documents"
    filters = {'tags': {'operator': 'contains', 'value': [tag]}}
    
    results = service.filter_documents(base_query, {}, filters, 10)
    
    print(f"\n找到 {len(results)} 个结果:")
    for i, result in enumerate(results, 1):
        print(f"\n{i}. [{result['category']}] {result['author']}")
        print(f"   {result['content'][:100]}...")
        print(f"   标签: {result['tags']}")

def custom_query(service):
    """自定义查询"""
    print("\n=== 自定义查询 ===")
    print("请输入JSON格式的过滤条件，例如:")
    print('{"category": "AI", "author": {"operator": "in", "value": ["张三", "李四"]}}')
    
    try:
        filter_json = input("\n过滤条件: ")
        filters = json.loads(filter_json)
        
        base_query = "SELECT id, content, category, author, department, tags, created_at FROM documents"
        results = service.filter_documents(base_query, {}, filters, 10)
        
        print(f"\n找到 {len(results)} 个结果:")
        for i, result in enumerate(results, 1):
            print(f"\n{i}. [{result['category']}] {result['author']} - {result['department']}")
            print(f"   {result['content'][:100]}...")
            print(f"   标签: {result['tags']}")
            print(f"   创建时间: {result['created_at']}")
    
    except json.JSONDecodeError:
        print("✗ JSON格式错误，请检查输入")
    except Exception as e:
        print(f"✗ 查询失败: {e}")

def main():
    """主函数"""
    service = MetadataFilterService()
    
    while True:
        print_menu()
        choice = input("请选择操作 (0-8): ")
        
        if choice == '0':
            print("再见！")
            break
        elif choice == '1':
            show_metadata_stats(service)
        elif choice == '2':
            query_by_category(service)
        elif choice == '5':
            query_by_tags(service)
        elif choice == '8':
            custom_query(service)
        else:
            print("功能开发中...")
        
        input("\n按回车键继续...")

if __name__ == "__main__":
    main()
```

## 实验扩展（可选）

### 扩展1：查询计划分析
创建查询性能分析工具，使用EXPLAIN ANALYZE分析查询计划。

### 扩展2：动态索引建议
基于查询模式，自动建议创建哪些索引以优化性能。

### 扩展3：元数据验证
实现元数据字段的验证规则，确保数据质量。

## 思考题

1. **召回率影响**：元数据过滤如何影响检索召回率？如何平衡精确度和召回率？

2. **性能优化**：在大规模数据中，如何保持过滤查询的高性能？

3. **索引策略**：什么情况下应该使用复合索引而不是单列索引？

4. **缓存策略**：如何为元数据过滤查询设计有效的缓存策略？

5. **动态字段**：如何支持用户自定义的元数据字段？

## 实验报告要求

请在实验完成后，提交包含以下内容的实验报告：

1. **数据库扩展结果**：截图显示新增字段和索引
2. **功能测试结果**：各项测试的执行结果
3. **性能测试数据**：不同查询条件的执行时间对比
4. **问题与解决方案**：实验过程中遇到的问题及解决方法
5. **思考题答案**：对上述思考题的分析和回答

## 下节课预告

下节课将学习**重排序(Rerank)接入**，通过集成重排序模型进一步提升检索精度，包括bge-reranker-v2-m3模型调用、批量重排序、缓存策略等内容。