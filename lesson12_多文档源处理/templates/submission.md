# Lesson 12 提交模板（多文档源处理）

> 请复制此模板填写，并与实验日志与截图一同提交。

## 1. 环境与配置
- 项目版本/分支：
- 语料简述（来源/类型/规模）：
- 分块器策略（按字符/按 token/按段落）：
- 评估方法（人工/脚本/指标）：

## 2. 三类来源（必须端到端验证并重向量化）
- 来源 A：PDF（文件名/路径）：
- 来源 B：TXT（文件名/路径）：
- 来源 C：URL（链接或快照）：

## 3. 指标记录
- 解析成功率：
- 去重率（重复判定与处理）：
- 检索：`top_k`、`score_threshold`、跨源召回覆盖（按问题域统计）：
- 来源一致性：问答 `sources` 与答案一致性（举例 1–2 条）。
- 重排影响：开启与关闭重排的排序差异（定性或定量）。

> 建议以表格呈现：
| 来源 | 数量 | 解析成功 | 去重处理 | total_found | 来源一致性 |
|------|------|----------|----------|-------------|------------|
| PDF  |      |          |          |             |            |
| TXT  |      |          |          |             |            |
| URL  |      |          |          |             |            |

## 4. 响应片段与截图
- 文档列表字段：`document_id/document_filename/source_type/metadata/status`。
- 检索字段：`chunk_id/document_id/chunk_index/content/score/start_position/end_position/metadata`。
- 问答来源字段：`sources[].document_id/.document_filename/.chunk_id/.score`。
- 必须包含时间戳与接口路径，保证可复核。

## 5. 结论与推荐
- 元数据归一化策略与命名一致性总结：
- 去重与版本化策略：
- 跨源融合与重排的建议：
- 局限与边界（如 URL 抓取稳定性、解析器限制）：

## 6. 故障排查与兜底
- 是否在改数据后重向量化并刷新索引：是/否。
- 错误示例与处理（不支持来源、解析异常、重复文档）：
- 兜底策略（静态快照、降级参数、缩小语料、调整 `top_k`/阈值）：

## 7. 承接与展望
- 与 Lesson 11 的衔接：分块策略对跨源覆盖与来源质量的影响。
- 对 Lesson 14 的铺垫：缓存与键设计（来源维度的复用与命中）。

---
声明：不允许虚构或伪造数据与截图；若无法量化则需给出充分的定性证据与可复核日志。