# 第十二节课：多文档源处理 - 学生实验指导

## 实验概述
- **实验时长**：15分钟
- **实验目标**：实现多文档格式处理系统，支持PDF、Word、TXT、HTML等格式
- **技术栈**：PyMuPDF、python-docx、BeautifulSoup、concurrent.futures
- **前置条件**：完成前面课程的文档解析和数据库操作实验

## 实验环境准备

### 1. 安装依赖包
```bash
# 进入rag-system目录
cd rag-system

# 安装文档处理相关依赖
uv add PyMuPDF python-docx beautifulsoup4 lxml
uv add chardet  # 字符编码检测
```

### 2. 准备测试文档
```bash
# 创建测试文档目录
mkdir -p test_documents

# 准备不同格式的测试文档
echo "这是一个测试文本文档" > test_documents/sample.txt
echo "<html><body><h1>测试HTML文档</h1><p>这是HTML内容</p></body></html>" > test_documents/sample.html
```

## 核心实验内容

### 实验一：实现文档处理器基类和具体实现

#### 1.1 创建文档处理器基类
```python
# src/services/document_processor.py
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional
from pathlib import Path
import logging
from enum import Enum

class ProcessingError(Exception):
    """文档处理异常"""
    def __init__(self, message: str, error_type: str, file_path: str):
        self.message = message
        self.error_type = error_type
        self.file_path = file_path
        super().__init__(self.message)

class ErrorType(Enum):
    FILE_NOT_FOUND = "FILE_NOT_FOUND"
    UNSUPPORTED_FORMAT = "UNSUPPORTED_FORMAT"
    PARSING_ERROR = "PARSING_ERROR"
    ENCODING_ERROR = "ENCODING_ERROR"

class DocumentProcessor(ABC):
    """文档处理器基类"""
    
    def __init__(self):
        self.logger = logging.getLogger(self.__class__.__name__)
    
    @abstractmethod
    def can_process(self, file_path: str) -> bool:
        """判断是否能处理该文件"""
        pass
    
    @abstractmethod
    def process(self, file_path: str) -> Dict[str, Any]:
        """处理文档并返回结构化数据"""
        pass
    
    def _validate_file(self, file_path: str) -> Path:
        """验证文件是否存在"""
        path = Path(file_path)
        if not path.exists():
            raise ProcessingError(
                f"File not found: {file_path}",
                ErrorType.FILE_NOT_FOUND.value,
                file_path
            )
        return path
    
    def _extract_metadata(self, file_path: str) -> Dict[str, Any]:
        """提取文件元数据"""
        path = Path(file_path)
        stat = path.stat()
        return {
            'filename': path.name,
            'file_size': stat.st_size,
            'created_time': stat.st_ctime,
            'modified_time': stat.st_mtime,
            'file_extension': path.suffix.lower()
        }
```

#### 1.2 实现PDF处理器
```python
# 继续在 src/services/document_processor.py 中添加
import fitz  # PyMuPDF

class PDFProcessor(DocumentProcessor):
    """PDF文档处理器"""
    
    def can_process(self, file_path: str) -> bool:
        return file_path.lower().endswith('.pdf')
    
    def process(self, file_path: str) -> Dict[str, Any]:
        path = self._validate_file(file_path)
        
        try:
            doc = fitz.open(str(path))
            text = ""
            pages_info = []
            
            for page_num in range(len(doc)):
                page = doc[page_num]
                page_text = page.get_text()
                text += page_text + "\n"
                
                pages_info.append({
                    'page_number': page_num + 1,
                    'text_length': len(page_text),
                    'has_images': len(page.get_images()) > 0
                })
            
            doc.close()
            
            result = {
                'text': text.strip(),
                'metadata': self._extract_metadata(file_path),
                'pages_info': pages_info,
                'total_pages': len(pages_info)
            }
            
            self.logger.info(f"Successfully processed PDF: {file_path}, {len(pages_info)} pages")
            return result
            
        except Exception as e:
            raise ProcessingError(
                f"Error processing PDF: {str(e)}",
                ErrorType.PARSING_ERROR.value,
                file_path
            )
```

#### 1.3 实现Word处理器
```python
# 继续在 src/services/document_processor.py 中添加
import docx

class WordProcessor(DocumentProcessor):
    """Word文档处理器"""
    
    def can_process(self, file_path: str) -> bool:
        return file_path.lower().endswith(('.docx', '.doc'))
    
    def process(self, file_path: str) -> Dict[str, Any]:
        path = self._validate_file(file_path)
        
        try:
            doc = docx.Document(str(path))
            text = ""
            paragraphs_info = []
            
            for i, paragraph in enumerate(doc.paragraphs):
                para_text = paragraph.text.strip()
                if para_text:  # 跳过空段落
                    text += para_text + "\n"
                    paragraphs_info.append({
                        'paragraph_number': i + 1,
                        'text_length': len(para_text),
                        'style': paragraph.style.name if paragraph.style else 'Normal'
                    })
            
            # 处理表格
            tables_info = []
            for table_idx, table in enumerate(doc.tables):
                table_text = ""
                for row in table.rows:
                    row_text = "\t".join([cell.text.strip() for cell in row.cells])
                    table_text += row_text + "\n"
                
                if table_text.strip():
                    text += table_text + "\n"
                    tables_info.append({
                        'table_number': table_idx + 1,
                        'rows': len(table.rows),
                        'columns': len(table.columns) if table.rows else 0
                    })
            
            result = {
                'text': text.strip(),
                'metadata': self._extract_metadata(file_path),
                'paragraphs_info': paragraphs_info,
                'tables_info': tables_info,
                'total_paragraphs': len(paragraphs_info),
                'total_tables': len(tables_info)
            }
            
            self.logger.info(f"Successfully processed Word: {file_path}, {len(paragraphs_info)} paragraphs")
            return result
            
        except Exception as e:
            raise ProcessingError(
                f"Error processing Word document: {str(e)}",
                ErrorType.PARSING_ERROR.value,
                file_path
            )
```

#### 1.4 实现HTML处理器
```python
# 继续在 src/services/document_processor.py 中添加
from bs4 import BeautifulSoup
import chardet

class HTMLProcessor(DocumentProcessor):
    """HTML文档处理器"""
    
    def can_process(self, file_path: str) -> bool:
        return file_path.lower().endswith(('.html', '.htm'))
    
    def _detect_encoding(self, file_path: str) -> str:
        """检测文件编码"""
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            return result['encoding'] or 'utf-8'
    
    def process(self, file_path: str) -> Dict[str, Any]:
        path = self._validate_file(file_path)
        
        try:
            encoding = self._detect_encoding(file_path)
            
            with open(path, 'r', encoding=encoding) as f:
                content = f.read()
            
            soup = BeautifulSoup(content, 'html.parser')
            
            # 移除脚本和样式标签
            for script in soup(["script", "style"]):
                script.decompose()
            
            # 提取文本
            text = soup.get_text()
            
            # 清理文本
            lines = (line.strip() for line in text.splitlines())
            chunks = (phrase.strip() for line in lines for phrase in line.split("  "))
            text = '\n'.join(chunk for chunk in chunks if chunk)
            
            # 提取结构信息
            structure_info = {
                'title': soup.title.string if soup.title else '',
                'headings': {
                    'h1': len(soup.find_all('h1')),
                    'h2': len(soup.find_all('h2')),
                    'h3': len(soup.find_all('h3')),
                },
                'paragraphs': len(soup.find_all('p')),
                'links': len(soup.find_all('a')),
                'images': len(soup.find_all('img'))
            }
            
            result = {
                'text': text,
                'metadata': self._extract_metadata(file_path),
                'structure_info': structure_info,
                'encoding': encoding
            }
            
            self.logger.info(f"Successfully processed HTML: {file_path}, encoding: {encoding}")
            return result
            
        except Exception as e:
            raise ProcessingError(
                f"Error processing HTML document: {str(e)}",
                ErrorType.PARSING_ERROR.value,
                file_path
            )
```

#### 1.5 实现TXT处理器
```python
# 继续在 src/services/document_processor.py 中添加

class TXTProcessor(DocumentProcessor):
    """纯文本文档处理器"""
    
    def can_process(self, file_path: str) -> bool:
        return file_path.lower().endswith('.txt')
    
    def _detect_encoding(self, file_path: str) -> str:
        """检测文件编码"""
        with open(file_path, 'rb') as f:
            raw_data = f.read()
            result = chardet.detect(raw_data)
            return result['encoding'] or 'utf-8'
    
    def process(self, file_path: str) -> Dict[str, Any]:
        path = self._validate_file(file_path)
        
        try:
            encoding = self._detect_encoding(file_path)
            
            with open(path, 'r', encoding=encoding) as f:
                text = f.read()
            
            # 统计信息
            lines = text.split('\n')
            non_empty_lines = [line for line in lines if line.strip()]
            
            result = {
                'text': text,
                'metadata': self._extract_metadata(file_path),
                'text_info': {
                    'total_lines': len(lines),
                    'non_empty_lines': len(non_empty_lines),
                    'total_characters': len(text),
                    'total_words': len(text.split())
                },
                'encoding': encoding
            }
            
            self.logger.info(f"Successfully processed TXT: {file_path}, {len(non_empty_lines)} lines")
            return result
            
        except Exception as e:
            raise ProcessingError(
                f"Error processing TXT document: {str(e)}",
                ErrorType.PARSING_ERROR.value,
                file_path
            )
```

### 实验二：实现处理器工厂和批量处理

#### 2.1 创建处理器工厂
```python
# 继续在 src/services/document_processor.py 中添加
from typing import List
import concurrent.futures
from pathlib import Path

class DocumentProcessorFactory:
    """文档处理器工厂"""
    
    def __init__(self):
        self.processors: List[DocumentProcessor] = []
        self.logger = logging.getLogger(self.__class__.__name__)
        
        # 注册默认处理器
        self._register_default_processors()
    
    def _register_default_processors(self):
        """注册默认处理器"""
        self.register(PDFProcessor())
        self.register(WordProcessor())
        self.register(HTMLProcessor())
        self.register(TXTProcessor())
    
    def register(self, processor: DocumentProcessor):
        """注册处理器"""
        self.processors.append(processor)
        self.logger.info(f"Registered processor: {processor.__class__.__name__}")
    
    def get_processor(self, file_path: str) -> DocumentProcessor:
        """获取合适的处理器"""
        for processor in self.processors:
            if processor.can_process(file_path):
                return processor
        
        raise ProcessingError(
            f"No processor found for file: {file_path}",
            ErrorType.UNSUPPORTED_FORMAT.value,
            file_path
        )
    
    def process_single_file(self, file_path: str) -> Dict[str, Any]:
        """处理单个文件"""
        try:
            processor = self.get_processor(file_path)
            return processor.process(file_path)
        except ProcessingError:
            raise
        except Exception as e:
            raise ProcessingError(
                f"Unexpected error processing file: {str(e)}",
                ErrorType.PARSING_ERROR.value,
                file_path
            )
    
    def batch_process(self, directory: str, max_workers: int = 4) -> Dict[str, Any]:
        """批量处理文档"""
        directory_path = Path(directory)
        if not directory_path.exists():
            raise ProcessingError(
                f"Directory not found: {directory}",
                ErrorType.FILE_NOT_FOUND.value,
                directory
            )
        
        # 获取所有支持的文件
        supported_files = []
        for file_path in directory_path.rglob("*.*"):
            if file_path.is_file():
                try:
                    self.get_processor(str(file_path))
                    supported_files.append(str(file_path))
                except ProcessingError:
                    continue  # 跳过不支持的文件
        
        self.logger.info(f"Found {len(supported_files)} supported files in {directory}")
        
        results = {
            'successful': [],
            'failed': [],
            'summary': {
                'total_files': len(supported_files),
                'successful_count': 0,
                'failed_count': 0
            }
        }
        
        # 并发处理
        with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_file = {executor.submit(self.process_single_file, file): file 
                            for file in supported_files}
            
            for future in concurrent.futures.as_completed(future_to_file):
                file_path = future_to_file[future]
                try:
                    result = future.result()
                    results['successful'].append({
                        'file_path': file_path,
                        'result': result
                    })
                    results['summary']['successful_count'] += 1
                    self.logger.info(f"Successfully processed: {file_path}")
                    
                except Exception as e:
                    results['failed'].append({
                        'file_path': file_path,
                        'error': str(e)
                    })
                    results['summary']['failed_count'] += 1
                    self.logger.error(f"Failed to process {file_path}: {e}")
        
        return results
```

### 实验三：创建测试脚本

#### 3.1 创建测试脚本
```python
# test_document_processing.py
import logging
import sys
from pathlib import Path

# 添加项目路径
sys.path.append(str(Path(__file__).parent))

from src.services.document_processor import (
    DocumentProcessorFactory,
    ProcessingError
)

def setup_logging():
    """设置日志"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('document_processing.log'),
            logging.StreamHandler()
        ]
    )

def test_single_file_processing():
    """测试单文件处理"""
    print("\n=== 测试单文件处理 ===")
    
    factory = DocumentProcessorFactory()
    
    # 测试文件列表
    test_files = [
        'test_documents/sample.txt',
        'test_documents/sample.html'
    ]
    
    for file_path in test_files:
        if Path(file_path).exists():
            try:
                result = factory.process_single_file(file_path)
                print(f"\n文件: {file_path}")
                print(f"文本长度: {len(result['text'])} 字符")
                print(f"文件大小: {result['metadata']['file_size']} 字节")
                print(f"文本预览: {result['text'][:100]}...")
            except ProcessingError as e:
                print(f"处理失败 {file_path}: {e.message}")
        else:
            print(f"文件不存在: {file_path}")

def test_batch_processing():
    """测试批量处理"""
    print("\n=== 测试批量处理 ===")
    
    factory = DocumentProcessorFactory()
    
    try:
        results = factory.batch_process('test_documents', max_workers=2)
        
        print(f"\n批量处理结果:")
        print(f"总文件数: {results['summary']['total_files']}")
        print(f"成功处理: {results['summary']['successful_count']}")
        print(f"处理失败: {results['summary']['failed_count']}")
        
        print("\n成功处理的文件:")
        for item in results['successful']:
            file_path = item['file_path']
            text_length = len(item['result']['text'])
            print(f"  - {file_path}: {text_length} 字符")
        
        if results['failed']:
            print("\n处理失败的文件:")
            for item in results['failed']:
                print(f"  - {item['file_path']}: {item['error']}")
                
    except ProcessingError as e:
        print(f"批量处理失败: {e.message}")

def test_error_handling():
    """测试错误处理"""
    print("\n=== 测试错误处理 ===")
    
    factory = DocumentProcessorFactory()
    
    # 测试不存在的文件
    try:
        factory.process_single_file('nonexistent.txt')
    except ProcessingError as e:
        print(f"预期错误 - 文件不存在: {e.error_type}")
    
    # 测试不支持的格式
    try:
        factory.process_single_file('test.xyz')
    except ProcessingError as e:
        print(f"预期错误 - 不支持的格式: {e.error_type}")

def main():
    """主函数"""
    setup_logging()
    
    print("多文档源处理系统测试")
    print("=" * 50)
    
    # 创建测试目录和文件
    Path('test_documents').mkdir(exist_ok=True)
    
    # 创建测试文件
    with open('test_documents/sample.txt', 'w', encoding='utf-8') as f:
        f.write("这是一个测试文本文档\n包含多行内容\n用于测试文本处理功能")
    
    with open('test_documents/sample.html', 'w', encoding='utf-8') as f:
        f.write("""
        <html>
        <head><title>测试HTML文档</title></head>
        <body>
            <h1>标题</h1>
            <p>这是一个测试段落</p>
            <p>包含多个段落的HTML文档</p>
        </body>
        </html>
        """)
    
    # 运行测试
    test_single_file_processing()
    test_batch_processing()
    test_error_handling()
    
    print("\n测试完成！查看 document_processing.log 获取详细日志。")

if __name__ == "__main__":
    main()
```

## 实验步骤

### 步骤1：创建文档处理器
1. 在 `src/services/` 目录下创建 `document_processor.py`
2. 实现基类和各种格式的处理器
3. 测试各个处理器的功能

### 步骤2：实现工厂模式
1. 创建 `DocumentProcessorFactory` 类
2. 实现处理器注册和选择逻辑
3. 添加批量处理功能

### 步骤3：添加错误处理和日志
1. 定义自定义异常类
2. 添加日志记录功能
3. 实现健壮的错误处理机制

### 步骤4：运行测试
```bash
# 运行测试脚本
python test_document_processing.py

# 查看日志文件
cat document_processing.log
```

## 实验验证

### 验证要点
1. **格式支持**：确认支持PDF、Word、HTML、TXT格式
2. **统一接口**：所有处理器返回相同结构的数据
3. **错误处理**：能正确处理各种异常情况
4. **批量处理**：能并发处理多个文档
5. **日志记录**：完整记录处理过程和结果

### 预期结果
- 成功解析不同格式的文档
- 提取文本内容和元数据信息
- 正确处理编码问题
- 并发处理提升效率
- 完整的错误日志记录

## 思考题

1. **扩展性问题**：如何添加对新文档格式（如PPT、Excel）的支持？

2. **性能优化**：处理大文件时如何避免内存溢出？

3. **错误恢复**：批量处理时如何实现断点续传功能？

4. **质量保证**：如何评估文档解析的质量和准确性？

## 扩展实验

### 扩展1：添加PPT支持
```python
# 使用python-pptx库
from pptx import Presentation

class PPTProcessor(DocumentProcessor):
    def can_process(self, file_path: str) -> bool:
        return file_path.lower().endswith(('.pptx', '.ppt'))
    
    def process(self, file_path: str) -> Dict[str, Any]:
        # 实现PPT解析逻辑
        pass
```

### 扩展2：添加缓存机制
```python
import hashlib
import pickle
from pathlib import Path

class CachedDocumentProcessor:
    def __init__(self, cache_dir: str = "cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
    
    def _get_cache_key(self, file_path: str) -> str:
        # 基于文件路径和修改时间生成缓存键
        stat = Path(file_path).stat()
        content = f"{file_path}_{stat.st_mtime}_{stat.st_size}"
        return hashlib.md5(content.encode()).hexdigest()
```

### 扩展3：添加进度监控
```python
from tqdm import tqdm

def batch_process_with_progress(self, directory: str, max_workers: int = 4):
    # 使用tqdm显示处理进度
    files = list(Path(directory).rglob("*.*"))
    
    with tqdm(total=len(files), desc="Processing documents") as pbar:
        # 处理逻辑
        pass
```

## 实验报告要求

请在实验完成后，提交包含以下内容的实验报告：

1. **实验环境**：Python版本、依赖包版本
2. **实现功能**：已实现的文档格式和功能特性
3. **测试结果**：各种格式文档的处理结果
4. **性能分析**：批量处理的效率和资源使用情况
5. **问题总结**：遇到的问题和解决方案
6. **改进建议**：对系统的优化建议

通过本实验，你将掌握构建可扩展文档处理系统的核心技术，为后续的RAG系统开发奠定坚实基础。