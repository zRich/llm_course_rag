# Lesson 12 讲稿（Teacher Script）— 多文档源处理

## 时间轴与流程
- 0–10 min：导入与目标说明（多源接入的意义与场景）。
- 10–30 min：概念讲解（适配器/解析器、归一化、去重与版本化）。
- 30–75 min：实践环节（三类来源端到端接入、检索与问答验证）。
- 75–90 min：总结与提交（指标、边界与下一课承接）。

## 开场话术（可照读）
- 今天我们聚焦“多文档源处理”，目标是在 PDF、TXT 与 Web URL 三类来源下，完成统一解析与元数据归一化，确保检索与问答的来源追踪与字段一致，最终给出跨源召回覆盖与一致性结论。

## 核心术语与定义
- Source Adapter/Parser：来源适配与解析组件（PDF/TXT/URL）。
- Normalization：元数据归一化与字段一致性（`document_id/document_filename/source_type/...`）。
- Deduplication：指纹/哈希去重与版本化策略；索引刷新。
- Fusion/Rerank：融合与重排，保障跨源结果的排序可比性与答案质量。

## 演示脚本（逐步）
1) 打开 `.env`，确认分块与基础配置（承接 Lesson 11）。
2) 接入三类来源：
   - PDF：上传 `sample.pdf`；
   - TXT：上传 `sample.txt`；
   - URL：抓取并解析正文（如课程站点示例）。
3) 统一元数据：
   - `document_id/document_filename/source_type/metadata` 一致；
   - 若重复：进行去重与版本更新，刷新索引。
4) 向量化与检索：
   - `POST /api/v1/vectors/vectorize`；
   - `POST /api/v1/retrieval/search`（按 `source_type` 过滤，查看融合与重排效果）。
5) 问答验证：
   - `POST /api/v1/qa/ask`，检查 `sources` 字段与答案一致性；
   - 比较开启/关闭重排的排序差异。
6) 记录与对比：解析成功率、去重率、跨源召回覆盖、来源一致性；汇总到模板。

## 互动与提问（参考答案）
- 问：为何需要归一化元数据？
  - 答：保证过滤与来源追踪可用，提升检索与问答的一致性与复核性。
- 问：去重与版本化如何影响索引？
  - 答：重复或旧版本需要刷新索引，否则会出现旧数据残留与排序异常。
- 问：跨源分数是否可直接比较？
  - 答：需要考虑分数归一化或融合策略（如 RRF），避免来源偏置。

## 常见误区与应对话术
- 误区：上传后未向量化就检索。应重向量化并确认索引刷新成功。
- 误区：元数据字段不统一导致过滤失败。应使用统一命名契约。
- 误区：URL 抓取失败或正文抽取不稳定。说明边界与兜底（降级到静态快照）。

## 总结与提交
- 总结：三类来源的统一解析与元数据归一，可显著改善跨源检索质量与来源追踪。
- 提交：按模板填写三类来源的日志与指标，附响应片段与截图；提交 PR；不可虚构。