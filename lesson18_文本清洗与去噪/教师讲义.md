# 第18节课：文本清洗与去噪 - 教师讲义

## 课程信息

- **课程名称**: 文本清洗与去噪
- **课程时长**: 45分钟
- **适用对象**: RAG系统开发者
- **前置知识**: 基础Python编程、文本处理概念

## 课程概述

文本清洗与去噪是RAG系统数据预处理的关键环节。原始文本数据往往包含各种噪声和格式问题，直接使用会严重影响检索和生成质量。本节课将系统介绍文本清洗的核心技术和实践方法。

### 为什么需要文本清洗？

1. **提高检索准确性**: 清洁的文本能提供更准确的语义表示
2. **减少存储开销**: 去除冗余信息，优化存储效率
3. **提升生成质量**: 高质量输入产生高质量输出
4. **降低计算成本**: 减少无效计算，提高系统性能

## 技术原理

### 1. 文本预处理算法

#### 1.1 空白字符处理
- **多余空格清理**: 将连续空格替换为单个空格
- **换行符规范化**: 统一不同操作系统的换行符
- **制表符处理**: 转换或删除制表符

```python
import re

def normalize_whitespace(text):
    """规范化空白字符"""
    # 统一换行符
    text = re.sub(r'\r\n|\r', '\n', text)
    # 清理多余空格
    text = re.sub(r' +', ' ', text)
    # 清理多余换行
    text = re.sub(r'\n+', '\n', text)
    return text.strip()
```

#### 1.2 特殊字符清理
- **控制字符**: 删除不可见的控制字符
- **特殊符号**: 处理或删除特殊Unicode字符
- **编码问题**: 修复编码错误

```python
import unicodedata

def clean_special_chars(text):
    """清理特殊字符"""
    # 移除控制字符
    text = ''.join(char for char in text 
                   if unicodedata.category(char)[0] != 'C')
    # 规范化Unicode
    text = unicodedata.normalize('NFKC', text)
    return text
```

### 2. 噪声检测与清理

#### 2.1 乱码检测
- **编码检测**: 识别文本的正确编码
- **乱码模式**: 检测常见的乱码特征
- **修复策略**: 尝试修复或标记乱码文本

```python
import chardet

def detect_and_fix_encoding(text_bytes):
    """检测并修复编码问题"""
    detected = chardet.detect(text_bytes)
    if detected['confidence'] > 0.8:
        try:
            return text_bytes.decode(detected['encoding'])
        except UnicodeDecodeError:
            pass
    # 降级处理
    return text_bytes.decode('utf-8', errors='ignore')
```

#### 2.2 无意义内容过滤
- **重复内容**: 检测和去除重复段落
- **模板文本**: 识别和过滤模板性内容
- **广告信息**: 过滤广告和推广内容

```python
def filter_meaningless_content(text):
    """过滤无意义内容"""
    lines = text.split('\n')
    filtered_lines = []
    
    for line in lines:
        line = line.strip()
        # 过滤过短的行
        if len(line) < 10:
            continue
        # 过滤重复内容
        if line not in filtered_lines:
            filtered_lines.append(line)
    
    return '\n'.join(filtered_lines)
```

### 3. 文本质量评估

#### 3.1 可读性评分
- **句子长度**: 评估句子复杂度
- **词汇难度**: 分析词汇复杂性
- **语法结构**: 检查语法正确性

```python
def calculate_readability_score(text):
    """计算可读性评分"""
    sentences = text.split('.')
    words = text.split()
    
    avg_sentence_length = len(words) / len(sentences) if sentences else 0
    
    # 简化的可读性评分
    if avg_sentence_length < 15:
        return 'high'
    elif avg_sentence_length < 25:
        return 'medium'
    else:
        return 'low'
```

#### 3.2 信息密度计算
- **关键词密度**: 计算重要词汇的分布
- **信息熵**: 评估文本的信息含量
- **语义相关性**: 分析内容的相关性

```python
from collections import Counter
import math

def calculate_information_density(text):
    """计算信息密度"""
    words = text.lower().split()
    word_freq = Counter(words)
    
    # 计算信息熵
    total_words = len(words)
    entropy = 0
    for freq in word_freq.values():
        prob = freq / total_words
        entropy -= prob * math.log2(prob)
    
    return entropy
```

### 4. 自动化清洗流程

#### 4.1 清洗管道设计
```python
class TextCleaningPipeline:
    """文本清洗管道"""
    
    def __init__(self):
        self.steps = [
            self.normalize_whitespace,
            self.clean_special_chars,
            self.filter_meaningless_content,
            self.validate_quality
        ]
    
    def process(self, text):
        """执行清洗流程"""
        for step in self.steps:
            text = step(text)
            if not text:  # 如果文本被完全过滤
                return None
        return text
    
    def validate_quality(self, text):
        """质量验证"""
        if len(text) < 50:  # 太短的文本
            return None
        if self.calculate_readability_score(text) == 'low':
            return None
        return text
```

## 实践要点

### 1. 性能优化
- **批量处理**: 使用向量化操作提高效率
- **并行处理**: 利用多进程处理大量文本
- **缓存机制**: 缓存清洗结果避免重复计算

### 2. 质量监控
- **清洗统计**: 记录清洗前后的文本变化
- **异常检测**: 监控异常的清洗结果
- **人工审核**: 定期人工检查清洗质量

### 3. 配置管理
- **规则配置**: 将清洗规则配置化
- **阈值调整**: 根据业务需求调整质量阈值
- **版本控制**: 管理清洗规则的版本变更

## 常见问题与解决方案

### 1. 过度清洗
**问题**: 清洗过程中丢失重要信息
**解决**: 设置合理的清洗阈值，保留必要的格式信息

### 2. 性能瓶颈
**问题**: 大量文本清洗导致性能问题
**解决**: 使用异步处理和批量操作优化性能

### 3. 编码问题
**问题**: 多种编码格式导致乱码
**解决**: 实现robust的编码检测和转换机制

## 课堂演示要点

1. **实时演示**: 展示不同类型噪声的清洗效果
2. **对比分析**: 对比清洗前后的文本质量
3. **性能测试**: 演示清洗流程的性能表现
4. **异常处理**: 展示如何处理特殊情况

## 课后作业

1. 实现一个完整的文本清洗管道
2. 测试不同类型文档的清洗效果
3. 优化清洗流程的性能
4. 设计质量评估指标

## 扩展阅读

- 自然语言处理中的文本预处理技术
- Unicode标准和字符编码
- 信息论在文本分析中的应用
- 大规模文本处理的工程实践