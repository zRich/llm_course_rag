# Lesson 07：关键词检索优化

## 1. 课次信息
- **课次编号**：Lesson 07
- **模块编号**：Module 02 - 检索技术进阶
- **预计时长**：45分钟
- **前置依赖**：Lesson 06（向量检索基础，已完成向量数据库搭建和基础检索功能）
- **后置依赖**：Lesson 08（混合检索策略，将复用关键词检索和向量检索功能）

## 2. 教学目标（SMART）
- **S（具体）**：能在RAG系统中正确实现PostgreSQL全文检索功能，集成jieba中文分词，并通过关键词搜索API测试验证
- **M（可测量）**：
  - 关键词搜索准确率 ≥ 80%
  - 搜索响应时间 ≤ 500ms
  - 分词效果验证通过率 ≥ 90%
  - 代码实现完整性 ≥ 95%
- **A（可达成）**：在限定工具（PostgreSQL、Python、jieba）和45分钟内，独立完成端到端关键词检索功能
- **R（相关性）**：与RAG系统检索模块目标一致，服务于多模态检索技术学习主线
- **T（时限性）**：45分钟内完成实现并通过验收测试

## 3. 教学重点
- **PostgreSQL全文检索核心概念**：tsvector、tsquery、@@操作符、ts_rank评分机制
- **jieba中文分词技术**：精确模式vs搜索模式、分词效果对比、搜索优化策略
- **关键词检索实现**：数据库字段扩展、索引创建、搜索接口开发
- **检索方式对比理解**：关键词检索vs向量检索的适用场景和性能特点

## 4. 教学难点
- **易错概念**：
  - tsvector和tsquery的区别与正确使用方法
  - 中文分词模式选择（精确vs搜索模式的权衡）
  - 全文检索索引类型（GIN vs GiST）的性能影响
- **复杂操作**：
  - 数据库字段动态更新和索引重建
  - 中文文本预处理和分词结果优化
  - 搜索结果相关性评分和排序逻辑
- **跨界依赖**：
  - 数据库操作与Python应用层的集成
  - 中文NLP处理与全文检索的结合
- **化解策略**：
  - 提供标准化的SQL操作模板
  - 演示分词效果对比，明确选择标准
  - 给出完整的错误处理和回滚方案

## 5. 知识点详解

### 5.1 PostgreSQL全文检索基础
**概念解释**：PostgreSQL全文检索是基于词汇匹配的文档检索技术，通过将文档和查询转换为向量进行匹配。

**核心组件**：
- `tsvector`：文档的标准化向量表示，包含词汇及其位置信息
- `tsquery`：查询的向量表示，支持布尔操作符
- `@@`操作符：执行向量匹配操作
- `ts_rank()`：计算文档与查询的相关性评分

**端到端示例**：
```sql
-- 输入：创建文档向量
SELECT to_tsvector('simple', '人工智能技术发展迅速');
-- 输出：'人工智能技术发展迅速':1,2,3,4,5

-- 输入：创建查询向量
SELECT to_tsquery('simple', '人工智能');
-- 输出：'人工智能'

-- 输入：执行匹配
SELECT to_tsvector('simple', '人工智能技术发展迅速') @@ to_tsquery('simple', '人工智能');
-- 输出：true
```

### 5.2 jieba中文分词技术
**概念解释**：jieba是Python中文分词库，解决中文文本没有天然分隔符的问题。

**分词模式对比**：
- 精确模式：追求分词准确性，适合文本分析
- 搜索模式：在精确模式基础上进一步切分长词，适合搜索引擎

**端到端示例**：
```python
import jieba

# 输入文本
text = "自然语言处理技术"

# 精确模式输出
words1 = jieba.lcut(text)
print(words1)  # ['自然语言处理', '技术']

# 搜索模式输出
words2 = jieba.lcut_for_search(text)
print(words2)  # ['自然', '语言', '处理', '自然语言处理', '技术']
```

### 5.3 关键词检索实现流程
**实现步骤**：
1. 数据库字段扩展：添加tsvector字段
2. 数据预处理：使用jieba分词处理中文内容
3. 向量生成：将分词结果转换为tsvector
4. 索引创建：建立GIN索引提升查询性能
5. 搜索接口：实现查询预处理和结果排序

## 6. 完整示例与演示

### 6.1 数据库扩展示例
**输入操作**：
```sql
-- 添加全文检索字段
ALTER TABLE documents ADD COLUMN content_vector tsvector;

-- 更新向量字段（使用分词结果）
UPDATE documents 
SET content_vector = to_tsvector('simple', title || ' ' || content);

-- 创建GIN索引
CREATE INDEX idx_content_vector ON documents USING gin(content_vector);
```

**期望输出**：
- 字段添加成功，无错误信息
- 数据更新完成，影响行数与文档总数一致
- 索引创建成功，查询性能提升明显

### 6.2 关键词搜索功能示例
**输入代码**：
```python
def keyword_search(query, limit=10):
    # 预处理查询
    processed_query = preprocess_query(query)
    
    # 执行搜索
    sql = """
    SELECT id, title, content, 
           ts_rank(content_vector, to_tsquery('simple', %s)) as score
    FROM documents 
    WHERE content_vector @@ to_tsquery('simple', %s)
    ORDER BY score DESC
    LIMIT %s
    """
    
    results = execute_query(sql, (processed_query, processed_query, limit))
    return results

def preprocess_query(query):
    # 使用jieba分词
    words = jieba.lcut_for_search(query)
    # 连接为搜索字符串
    return ' & '.join(words)
```

**期望输出**：
```json
{
  "results": [
    {
      "id": 1,
      "title": "人工智能基础",
      "content": "人工智能是计算机科学的一个分支...",
      "score": 0.8945
    }
  ],
  "total": 1,
  "query_time": "0.023s"
}
```

### 6.3 异常场景与兜底
**常见错误**：
1. 分词库未安装：`ModuleNotFoundError: No module named 'jieba'`
2. 数据库字段不存在：`column "content_vector" does not exist`
3. 索引创建失败：`relation "idx_content_vector" already exists`

**兜底策略**：
```python
def safe_keyword_search(query, limit=10):
    try:
        return keyword_search(query, limit)
    except ImportError:
        logger.error("jieba not installed, falling back to simple search")
        return simple_text_search(query, limit)
    except DatabaseError as e:
        logger.error(f"Database error: {e}")
        return {"error": "Search temporarily unavailable", "results": []}
```

## 7. 授课老师指导

### 7.1 时间轴与脚本（45分钟）
- **导入阶段（5分钟）**：回顾lesson06向量检索，引出关键词检索需求
- **理论讲解（15分钟）**：PostgreSQL全文检索原理、jieba分词技术
- **演示操作（15分钟）**：现场演示数据库扩展和搜索功能实现
- **学生实践（8分钟）**：学生独立完成关键词搜索功能
- **总结验收（2分钟）**：检查实现效果，预告下节课内容

### 7.2 教师讲稿（可直接照读）

**开场白**：
"同学们好，上节课我们学习了向量检索，今天我们要学习另一种重要的检索技术——关键词检索。今天的目标是让大家掌握PostgreSQL全文检索和jieba中文分词，最终实现一个完整的关键词搜索功能。"

**核心术语解释**：
- **tsvector**：文档向量，是PostgreSQL对文档内容的标准化表示
- **tsquery**：查询向量，是对搜索关键词的标准化表示
- **@@操作符**：PostgreSQL中的匹配操作符，用于判断文档是否匹配查询
- **ts_rank**：相关性评分函数，数值越高表示匹配度越好
- **jieba分词**：中文文本分词工具，解决中文没有空格分隔的问题

**示例讲解**：
"让我们看一个具体例子。当我们搜索'人工智能'时，系统首先用jieba将查询分词，然后转换为tsquery，再与文档的tsvector进行匹配，最后按相关性评分排序返回结果。"

### 7.3 课堂提问与练习（含参考答案）

**提问1**：关键词检索和向量检索有什么区别？
**参考答案**：关键词检索基于精确词汇匹配，适合专有名词搜索，速度快但语义理解有限；向量检索基于语义相似性，能理解同义词但计算复杂度高。

**提问2**：为什么中文需要分词处理？
**参考答案**：中文文本没有天然的词汇分隔符（如英文的空格），需要通过分词算法将连续的字符序列切分为有意义的词汇单元。

**练习任务**：
1. 使用jieba对"机器学习算法优化"进行分词，比较精确模式和搜索模式的结果
2. 编写SQL查询，搜索包含"数据库"关键词的文档并按相关性排序

### 7.4 常见误区与应对话术

**误区1**：认为关键词检索已经过时，向量检索能完全替代
**应对话术**："关键词检索在特定场景下仍然不可替代，比如搜索具体的产品型号、技术术语等。两种技术是互补的，不是替代关系。"

**误区2**：忽视中文分词的重要性，直接使用原始文本
**应对话术**："中文分词质量直接影响搜索效果。没有分词的中文搜索只能进行字符串匹配，无法理解词汇边界，会产生大量误匹配。"

**误区3**：认为全文检索索引会显著影响写入性能
**应对话术**："GIN索引确实会增加写入开销，但对于读多写少的应用场景，查询性能的提升远大于写入性能的损失。可以通过批量更新等策略优化。"

### 7.5 黑板/投屏操作步骤（逐步）

**步骤1**：投屏显示PostgreSQL全文检索架构图
- 展示tsvector、tsquery、@@操作符的关系
- 标注数据流向：文档→分词→tsvector→匹配→排序

**步骤2**：现场演示jieba分词效果
```bash
# 打开Python终端
python3
>>> import jieba
>>> text = "自然语言处理技术发展"
>>> jieba.lcut(text)
>>> jieba.lcut_for_search(text)
```

**步骤3**：数据库操作演示
```sql
-- 连接数据库
psql -d rag_system
-- 检查现有表结构
\d documents
-- 执行字段添加
ALTER TABLE documents ADD COLUMN content_vector tsvector;
```

**步骤4**：一致性检查
- 验证字段添加成功：`SELECT column_name FROM information_schema.columns WHERE table_name='documents';`
- 检查索引创建：`\di idx_content_vector`
- 测试搜索功能：执行示例查询并验证结果格式

**步骤5**：现场填写提交模板
```python
# 展示完整的搜索函数模板
def keyword_search(query, limit=10):
    # TODO: 实现查询预处理
    pass
    
    # TODO: 执行数据库查询
    pass
    
    # TODO: 格式化返回结果
    pass
```

## 8. 学生任务

### 8.1 课堂任务（即时练习）
1. **环境验证**：确认jieba库安装成功，能正常导入使用
2. **分词测试**：对给定中文文本进行分词，比较不同模式的效果
3. **数据库扩展**：为documents表添加content_vector字段并创建索引
4. **基础搜索**：实现简单的关键词搜索功能，返回匹配结果

### 8.2 课后任务（延伸作业）
1. **性能优化**：分析不同索引类型对查询性能的影响
2. **搜索增强**：实现搜索结果高亮显示功能
3. **错误处理**：完善异常情况的处理逻辑
4. **效果评估**：设计测试用例评估搜索准确率

### 8.3 提交格式
- **代码文件**：`keyword_search.py`（包含完整搜索功能）
- **测试文件**：`test_search.py`（包含测试用例）
- **文档文件**：`README.md`（说明实现思路和测试结果）
- **SQL文件**：`schema_update.sql`（数据库结构变更脚本）

### 8.4 工具与环境要求
- Python 3.8+
- PostgreSQL 12+
- jieba 0.42+
- psycopg2-binary 2.9+

## 9. 对齐与连续性

### 9.1 与模块/大纲的锚点
- **Module 02锚点**：检索技术进阶，承接基础向量检索，引入关键词检索
- **课程主线契约**：RAG系统多模态检索能力建设
- **核心API一致性**：搜索接口格式与lesson06保持一致
- **数据模型对齐**：复用documents表结构，扩展检索字段

### 9.2 承接与引出说明
**承接lesson06**：
- 复用已建立的向量数据库和文档数据
- 在现有检索框架基础上添加关键词检索模块
- 保持API接口的一致性和兼容性

**引出lesson08**：
- 为混合检索策略提供关键词检索基础
- 建立检索效果对比的评估框架
- 准备多种检索方式的融合机制

## 10. 提交与验收

### 10.1 评估标准阈值
- **功能完整性**：≥ 95%（必须实现所有核心功能）
- **代码质量**：≥ 85%（符合PEP8规范，有适当注释）
- **搜索准确率**：≥ 80%（基于标准测试集）
- **响应时间**：≤ 500ms（单次查询平均响应时间）
- **错误处理**：≥ 90%（覆盖主要异常场景）

### 10.2 不可虚构声明
- 不得编造未实现的搜索算法或优化策略
- 不得虚报性能测试数据或准确率指标
- 不得使用未经验证的第三方库或服务
- 必须基于实际运行结果提供测试报告

### 10.3 验收流程
1. **代码审查**：检查实现逻辑和代码规范
2. **功能测试**：验证搜索功能的正确性
3. **性能测试**：测量查询响应时间和准确率
4. **异常测试**：验证错误处理的完整性
5. **文档检查**：确认说明文档的完整性和准确性

### 10.4 命名与口径一致性检查表
- [ ] 函数命名遵循snake_case规范
- [ ] 数据库字段命名与现有结构一致
- [ ] API响应格式与lesson06保持一致
- [ ] 错误码使用标准HTTP状态码
- [ ] 日志格式符合项目规范

## 11. 术语与概念定义

### 11.1 核心概念
- **全文检索（Full-Text Search）**：基于文档内容进行的搜索技术，支持词汇匹配和相关性排序
- **tsvector**：PostgreSQL中文档的向量化表示，包含词汇及其位置权重信息
- **tsquery**：PostgreSQL中查询的向量化表示，支持布尔逻辑操作
- **GIN索引**：Generalized Inverted Index，适用于包含多个值的数据类型的索引方法

### 11.2 技术术语
- **分词（Tokenization）**：将连续文本切分为独立词汇单元的过程
- **词频（Term Frequency）**：词汇在文档中出现的频率
- **相关性评分（Relevance Score）**：衡量文档与查询匹配程度的数值指标
- **倒排索引（Inverted Index）**：以词汇为键、文档列表为值的索引结构

### 11.3 评估标准
- **准确率（Precision）**：检索结果中相关文档的比例
- **召回率（Recall）**：相关文档中被检索到的比例
- **F1分数**：准确率和召回率的调和平均数
- **响应时间**：从查询发起到返回结果的时间间隔

## 12. 提交前检查清单

### 12.1 教师检查清单
- [ ] 三要素齐备：教学目标、重点、难点已明确定义且可测量
- [ ] 知识点完整：包含输入/输出/异常处理的端到端示例
- [ ] 教师指导可执行：时间轴明确，话术具体，操作步骤详细
- [ ] 对齐与连续性：与lesson06承接清晰，为lesson08做好准备
- [ ] 验收标准统一：评估指标已定义且可验证
- [ ] 一致性检查：命名规范统一，错误码标准化

### 12.2 学生检查清单
- [ ] 环境准备完成：jieba库安装成功，数据库连接正常
- [ ] 核心功能实现：关键词搜索、分词处理、结果排序
- [ ] 测试用例完整：覆盖正常场景、边界情况、异常处理
- [ ] 代码质量达标：符合规范，注释充分，结构清晰
- [ ] 文档说明完整：实现思路、测试结果、使用说明
- [ ] 性能指标达标：响应时间、准确率符合要求

### 12.3 质量要求
- [ ] 覆盖主线：实现完整的关键词检索流程
- [ ] 核心要点：PostgreSQL全文检索、jieba分词、搜索接口
- [ ] 输入/输出路径：正常查询、空查询、特殊字符查询
- [ ] 错误路径：数据库连接失败、分词库异常、查询超时
- [ ] 一致性要求：API格式、错误处理、日志记录统一

## 13. 边界声明

### 13.1 本课不解决的问题
- **高级搜索语法**：不涉及复杂的布尔查询和短语搜索
- **搜索结果聚合**：不包含分类、标签等聚合功能
- **个性化排序**：不涉及用户行为和偏好的个性化算法
- **分布式搜索**：不处理跨多个数据库的分布式查询
- **实时索引更新**：不涉及增量索引和实时更新机制

### 13.2 外部依赖
- **jieba分词库**：依赖第三方库进行中文分词处理
- **PostgreSQL数据库**：需要PostgreSQL 12+版本支持
- **网络连接**：数据库连接需要稳定的网络环境
- **系统资源**：索引创建和查询需要足够的内存和存储空间

### 13.3 替代方案
- **Elasticsearch**：可作为更强大的全文检索引擎替代方案
- **其他分词库**：可使用pkuseg、thulac等替代jieba
- **SQLite FTS**：轻量级应用可考虑SQLite的全文检索功能
- **云搜索服务**：可使用阿里云、腾讯云等托管搜索服务

---

**文档版本**：v1.0  
**最后更新**：2024年  
**审核状态**：待审核