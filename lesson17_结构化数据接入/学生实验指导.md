# 第17节课：结构化数据接入系统 - 学生实验指导

## 实验目标
通过本实验，学生将：
1. 理解结构化数据接入的核心概念和架构设计
2. 掌握数据连接器的实现方法
3. 学会设计和实现同步管理系统
4. 实现数据库和API数据源的接入功能
5. 了解数据转换和RAG系统集成的方法

## 实验环境准备

### 环境要求
- Python 3.8+
- 已完成前面课程的RAG系统基础代码
- 文本编辑器或IDE
- PostgreSQL或MySQL数据库（可选）

### 依赖安装
```bash
cd lesson17_structured_data
pip install -r requirements.txt
```

依赖包包括：
- fastapi
- uvicorn
- sqlalchemy
- asyncpg
- aiohttp
- pandas
- pydantic

## 实验步骤

### 步骤1：创建数据连接器基类（15分钟）

创建文件 `connectors/base.py`：

```python
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import logging

class DataConnector(ABC):
    """数据连接器抽象基类"""
    
    def __init__(self, connector_id: str, config: Dict[str, Any]):
        self.connector_id = connector_id
        self.config = config
        self.is_connected = False
        self.logger = logging.getLogger(f"{self.__class__.__name__}_{connector_id}")
    
    @abstractmethod
    async def connect(self) -> bool:
        """建立连接
        
        Returns:
            bool: 连接是否成功
        """
        pass
    
    @abstractmethod
    async def disconnect(self):
        """断开连接"""
        pass
    
    @abstractmethod
    async def test_connection(self) -> bool:
        """测试连接
        
        Returns:
            bool: 连接测试是否成功
        """
        pass
    
    @abstractmethod
    async def fetch_data(self, **kwargs) -> List[Dict[str, Any]]:
        """获取数据
        
        Args:
            **kwargs: 查询参数
            
        Returns:
            List[Dict[str, Any]]: 数据记录列表
        """
        pass
    
    @abstractmethod
    async def get_incremental_data(self, last_sync_time: Optional[str] = None) -> List[Dict[str, Any]]:
        """获取增量数据
        
        Args:
            last_sync_time: 上次同步时间
            
        Returns:
            List[Dict[str, Any]]: 增量数据记录列表
        """
        pass
    
    def get_connector_info(self) -> Dict[str, Any]:
        """获取连接器信息"""
        return {
            'connector_id': self.connector_id,
            'connector_type': self.__class__.__name__,
            'is_connected': self.is_connected,
            'config_keys': list(self.config.keys())
        }
```

### 步骤2：实现数据库连接器（20分钟）

创建文件 `connectors/database.py`：

```python
import asyncio
from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine
from sqlalchemy import text
from .base import DataConnector

class DatabaseConnector(DataConnector):
    """数据库连接器"""
    
    def __init__(self, connector_id: str, config: Dict[str, Any]):
        super().__init__(connector_id, config)
        self.engine: Optional[AsyncEngine] = None
        self.connection_string = self._build_connection_string()
    
    def _build_connection_string(self) -> str:
        """构建数据库连接字符串"""
        db_type = self.config.get('type', 'postgresql')
        host = self.config['host']
        port = self.config.get('port', 5432 if db_type == 'postgresql' else 3306)
        database = self.config['database']
        username = self.config['username']
        password = self.config['password']
        
        if db_type == 'postgresql':
            return f"postgresql+asyncpg://{username}:{password}@{host}:{port}/{database}"
        elif db_type == 'mysql':
            return f"mysql+aiomysql://{username}:{password}@{host}:{port}/{database}"
        else:
            raise ValueError(f"不支持的数据库类型: {db_type}")
    
    async def connect(self) -> bool:
        """建立数据库连接"""
        try:
            self.engine = create_async_engine(
                self.connection_string,
                pool_size=self.config.get('pool_size', 5),
                max_overflow=self.config.get('max_overflow', 10),
                echo=self.config.get('echo', False)
            )
            
            # 测试连接
            async with self.engine.begin() as conn:
                await conn.execute(text("SELECT 1"))
            
            self.is_connected = True
            self.logger.info(f"数据库连接成功: {self.connector_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"数据库连接失败: {e}")
            self.is_connected = False
            return False
    
    async def disconnect(self):
        """断开数据库连接"""
        if self.engine:
            await self.engine.dispose()
            self.engine = None
            self.is_connected = False
            self.logger.info(f"数据库连接已断开: {self.connector_id}")
    
    async def test_connection(self) -> bool:
        """测试数据库连接"""
        if not self.is_connected:
            return await self.connect()
        
        try:
            async with self.engine.begin() as conn:
                await conn.execute(text("SELECT 1"))
            return True
        except Exception as e:
            self.logger.error(f"连接测试失败: {e}")
            return False
    
    async def fetch_data(self, query: str = None, table: str = None, 
                        limit: int = 1000, offset: int = 0, 
                        where_clause: str = None) -> List[Dict[str, Any]]:
        """从数据库获取数据"""
        if not self.is_connected:
            await self.connect()
        
        # 构建查询语句
        if query is None:
            if table is None:
                raise ValueError("必须提供query或table参数")
            
            query = f"SELECT * FROM {table}"
            if where_clause:
                query += f" WHERE {where_clause}"
            query += f" LIMIT {limit} OFFSET {offset}"
        
        try:
            async with self.engine.begin() as conn:
                result = await conn.execute(text(query))
                rows = result.fetchall()
                columns = result.keys()
                
                data = [dict(zip(columns, row)) for row in rows]
                self.logger.info(f"获取数据成功，共 {len(data)} 条记录")
                return data
                
        except Exception as e:
            self.logger.error(f"数据获取失败: {e}")
            raise
    
    async def get_incremental_data(self, last_sync_time: Optional[str] = None) -> List[Dict[str, Any]]:
        """获取增量数据"""
        incremental_field = self.config.get('incremental_field', 'updated_at')
        table = self.config.get('table')
        
        if not table:
            raise ValueError("增量同步需要配置table参数")
        
        where_clause = None
        if last_sync_time:
            where_clause = f"{incremental_field} > '{last_sync_time}'"
        
        return await self.fetch_data(
            table=table,
            where_clause=where_clause,
            limit=self.config.get('batch_size', 1000)
        )
    
    async def get_table_schema(self, table: str) -> List[Dict[str, Any]]:
        """获取表结构信息"""
        db_type = self.config.get('type', 'postgresql')
        
        if db_type == 'postgresql':
            query = """
                SELECT column_name, data_type, is_nullable, column_default
                FROM information_schema.columns
                WHERE table_name = :table_name
                ORDER BY ordinal_position
            """
        elif db_type == 'mysql':
            query = """
                SELECT COLUMN_NAME as column_name, DATA_TYPE as data_type, 
                       IS_NULLABLE as is_nullable, COLUMN_DEFAULT as column_default
                FROM information_schema.COLUMNS
                WHERE TABLE_NAME = :table_name
                ORDER BY ORDINAL_POSITION
            """
        else:
            raise ValueError(f"不支持的数据库类型: {db_type}")
        
        async with self.engine.begin() as conn:
            result = await conn.execute(text(query), {'table_name': table})
            rows = result.fetchall()
            columns = result.keys()
            return [dict(zip(columns, row)) for row in rows]
```

### 步骤3：实现API连接器（20分钟）

创建文件 `connectors/api.py`：

```python
import asyncio
import aiohttp
from typing import List, Dict, Any, Optional
from urllib.parse import urljoin, urlencode
from .base import DataConnector

class APIConnector(DataConnector):
    """REST API连接器"""
    
    def __init__(self, connector_id: str, config: Dict[str, Any]):
        super().__init__(connector_id, config)
        self.session: Optional[aiohttp.ClientSession] = None
        self.base_url = config['base_url']
        self.headers = config.get('headers', {})
        self.timeout = config.get('timeout', 30)
        self.max_retries = config.get('max_retries', 3)
        self.rate_limit = config.get('rate_limit', {}).get('requests_per_second', 10)
        self._last_request_time = 0
    
    async def connect(self) -> bool:
        """建立HTTP会话"""
        try:
            timeout = aiohttp.ClientTimeout(total=self.timeout)
            self.session = aiohttp.ClientSession(
                headers=self.headers,
                timeout=timeout,
                connector=aiohttp.TCPConnector(
                    limit=self.config.get('connection_pool_size', 10)
                )
            )
            self.is_connected = True
            self.logger.info(f"API连接建立成功: {self.connector_id}")
            return True
            
        except Exception as e:
            self.logger.error(f"API连接失败: {e}")
            self.is_connected = False
            return False
    
    async def disconnect(self):
        """关闭HTTP会话"""
        if self.session:
            await self.session.close()
            self.session = None
            self.is_connected = False
            self.logger.info(f"API连接已关闭: {self.connector_id}")
    
    async def test_connection(self) -> bool:
        """测试API连接"""
        if not self.is_connected:
            await self.connect()
        
        test_endpoint = self.config.get('test_endpoint', '/')
        
        try:
            async with self.session.get(urljoin(self.base_url, test_endpoint)) as response:
                return response.status < 400
        except Exception as e:
            self.logger.error(f"API连接测试失败: {e}")
            return False
    
    async def _rate_limit_wait(self):
        """速率限制等待"""
        if self.rate_limit > 0:
            min_interval = 1.0 / self.rate_limit
            current_time = asyncio.get_event_loop().time()
            time_since_last = current_time - self._last_request_time
            
            if time_since_last < min_interval:
                await asyncio.sleep(min_interval - time_since_last)
            
            self._last_request_time = asyncio.get_event_loop().time()
    
    async def _make_request(self, method: str, endpoint: str, **kwargs) -> Dict[str, Any]:
        """发起HTTP请求（带重试和速率限制）"""
        url = urljoin(self.base_url, endpoint)
        
        for attempt in range(self.max_retries + 1):
            try:
                # 速率限制
                await self._rate_limit_wait()
                
                async with self.session.request(method, url, **kwargs) as response:
                    if response.status == 429:  # Too Many Requests
                        retry_after = int(response.headers.get('Retry-After', 60))
                        self.logger.warning(f"API速率限制，等待 {retry_after} 秒")
                        await asyncio.sleep(retry_after)
                        continue
                    
                    response.raise_for_status()
                    
                    content_type = response.headers.get('Content-Type', '')
                    if 'application/json' in content_type:
                        return await response.json()
                    else:
                        text_data = await response.text()
                        return {'data': text_data}
                        
            except Exception as e:
                if attempt == self.max_retries:
                    self.logger.error(f"API请求失败，已重试 {self.max_retries} 次: {e}")
                    raise e
                
                wait_time = 2 ** attempt
                self.logger.warning(f"API请求失败，{wait_time}秒后重试: {e}")
                await asyncio.sleep(wait_time)
    
    async def fetch_data(self, endpoint: str, method: str = 'GET', 
                        params: Dict = None, data: Dict = None,
                        paginate: bool = True, **kwargs) -> List[Dict[str, Any]]:
        """从API获取数据"""
        if not self.is_connected:
            await self.connect()
        
        all_data = []
        page = 1
        page_size = self.config.get('page_size', 100)
        max_pages = self.config.get('max_pages', 10)
        
        while page <= max_pages:
            # 构建请求参数
            request_params = params.copy() if params else {}
            
            if paginate:
                # 添加分页参数
                page_param = self.config.get('page_param', 'page')
                size_param = self.config.get('size_param', 'size')
                request_params[page_param] = page
                request_params[size_param] = page_size
            
            try:
                # 发起请求
                request_kwargs = {}
                if method.upper() == 'GET':
                    request_kwargs['params'] = request_params
                else:
                    request_kwargs['json'] = data or {}
                    if request_params:
                        endpoint_with_params = f"{endpoint}?{urlencode(request_params)}"
                        endpoint = endpoint_with_params
                
                response_data = await self._make_request(method, endpoint, **request_kwargs)
                
                # 提取数据
                page_data = self._extract_data_from_response(response_data)
                
                if not page_data:
                    break
                
                all_data.extend(page_data)
                
                # 检查是否还有更多数据
                if not paginate or len(page_data) < page_size:
                    break
                
                page += 1
                
            except Exception as e:
                self.logger.error(f"获取第 {page} 页数据失败: {e}")
                break
        
        self.logger.info(f"API数据获取完成，共 {len(all_data)} 条记录")
        return all_data
    
    def _extract_data_from_response(self, response_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """从响应中提取数据列表"""
        if isinstance(response_data, list):
            return response_data
        
        if isinstance(response_data, dict):
            # 尝试从常见的数据字段中提取列表
            data_fields = self.config.get('data_fields', ['data', 'items', 'results', 'records'])
            
            for field in data_fields:
                if field in response_data and isinstance(response_data[field], list):
                    return response_data[field]
            
            # 如果没有找到列表，返回单个对象的列表
            return [response_data]
        
        return []
    
    async def get_incremental_data(self, last_sync_time: Optional[str] = None) -> List[Dict[str, Any]]:
        """获取增量数据"""
        endpoint = self.config.get('incremental_endpoint')
        if not endpoint:
            raise ValueError("增量同步需要配置incremental_endpoint参数")
        
        params = {}
        if last_sync_time:
            time_param = self.config.get('time_param', 'since')
            params[time_param] = last_sync_time
        
        return await self.fetch_data(
            endpoint=endpoint,
            params=params,
            paginate=self.config.get('paginate_incremental', True)
        )
```

### 步骤4：实现同步管理器（25分钟）

创建文件 `sync_manager.py`：

```python
import asyncio
import json
import os
from datetime import datetime
from enum import Enum
from typing import Dict, List, Optional, Any
from dataclasses import dataclass, asdict
from connectors.base import DataConnector

class SyncType(Enum):
    FULL = "full"
    INCREMENTAL = "incremental"

class SyncStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class SyncTask:
    """同步任务信息"""
    sync_id: str
    connector_id: str
    sync_type: str
    status: str
    start_time: str
    end_time: Optional[str] = None
    total_records: int = 0
    processed_records: int = 0
    error_message: Optional[str] = None
    config: Dict[str, Any] = None
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SyncTask':
        return cls(**data)

class SyncManager:
    """同步管理器"""
    
    def __init__(self, history_file: str = "sync_history.json"):
        self.connectors: Dict[str, DataConnector] = {}
        self.sync_tasks: Dict[str, SyncTask] = {}
        self.running_tasks: Dict[str, asyncio.Task] = {}
        self.history_file = history_file
        self.load_history()
    
    def register_connector(self, connector: DataConnector):
        """注册数据连接器"""
        self.connectors[connector.connector_id] = connector
        print(f"连接器已注册: {connector.connector_id}")
    
    def get_connector(self, connector_id: str) -> Optional[DataConnector]:
        """获取连接器"""
        return self.connectors.get(connector_id)
    
    def list_connectors(self) -> List[Dict[str, Any]]:
        """列出所有连接器"""
        return [connector.get_connector_info() for connector in self.connectors.values()]
    
    async def start_sync(self, connector_id: str, sync_type: SyncType, 
                        config: Dict[str, Any] = None) -> str:
        """启动同步任务"""
        if connector_id not in self.connectors:
            raise ValueError(f"连接器 {connector_id} 不存在")
        
        # 检查是否有正在运行的任务
        running_task = self._get_running_task(connector_id)
        if running_task:
            raise ValueError(f"连接器 {connector_id} 已有正在运行的同步任务: {running_task.sync_id}")
        
        # 生成同步ID
        sync_id = f"{connector_id}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        # 创建同步任务
        task = SyncTask(
            sync_id=sync_id,
            connector_id=connector_id,
            sync_type=sync_type.value,
            status=SyncStatus.PENDING.value,
            start_time=datetime.now().isoformat(),
            config=config or {}
        )
        
        self.sync_tasks[sync_id] = task
        
        # 启动异步同步任务
        async_task = asyncio.create_task(self._execute_sync(sync_id))
        self.running_tasks[sync_id] = async_task
        
        print(f"同步任务已启动: {sync_id}")
        return sync_id
    
    def _get_running_task(self, connector_id: str) -> Optional[SyncTask]:
        """获取连接器的运行中任务"""
        for task in self.sync_tasks.values():
            if (task.connector_id == connector_id and 
                task.status == SyncStatus.RUNNING.value):
                return task
        return None
    
    async def _execute_sync(self, sync_id: str):
        """执行同步任务"""
        task = self.sync_tasks[sync_id]
        connector = self.connectors[task.connector_id]
        
        try:
            # 更新状态为运行中
            task.status = SyncStatus.RUNNING.value
            print(f"开始执行同步任务: {sync_id}")
            
            # 确保连接器已连接
            if not connector.is_connected:
                await connector.connect()
            
            # 获取数据
            if task.sync_type == SyncType.FULL.value:
                data = await connector.fetch_data(**task.config)
            else:
                # 获取上次同步时间
                last_sync_time = self._get_last_sync_time(task.connector_id)
                data = await connector.get_incremental_data(last_sync_time)
            
            task.total_records = len(data)
            print(f"获取到 {task.total_records} 条数据")
            
            # 处理数据（这里可以添加数据转换和存储逻辑）
            for i, record in enumerate(data):
                # 模拟数据处理时间
                await asyncio.sleep(0.01)
                
                # 这里可以添加实际的数据处理逻辑
                # 例如：数据转换、验证、存储到RAG系统等
                
                task.processed_records = i + 1
                
                # 每处理100条记录输出一次进度
                if (i + 1) % 100 == 0:
                    progress = (i + 1) / task.total_records * 100
                    print(f"同步进度: {progress:.1f}% ({i + 1}/{task.total_records})")
            
            # 更新状态为完成
            task.status = SyncStatus.COMPLETED.value
            task.end_time = datetime.now().isoformat()
            print(f"同步任务完成: {sync_id}")
            
        except asyncio.CancelledError:
            task.status = SyncStatus.CANCELLED.value
            task.end_time = datetime.now().isoformat()
            print(f"同步任务已取消: {sync_id}")
            
        except Exception as e:
            task.status = SyncStatus.FAILED.value
            task.error_message = str(e)
            task.end_time = datetime.now().isoformat()
            print(f"同步任务失败: {sync_id}, 错误: {e}")
            
        finally:
            # 清理运行中的任务
            if sync_id in self.running_tasks:
                del self.running_tasks[sync_id]
            
            # 保存历史记录
            self.save_history()
    
    def _get_last_sync_time(self, connector_id: str) -> Optional[str]:
        """获取连接器的最后同步时间"""
        # 查找最近一次成功的同步任务
        successful_tasks = [
            task for task in self.sync_tasks.values()
            if (task.connector_id == connector_id and 
                task.status == SyncStatus.COMPLETED.value)
        ]
        
        if successful_tasks:
            # 按结束时间排序，取最新的
            latest_task = max(successful_tasks, key=lambda t: t.end_time or "")
            return latest_task.end_time
        
        return None
    
    async def cancel_sync(self, sync_id: str) -> bool:
        """取消同步任务"""
        if sync_id not in self.running_tasks:
            return False
        
        task = self.running_tasks[sync_id]
        task.cancel()
        
        # 等待任务完成取消
        try:
            await task
        except asyncio.CancelledError:
            pass
        
        print(f"同步任务已取消: {sync_id}")
        return True
    
    def get_sync_status(self, sync_id: str) -> Optional[Dict[str, Any]]:
        """获取同步状态"""
        task = self.sync_tasks.get(sync_id)
        if task:
            return task.to_dict()
        return None
    
    def list_sync_history(self, connector_id: str = None, 
                         limit: int = 50) -> List[Dict[str, Any]]:
        """列出同步历史"""
        tasks = list(self.sync_tasks.values())
        
        # 按连接器过滤
        if connector_id:
            tasks = [task for task in tasks if task.connector_id == connector_id]
        
        # 按开始时间排序（最新的在前）
        tasks.sort(key=lambda t: t.start_time, reverse=True)
        
        # 限制数量
        tasks = tasks[:limit]
        
        return [task.to_dict() for task in tasks]
    
    def cleanup_history(self, days: int = 30):
        """清理历史记录"""
        cutoff_time = datetime.now().timestamp() - (days * 24 * 3600)
        
        tasks_to_remove = []
        for sync_id, task in self.sync_tasks.items():
            task_time = datetime.fromisoformat(task.start_time).timestamp()
            if task_time < cutoff_time and task.status != SyncStatus.RUNNING.value:
                tasks_to_remove.append(sync_id)
        
        for sync_id in tasks_to_remove:
            del self.sync_tasks[sync_id]
        
        self.save_history()
        print(f"已清理 {len(tasks_to_remove)} 条历史记录")
    
    def save_history(self):
        """保存同步历史"""
        try:
            data = {sync_id: task.to_dict() for sync_id, task in self.sync_tasks.items()}
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"保存同步历史失败: {e}")
    
    def load_history(self):
        """加载同步历史"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                self.sync_tasks = {sync_id: SyncTask.from_dict(task_data) 
                                 for sync_id, task_data in data.items()}
                print(f"已加载 {len(self.sync_tasks)} 条同步历史")
        except Exception as e:
            print(f"加载同步历史失败: {e}")
            self.sync_tasks = {}
```

### 步骤5：创建API接口（15分钟）

创建文件 `api.py`：

```python
from fastapi import FastAPI, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import Dict, List, Any, Optional
import uvicorn
from connectors.database import DatabaseConnector
from connectors.api import APIConnector
from sync_manager import SyncManager, SyncType

app = FastAPI(title="结构化数据接入API", version="1.0.0")
sync_manager = SyncManager()

# Pydantic模型
class ConnectorConfig(BaseModel):
    connector_id: str
    connector_type: str  # "database" 或 "api"
    config: Dict[str, Any]

class SyncRequest(BaseModel):
    connector_id: str
    sync_type: str  # "full" 或 "incremental"
    config: Optional[Dict[str, Any]] = None

class SyncResponse(BaseModel):
    sync_id: str
    message: str

@app.get("/")
async def root():
    return {"message": "结构化数据接入系统 API"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "timestamp": "2024-01-01T00:00:00"}

# 连接器管理接口
@app.get("/connectors")
async def list_connectors():
    """获取所有连接器"""
    return sync_manager.list_connectors()

@app.post("/connectors")
async def add_connector(config: ConnectorConfig):
    """添加连接器"""
    try:
        if config.connector_type == "database":
            connector = DatabaseConnector(config.connector_id, config.config)
        elif config.connector_type == "api":
            connector = APIConnector(config.connector_id, config.config)
        else:
            raise HTTPException(status_code=400, detail=f"不支持的连接器类型: {config.connector_type}")
        
        # 测试连接
        if not await connector.test_connection():
            raise HTTPException(status_code=400, detail="连接器连接测试失败")
        
        sync_manager.register_connector(connector)
        return {"message": f"连接器 {config.connector_id} 添加成功"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/connectors/{connector_id}/test")
async def test_connector(connector_id: str):
    """测试连接器"""
    connector = sync_manager.get_connector(connector_id)
    if not connector:
        raise HTTPException(status_code=404, detail=f"连接器 {connector_id} 不存在")
    
    try:
        result = await connector.test_connection()
        return {"connector_id": connector_id, "connected": result}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# 同步管理接口
@app.post("/sync/start", response_model=SyncResponse)
async def start_sync(request: SyncRequest):
    """启动同步"""
    try:
        sync_type = SyncType.FULL if request.sync_type == "full" else SyncType.INCREMENTAL
        sync_id = await sync_manager.start_sync(
            request.connector_id, 
            sync_type, 
            request.config or {}
        )
        return SyncResponse(sync_id=sync_id, message="同步任务已启动")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/sync/status/{sync_id}")
async def get_sync_status(sync_id: str):
    """获取同步状态"""
    status = sync_manager.get_sync_status(sync_id)
    if not status:
        raise HTTPException(status_code=404, detail=f"同步任务 {sync_id} 不存在")
    return status

@app.get("/sync/history")
async def get_sync_history(connector_id: Optional[str] = None, limit: int = 50):
    """获取同步历史"""
    return sync_manager.list_sync_history(connector_id, limit)

@app.post("/sync/cancel/{sync_id}")
async def cancel_sync(sync_id: str):
    """取消同步"""
    result = await sync_manager.cancel_sync(sync_id)
    if not result:
        raise HTTPException(status_code=404, detail=f"同步任务 {sync_id} 不存在或未运行")
    return {"message": f"同步任务 {sync_id} 已取消"}

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8001)
```

### 步骤6：创建测试脚本（10分钟）

创建文件 `test_system.py`：

```python
import asyncio
import json
from connectors.database import DatabaseConnector
from connectors.api import APIConnector
from sync_manager import SyncManager, SyncType

async def test_api_connector():
    """测试API连接器"""
    print("\n=== 测试API连接器 ===")
    
    # 配置API连接器（使用公开的测试API）
    config = {
        'base_url': 'https://jsonplaceholder.typicode.com',
        'headers': {'Content-Type': 'application/json'},
        'timeout': 30,
        'max_retries': 3,
        'page_size': 10
    }
    
    connector = APIConnector('test_api', config)
    
    try:
        # 测试连接
        connected = await connector.connect()
        print(f"连接状态: {connected}")
        
        if connected:
            # 获取数据
            data = await connector.fetch_data('/posts', paginate=False)
            print(f"获取到 {len(data)} 条数据")
            if data:
                print(f"示例数据: {json.dumps(data[0], indent=2)}")
        
    except Exception as e:
        print(f"API连接器测试失败: {e}")
    
    finally:
        await connector.disconnect()

async def test_sync_manager():
    """测试同步管理器"""
    print("\n=== 测试同步管理器 ===")
    
    manager = SyncManager()
    
    # 创建API连接器
    api_config = {
        'base_url': 'https://jsonplaceholder.typicode.com',
        'headers': {'Content-Type': 'application/json'},
        'page_size': 5
    }
    
    api_connector = APIConnector('posts_api', api_config)
    manager.register_connector(api_connector)
    
    try:
        # 启动同步任务
        sync_id = await manager.start_sync(
            'posts_api', 
            SyncType.FULL, 
            {'endpoint': '/posts', 'paginate': False}
        )
        
        print(f"同步任务ID: {sync_id}")
        
        # 等待同步完成
        while True:
            status = manager.get_sync_status(sync_id)
            print(f"同步状态: {status['status']}, 进度: {status['processed_records']}/{status['total_records']}")
            
            if status['status'] in ['completed', 'failed', 'cancelled']:
                break
            
            await asyncio.sleep(1)
        
        # 显示最终状态
        final_status = manager.get_sync_status(sync_id)
        print(f"最终状态: {json.dumps(final_status, indent=2)}")
        
    except Exception as e:
        print(f"同步管理器测试失败: {e}")

async def main():
    """主测试函数"""
    print("开始测试结构化数据接入系统")
    
    await test_api_connector()
    await test_sync_manager()
    
    print("\n测试完成")

if __name__ == "__main__":
    asyncio.run(main())
```

## 实验验证

### 1. 运行测试脚本
```bash
python test_system.py
```

### 2. 启动API服务
```bash
python api.py
```

### 3. 测试API接口
```bash
# 添加API连接器
curl -X POST "http://localhost:8001/connectors" \
  -H "Content-Type: application/json" \
  -d '{
    "connector_id": "test_api",
    "connector_type": "api",
    "config": {
      "base_url": "https://jsonplaceholder.typicode.com",
      "headers": {"Content-Type": "application/json"}
    }
  }'

# 启动同步
curl -X POST "http://localhost:8001/sync/start" \
  -H "Content-Type: application/json" \
  -d '{
    "connector_id": "test_api",
    "sync_type": "full",
    "config": {"endpoint": "/posts"}
  }'
```

## 实验总结

通过本实验，你应该掌握了：

1. **数据连接器架构**：理解了抽象基类的设计和具体实现
2. **异步编程应用**：学会了在数据获取中使用异步编程
3. **同步管理**：实现了完整的同步任务生命周期管理
4. **API设计**：创建了RESTful API接口
5. **错误处理**：实现了重试机制和错误恢复

## 扩展练习

1. 实现一个文件连接器，支持CSV、JSON文件的读取
2. 添加数据转换功能，将结构化数据转换为文档格式
3. 实现WebSocket接口，提供实时的同步进度推送
4. 添加数据验证和清洗功能
5. 实现分布式同步，支持多个worker并行处理