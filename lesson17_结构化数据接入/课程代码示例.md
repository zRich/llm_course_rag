# 第17节课：结构化数据接入系统 - 课程代码示例

## 概述

本文档提供第17节课结构化数据接入系统的核心代码示例，包括数据连接器、同步管理器、API接口等关键组件的实现和使用方法。

## 目录结构

```
lesson17_structured_data/
├── connectors/
│   ├── __init__.py
│   ├── base.py              # 数据连接器基类
│   ├── database.py          # 数据库连接器
│   └── api.py              # API连接器
├── sync_manager.py          # 同步管理器
├── api.py                  # FastAPI接口
├── test_system.py          # 系统测试脚本
├── requirements.txt        # 依赖包列表
└── README.md              # 系统说明文档
```

## 核心代码示例

### 1. 数据连接器基类

```python
# connectors/base.py
from abc import ABC, abstractmethod
from typing import List, Dict, Any, Optional
import logging

class DataConnector(ABC):
    """数据连接器抽象基类
    
    定义了所有数据连接器必须实现的接口方法，
    包括连接管理、数据获取、增量同步等功能。
    """
    
    def __init__(self, connector_id: str, config: Dict[str, Any]):
        self.connector_id = connector_id
        self.config = config
        self.is_connected = False
        self.logger = logging.getLogger(f"{self.__class__.__name__}_{connector_id}")
    
    @abstractmethod
    async def connect(self) -> bool:
        """建立连接"""
        pass
    
    @abstractmethod
    async def disconnect(self):
        """断开连接"""
        pass
    
    @abstractmethod
    async def test_connection(self) -> bool:
        """测试连接"""
        pass
    
    @abstractmethod
    async def fetch_data(self, **kwargs) -> List[Dict[str, Any]]:
        """获取数据"""
        pass
    
    @abstractmethod
    async def get_incremental_data(self, last_sync_time: Optional[str] = None) -> List[Dict[str, Any]]:
        """获取增量数据"""
        pass
```

### 2. 数据库连接器使用示例

```python
# 数据库连接器配置示例
from connectors.database import DatabaseConnector

# PostgreSQL配置
postgres_config = {
    'type': 'postgresql',
    'host': 'localhost',
    'port': 5432,
    'database': 'mydb',
    'username': 'user',
    'password': 'password',
    'table': 'products',
    'incremental_field': 'updated_at',
    'batch_size': 1000
}

# 创建连接器
db_connector = DatabaseConnector('postgres_products', postgres_config)

# 使用示例
async def use_database_connector():
    # 建立连接
    await db_connector.connect()
    
    # 获取全量数据
    all_data = await db_connector.fetch_data(
        table='products',
        limit=100
    )
    
    # 获取增量数据
    incremental_data = await db_connector.get_incremental_data(
        last_sync_time='2024-01-01 00:00:00'
    )
    
    # 自定义查询
    custom_data = await db_connector.fetch_data(
        query="SELECT * FROM products WHERE price > 100"
    )
    
    # 断开连接
    await db_connector.disconnect()
```

### 3. API连接器使用示例

```python
# API连接器配置示例
from connectors.api import APIConnector

# REST API配置
api_config = {
    'base_url': 'https://api.example.com',
    'headers': {
        'Authorization': 'Bearer your-token',
        'Content-Type': 'application/json'
    },
    'timeout': 30,
    'max_retries': 3,
    'rate_limit': {'requests_per_second': 10},
    'page_size': 100,
    'page_param': 'page',
    'size_param': 'limit',
    'data_fields': ['data', 'items'],
    'incremental_endpoint': '/api/v1/products/updates',
    'time_param': 'since'
}

# 创建连接器
api_connector = APIConnector('products_api', api_config)

# 使用示例
async def use_api_connector():
    # 建立连接
    await api_connector.connect()
    
    # 获取分页数据
    all_products = await api_connector.fetch_data(
        endpoint='/api/v1/products',
        method='GET',
        paginate=True
    )
    
    # 获取增量数据
    updates = await api_connector.get_incremental_data(
        last_sync_time='2024-01-01T00:00:00Z'
    )
    
    # POST请求示例
    result = await api_connector.fetch_data(
        endpoint='/api/v1/search',
        method='POST',
        data={'query': 'electronics', 'category': 'products'},
        paginate=False
    )
    
    # 断开连接
    await api_connector.disconnect()
```

### 4. 同步管理器使用示例

```python
# 同步管理器使用示例
from sync_manager import SyncManager, SyncType
from connectors.database import DatabaseConnector
from connectors.api import APIConnector

async def sync_management_example():
    # 创建同步管理器
    manager = SyncManager(history_file='sync_history.json')
    
    # 注册数据库连接器
    db_connector = DatabaseConnector('products_db', {
        'type': 'postgresql',
        'host': 'localhost',
        'database': 'ecommerce',
        'username': 'user',
        'password': 'pass',
        'table': 'products'
    })
    manager.register_connector(db_connector)
    
    # 注册API连接器
    api_connector = APIConnector('orders_api', {
        'base_url': 'https://api.orders.com',
        'headers': {'Authorization': 'Bearer token'}
    })
    manager.register_connector(api_connector)
    
    # 启动全量同步
    sync_id = await manager.start_sync(
        connector_id='products_db',
        sync_type=SyncType.FULL,
        config={'limit': 1000}
    )
    
    print(f"同步任务已启动: {sync_id}")
    
    # 监控同步进度
    while True:
        status = manager.get_sync_status(sync_id)
        if status['status'] in ['completed', 'failed', 'cancelled']:
            break
        
        progress = status['processed_records'] / status['total_records'] * 100
        print(f"同步进度: {progress:.1f}%")
        await asyncio.sleep(1)
    
    # 查看同步历史
    history = manager.list_sync_history(limit=10)
    for task in history:
        print(f"任务: {task['sync_id']}, 状态: {task['status']}, 记录数: {task['total_records']}")
```

### 5. FastAPI接口使用示例

```python
# API接口使用示例
import requests
import json

# 服务器地址
BASE_URL = 'http://localhost:8001'

def api_usage_examples():
    # 1. 添加数据库连接器
    db_config = {
        'connector_id': 'products_db',
        'connector_type': 'database',
        'config': {
            'type': 'postgresql',
            'host': 'localhost',
            'database': 'ecommerce',
            'username': 'user',
            'password': 'password',
            'table': 'products'
        }
    }
    
    response = requests.post(f'{BASE_URL}/connectors', json=db_config)
    print(f"添加连接器: {response.json()}")
    
    # 2. 测试连接器
    response = requests.post(f'{BASE_URL}/connectors/products_db/test')
    print(f"连接测试: {response.json()}")
    
    # 3. 启动同步
    sync_request = {
        'connector_id': 'products_db',
        'sync_type': 'full',
        'config': {'limit': 500}
    }
    
    response = requests.post(f'{BASE_URL}/sync/start', json=sync_request)
    sync_result = response.json()
    sync_id = sync_result['sync_id']
    print(f"同步启动: {sync_result}")
    
    # 4. 查询同步状态
    response = requests.get(f'{BASE_URL}/sync/status/{sync_id}')
    print(f"同步状态: {response.json()}")
    
    # 5. 查看同步历史
    response = requests.get(f'{BASE_URL}/sync/history?limit=5')
    print(f"同步历史: {response.json()}")
    
    # 6. 列出所有连接器
    response = requests.get(f'{BASE_URL}/connectors')
    print(f"连接器列表: {response.json()}")
```

### 6. 数据转换示例

```python
# 数据转换器示例
from typing import Dict, Any, List
import json
from datetime import datetime

class DataTransformer:
    """数据转换器
    
    将结构化数据转换为适合RAG系统的文档格式
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.text_fields = config.get('text_fields', [])
        self.metadata_fields = config.get('metadata_fields', [])
        self.id_field = config.get('id_field', 'id')
    
    def transform_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        """转换单条记录"""
        # 提取文本内容
        text_parts = []
        for field in self.text_fields:
            if field in record and record[field]:
                text_parts.append(str(record[field]))
        
        content = ' '.join(text_parts)
        
        # 提取元数据
        metadata = {}
        for field in self.metadata_fields:
            if field in record:
                metadata[field] = record[field]
        
        # 添加转换时间戳
        metadata['transformed_at'] = datetime.now().isoformat()
        metadata['source_record_id'] = record.get(self.id_field)
        
        return {
            'id': f"{self.config.get('source_name', 'unknown')}_{record.get(self.id_field)}",
            'content': content,
            'metadata': metadata,
            'source': self.config.get('source_name', 'structured_data')
        }
    
    def transform_batch(self, records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """批量转换记录"""
        return [self.transform_record(record) for record in records]

# 使用示例
transformer_config = {
    'source_name': 'products',
    'text_fields': ['name', 'description', 'category'],
    'metadata_fields': ['price', 'brand', 'created_at', 'updated_at'],
    'id_field': 'product_id'
}

transformer = DataTransformer(transformer_config)

# 转换产品数据
product_records = [
    {
        'product_id': 1,
        'name': 'iPhone 15',
        'description': '最新款智能手机',
        'category': '电子产品',
        'price': 999.99,
        'brand': 'Apple',
        'created_at': '2024-01-01T00:00:00'
    }
]

transformed_docs = transformer.transform_batch(product_records)
print(json.dumps(transformed_docs[0], indent=2, ensure_ascii=False))
```

### 7. 错误处理和重试机制

```python
# 错误处理示例
import asyncio
from typing import Callable, Any
import logging

class RetryHandler:
    """重试处理器"""
    
    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):
        self.max_retries = max_retries
        self.base_delay = base_delay
        self.logger = logging.getLogger(self.__class__.__name__)
    
    async def retry_async(self, func: Callable, *args, **kwargs) -> Any:
        """异步重试装饰器"""
        last_exception = None
        
        for attempt in range(self.max_retries + 1):
            try:
                return await func(*args, **kwargs)
            except Exception as e:
                last_exception = e
                
                if attempt == self.max_retries:
                    self.logger.error(f"函数 {func.__name__} 执行失败，已重试 {self.max_retries} 次: {e}")
                    raise e
                
                delay = self.base_delay * (2 ** attempt)
                self.logger.warning(f"函数 {func.__name__} 执行失败，{delay}秒后重试 (第{attempt + 1}次): {e}")
                await asyncio.sleep(delay)
        
        raise last_exception

# 使用示例
retry_handler = RetryHandler(max_retries=3, base_delay=1.0)

async def unreliable_api_call():
    """模拟不稳定的API调用"""
    import random
    if random.random() < 0.7:  # 70%的失败率
        raise Exception("API调用失败")
    return "API调用成功"

# 带重试的API调用
result = await retry_handler.retry_async(unreliable_api_call)
print(result)
```

### 8. 配置管理示例

```python
# 配置管理示例
import json
import os
from typing import Dict, Any

class ConfigManager:
    """配置管理器"""
    
    def __init__(self, config_file: str = 'config.json'):
        self.config_file = config_file
        self.config = self.load_config()
    
    def load_config(self) -> Dict[str, Any]:
        """加载配置文件"""
        if os.path.exists(self.config_file):
            with open(self.config_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {}
    
    def save_config(self):
        """保存配置文件"""
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2, ensure_ascii=False)
    
    def get_connector_config(self, connector_id: str) -> Dict[str, Any]:
        """获取连接器配置"""
        return self.config.get('connectors', {}).get(connector_id, {})
    
    def set_connector_config(self, connector_id: str, config: Dict[str, Any]):
        """设置连接器配置"""
        if 'connectors' not in self.config:
            self.config['connectors'] = {}
        self.config['connectors'][connector_id] = config
        self.save_config()

# 配置文件示例 (config.json)
config_example = {
    "connectors": {
        "products_db": {
            "type": "database",
            "config": {
                "type": "postgresql",
                "host": "localhost",
                "database": "ecommerce",
                "username": "user",
                "password": "password",
                "table": "products",
                "incremental_field": "updated_at"
            }
        },
        "orders_api": {
            "type": "api",
            "config": {
                "base_url": "https://api.orders.com",
                "headers": {
                    "Authorization": "Bearer token"
                },
                "endpoints": {
                    "orders": "/api/v1/orders",
                    "incremental": "/api/v1/orders/updates"
                }
            }
        }
    },
    "sync_settings": {
        "default_batch_size": 1000,
        "max_concurrent_syncs": 3,
        "history_retention_days": 30
    }
}
```

## 最佳实践

### 1. 连接器设计原则
- 实现统一的抽象接口
- 支持异步操作
- 包含完善的错误处理
- 提供连接池管理
- 支持配置化参数

### 2. 同步策略
- 优先使用增量同步
- 实现断点续传
- 支持并发控制
- 记录详细的同步日志
- 提供进度监控

### 3. 性能优化
- 使用连接池
- 实现批量处理
- 支持分页获取
- 添加缓存机制
- 控制并发数量

### 4. 安全考虑
- 加密存储敏感信息
- 使用安全的连接协议
- 实现访问控制
- 记录操作审计日志
- 定期更新依赖包

## 扩展开发

### 1. 添加新的连接器类型
```python
# 文件连接器示例
class FileConnector(DataConnector):
    """文件连接器"""
    
    async def connect(self) -> bool:
        # 检查文件路径是否存在
        pass
    
    async def fetch_data(self, **kwargs) -> List[Dict[str, Any]]:
        # 读取CSV、JSON等文件
        pass
```

### 2. 自定义数据转换器
```python
# 自定义转换器
class CustomTransformer(DataTransformer):
    """自定义数据转换器"""
    
    def transform_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        # 实现特定的转换逻辑
        pass
```

### 3. 集成RAG系统
```python
# RAG系统集成示例
class RAGIntegration:
    """RAG系统集成"""
    
    def __init__(self, rag_client):
        self.rag_client = rag_client
    
    async def sync_to_rag(self, documents: List[Dict[str, Any]]):
        """将文档同步到RAG系统"""
        for doc in documents:
            await self.rag_client.add_document(doc)
```

这些代码示例展示了结构化数据接入系统的核心功能和使用方法，为学生提供了完整的实现参考和最佳实践指导。