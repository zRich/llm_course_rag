# 第十四节课：缓存策略 - 学生实验指导

## 实验概述

**实验时长**：15分钟  
**实验目标**：实现RAG系统的多层缓存策略，提升系统性能  
**实验环境**：Python 3.8+, Redis, 已完成前面课程的RAG系统搭建  

## 实验准备

### 1. 确认环境
确保你已经完成了前面课程的实验，特别是：
- 引用与可溯源输出系统
- 多文档处理系统
- 重排序模型集成

### 2. 安装Redis

**macOS用户**：
```bash
# 使用Homebrew安装Redis
brew install redis

# 启动Redis服务
brew services start redis

# 验证Redis是否正常运行
redis-cli ping
# 应该返回 PONG
```

**Linux用户**：
```bash
# Ubuntu/Debian
sudo apt update
sudo apt install redis-server

# 启动Redis服务
sudo systemctl start redis-server
sudo systemctl enable redis-server

# 验证Redis
redis-cli ping
```

**Windows用户**：
- 下载Redis for Windows或使用WSL
- 或使用Docker：`docker run -d -p 6379:6379 redis:alpine`

### 3. 安装Python依赖
```bash
# 进入rag-system目录
cd rag-system

# 安装Redis客户端
uv add redis
uv add hiredis  # 可选，提升性能
```

## 实验步骤

### 步骤1：创建lesson14分支

```bash
# 确保在rag-system目录
cd rag-system

# 从lesson13分支创建lesson14分支
git checkout lesson13
git checkout -b lesson14

echo "开始第14节课：缓存策略实验"
```

### 步骤2：实现缓存管理器

创建 `cache_manager.py`：

```python
import redis
import json
import time
import hashlib
from typing import Any, Optional, Dict
from dataclasses import dataclass
from datetime import datetime, timedelta

@dataclass
class CacheStats:
    """缓存统计信息"""
    hits: int = 0
    misses: int = 0
    total_requests: int = 0
    
    @property
    def hit_rate(self) -> float:
        """计算缓存命中率"""
        if self.total_requests == 0:
            return 0.0
        return self.hits / self.total_requests

class CacheManager:
    """多层缓存管理器"""
    
    def __init__(self, redis_host='localhost', redis_port=6379, redis_db=0):
        # Redis连接（L2缓存）
        try:
            self.redis_client = redis.Redis(
                host=redis_host, 
                port=redis_port, 
                db=redis_db,
                decode_responses=True
            )
            # 测试连接
            self.redis_client.ping()
            self.redis_available = True
            print("✅ Redis连接成功")
        except Exception as e:
            print(f"⚠️ Redis连接失败: {e}")
            self.redis_available = False
        
        # 本地内存缓存（L1缓存）
        self.local_cache: Dict[str, Dict] = {}
        self.local_cache_ttl: Dict[str, datetime] = {}
        
        # 缓存配置
        self.ttl_config = {
            'query_result': 3600,      # 查询结果1小时
            'vector_search': 7200,     # 向量检索2小时
            'document_content': 86400, # 文档内容24小时
            'rerank_scores': 1800      # 重排序分数30分钟
        }
        
        # 统计信息
        self.stats = CacheStats()
        
        # L1缓存大小限制
        self.max_local_cache_size = 1000
    
    def _generate_cache_key(self, prefix: str, data: Any) -> str:
        """生成缓存键"""
        if isinstance(data, str):
            content = data
        else:
            content = json.dumps(data, sort_keys=True)
        
        hash_obj = hashlib.md5(content.encode('utf-8'))
        return f"{prefix}:{hash_obj.hexdigest()}"
    
    def _cleanup_local_cache(self):
        """清理过期的本地缓存"""
        current_time = datetime.now()
        expired_keys = [
            key for key, ttl in self.local_cache_ttl.items()
            if ttl < current_time
        ]
        
        for key in expired_keys:
            self.local_cache.pop(key, None)
            self.local_cache_ttl.pop(key, None)
    
    def _evict_local_cache(self):
        """LRU淘汰本地缓存"""
        if len(self.local_cache) >= self.max_local_cache_size:
            # 简单的FIFO淘汰策略
            oldest_key = next(iter(self.local_cache))
            self.local_cache.pop(oldest_key, None)
            self.local_cache_ttl.pop(oldest_key, None)
    
    def get(self, cache_type: str, key_data: Any) -> Optional[Any]:
        """获取缓存数据"""
        self.stats.total_requests += 1
        cache_key = self._generate_cache_key(cache_type, key_data)
        
        # 清理过期的本地缓存
        self._cleanup_local_cache()
        
        # L1缓存检查
        if cache_key in self.local_cache:
            self.stats.hits += 1
            print(f"🎯 L1缓存命中: {cache_key[:20]}...")
            return self.local_cache[cache_key]
        
        # L2缓存检查（Redis）
        if self.redis_available:
            try:
                redis_result = self.redis_client.get(cache_key)
                if redis_result:
                    result = json.loads(redis_result)
                    
                    # 回填到L1缓存
                    self._evict_local_cache()
                    self.local_cache[cache_key] = result
                    ttl_seconds = self.ttl_config.get(cache_type, 3600)
                    self.local_cache_ttl[cache_key] = datetime.now() + timedelta(seconds=ttl_seconds)
                    
                    self.stats.hits += 1
                    print(f"🎯 L2缓存命中: {cache_key[:20]}...")
                    return result
            except Exception as e:
                print(f"Redis读取错误: {e}")
        
        # 缓存未命中
        self.stats.misses += 1
        print(f"❌ 缓存未命中: {cache_key[:20]}...")
        return None
    
    def set(self, cache_type: str, key_data: Any, value: Any) -> bool:
        """设置缓存数据"""
        cache_key = self._generate_cache_key(cache_type, key_data)
        ttl_seconds = self.ttl_config.get(cache_type, 3600)
        
        try:
            # 设置L2缓存（Redis）
            if self.redis_available:
                self.redis_client.setex(
                    cache_key, 
                    ttl_seconds, 
                    json.dumps(value)
                )
            
            # 设置L1缓存
            self._evict_local_cache()
            self.local_cache[cache_key] = value
            self.local_cache_ttl[cache_key] = datetime.now() + timedelta(seconds=ttl_seconds)
            
            print(f"💾 缓存已设置: {cache_key[:20]}...")
            return True
            
        except Exception as e:
            print(f"缓存设置错误: {e}")
            return False
    
    def delete(self, cache_type: str, key_data: Any) -> bool:
        """删除缓存数据"""
        cache_key = self._generate_cache_key(cache_type, key_data)
        
        try:
            # 删除L1缓存
            self.local_cache.pop(cache_key, None)
            self.local_cache_ttl.pop(cache_key, None)
            
            # 删除L2缓存
            if self.redis_available:
                self.redis_client.delete(cache_key)
            
            print(f"🗑️ 缓存已删除: {cache_key[:20]}...")
            return True
            
        except Exception as e:
            print(f"缓存删除错误: {e}")
            return False
    
    def clear_all(self) -> bool:
        """清空所有缓存"""
        try:
            # 清空L1缓存
            self.local_cache.clear()
            self.local_cache_ttl.clear()
            
            # 清空L2缓存
            if self.redis_available:
                self.redis_client.flushdb()
            
            print("🧹 所有缓存已清空")
            return True
            
        except Exception as e:
            print(f"清空缓存错误: {e}")
            return False
    
    def get_stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        return {
            'hit_rate': f"{self.stats.hit_rate:.2%}",
            'total_requests': self.stats.total_requests,
            'cache_hits': self.stats.hits,
            'cache_misses': self.stats.misses,
            'l1_cache_size': len(self.local_cache),
            'redis_available': self.redis_available
        }
    
    def print_stats(self):
        """打印缓存统计信息"""
        stats = self.get_stats()
        print("\n📊 缓存统计信息:")
        print(f"   命中率: {stats['hit_rate']}")
        print(f"   总请求数: {stats['total_requests']}")
        print(f"   缓存命中: {stats['cache_hits']}")
        print(f"   缓存未命中: {stats['cache_misses']}")
        print(f"   L1缓存大小: {stats['l1_cache_size']}")
        print(f"   Redis可用: {stats['redis_available']}")
```

### 步骤3：集成缓存到RAG系统

创建 `cached_rag_system.py`：

```python
import time
from typing import List, Dict, Any
from cache_manager import CacheManager

class CachedRAGSystem:
    """带缓存的RAG系统"""
    
    def __init__(self):
        self.cache_manager = CacheManager()
        print("🚀 缓存RAG系统初始化完成")
    
    def normalize_query(self, query: str) -> str:
        """标准化查询以提高缓存命中率"""
        import re
        # 去除多余空格、统一大小写
        normalized = re.sub(r'\s+', ' ', query.lower().strip())
        # 去除标点符号
        normalized = re.sub(r'[^\w\s]', '', normalized)
        return normalized
    
    def simulate_vector_search(self, query: str) -> List[Dict[str, Any]]:
        """模拟向量检索（实际应用中替换为真实的向量检索）"""
        print(f"🔍 执行向量检索: {query}")
        time.sleep(0.5)  # 模拟检索耗时
        
        # 模拟检索结果
        results = [
            {
                'id': f'doc_{i}',
                'content': f'这是关于"{query}"的文档内容 {i}',
                'score': 0.9 - i * 0.1,
                'metadata': {'source': f'document_{i}.pdf', 'page': i+1}
            }
            for i in range(3)
        ]
        return results
    
    def simulate_rerank(self, query: str, documents: List[Dict]) -> List[Dict[str, Any]]:
        """模拟重排序（实际应用中替换为真实的重排序）"""
        print(f"🔄 执行重排序: {len(documents)} 个文档")
        time.sleep(0.3)  # 模拟重排序耗时
        
        # 简单的重排序逻辑
        for doc in documents:
            doc['rerank_score'] = doc['score'] * 1.1
        
        return sorted(documents, key=lambda x: x['rerank_score'], reverse=True)
    
    def simulate_llm_generation(self, query: str, context_docs: List[Dict]) -> Dict[str, Any]:
        """模拟LLM生成（实际应用中替换为真实的LLM调用）"""
        print(f"🤖 执行LLM生成")
        time.sleep(1.0)  # 模拟LLM生成耗时
        
        # 模拟生成结果
        context_text = "\n".join([doc['content'] for doc in context_docs[:2]])
        answer = f"根据检索到的文档，关于"{query}"的回答是：{context_text[:100]}..."
        
        return {
            'answer': answer,
            'sources': [doc['metadata'] for doc in context_docs[:2]],
            'confidence': 0.85
        }
    
    def search_with_cache(self, query: str) -> Dict[str, Any]:
        """带缓存的RAG查询"""
        start_time = time.time()
        
        # 标准化查询
        normalized_query = self.normalize_query(query)
        print(f"\n🔍 处理查询: {query}")
        print(f"📝 标准化后: {normalized_query}")
        
        # 1. 检查完整结果缓存
        cached_result = self.cache_manager.get('query_result', normalized_query)
        if cached_result:
            elapsed_time = time.time() - start_time
            cached_result['response_time'] = f"{elapsed_time:.3f}s"
            cached_result['from_cache'] = True
            return cached_result
        
        # 2. 检查向量检索缓存
        cached_vector_results = self.cache_manager.get('vector_search', normalized_query)
        if cached_vector_results:
            print("📋 使用缓存的向量检索结果")
            vector_results = cached_vector_results
        else:
            vector_results = self.simulate_vector_search(normalized_query)
            self.cache_manager.set('vector_search', normalized_query, vector_results)
        
        # 3. 检查重排序缓存
        rerank_cache_key = f"{normalized_query}_{len(vector_results)}"
        cached_rerank_results = self.cache_manager.get('rerank_scores', rerank_cache_key)
        if cached_rerank_results:
            print("📋 使用缓存的重排序结果")
            reranked_results = cached_rerank_results
        else:
            reranked_results = self.simulate_rerank(normalized_query, vector_results)
            self.cache_manager.set('rerank_scores', rerank_cache_key, reranked_results)
        
        # 4. LLM生成（通常不缓存，因为可能需要实时性）
        final_result = self.simulate_llm_generation(normalized_query, reranked_results)
        
        # 5. 缓存完整结果
        elapsed_time = time.time() - start_time
        final_result['response_time'] = f"{elapsed_time:.3f}s"
        final_result['from_cache'] = False
        final_result['retrieved_docs'] = reranked_results
        
        self.cache_manager.set('query_result', normalized_query, final_result)
        
        return final_result
    
    def get_cache_stats(self):
        """获取缓存统计"""
        return self.cache_manager.get_stats()
    
    def clear_cache(self):
        """清空缓存"""
        return self.cache_manager.clear_all()
```

### 步骤4：创建测试脚本

创建 `test_cache_system.py`：

```python
import time
from cached_rag_system import CachedRAGSystem

def test_cache_performance():
    """测试缓存性能"""
    print("🧪 开始缓存性能测试\n")
    
    # 初始化系统
    rag_system = CachedRAGSystem()
    
    # 测试查询列表
    test_queries = [
        "什么是人工智能",
        "机器学习的基本原理",
        "深度学习和神经网络",
        "什么是人工智能",  # 重复查询
        "自然语言处理技术",
        "机器学习的基本原理",  # 重复查询
        "计算机视觉应用",
        "什么是人工智能",  # 再次重复
    ]
    
    print("📋 测试查询列表:")
    for i, query in enumerate(test_queries, 1):
        print(f"   {i}. {query}")
    print()
    
    # 执行测试
    total_time = 0
    results = []
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'='*50}")
        print(f"🔍 测试 {i}/{len(test_queries)}: {query}")
        print(f"{'='*50}")
        
        start_time = time.time()
        result = rag_system.search_with_cache(query)
        end_time = time.time()
        
        query_time = end_time - start_time
        total_time += query_time
        
        results.append({
            'query': query,
            'time': query_time,
            'from_cache': result.get('from_cache', False),
            'answer_length': len(result.get('answer', ''))
        })
        
        print(f"\n📊 查询结果:")
        print(f"   响应时间: {query_time:.3f}s")
        print(f"   来源: {'缓存' if result.get('from_cache') else '实时计算'}")
        print(f"   答案长度: {len(result.get('answer', ''))} 字符")
        
        # 显示缓存统计
        rag_system.cache_manager.print_stats()
        
        time.sleep(0.5)  # 短暂暂停
    
    # 最终统计
    print(f"\n{'='*60}")
    print("📈 最终测试统计")
    print(f"{'='*60}")
    
    cache_hits = sum(1 for r in results if r['from_cache'])
    cache_misses = len(results) - cache_hits
    avg_time = total_time / len(results)
    
    print(f"总查询数: {len(results)}")
    print(f"缓存命中: {cache_hits}")
    print(f"缓存未命中: {cache_misses}")
    print(f"缓存命中率: {cache_hits/len(results):.2%}")
    print(f"平均响应时间: {avg_time:.3f}s")
    print(f"总耗时: {total_time:.3f}s")
    
    # 详细结果
    print("\n📋 详细结果:")
    for i, result in enumerate(results, 1):
        status = "🎯缓存" if result['from_cache'] else "⚡计算"
        print(f"   {i}. {result['query'][:20]}... - {result['time']:.3f}s - {status}")
    
    return results

def test_cache_strategies():
    """测试不同缓存策略"""
    print("\n🔬 测试缓存策略效果\n")
    
    rag_system = CachedRAGSystem()
    
    # 测试查询标准化
    queries = [
        "什么是人工智能？",
        "什么是人工智能",
        "  什么是人工智能  ",
        "什么是人工智能！！！"
    ]
    
    print("🧪 测试查询标准化效果:")
    for query in queries:
        normalized = rag_system.normalize_query(query)
        print(f"   原始: '{query}'")
        print(f"   标准化: '{normalized}'")
        print()
    
    # 测试相同标准化查询的缓存命中
    print("🎯 测试标准化查询的缓存命中:")
    for i, query in enumerate(queries, 1):
        print(f"\n--- 查询 {i} ---")
        result = rag_system.search_with_cache(query)
        print(f"来源: {'缓存' if result.get('from_cache') else '实时计算'}")
    
    rag_system.cache_manager.print_stats()

def main():
    """主测试函数"""
    print("🚀 RAG缓存系统测试开始\n")
    
    try:
        # 测试1：基本缓存性能
        test_cache_performance()
        
        # 测试2：缓存策略
        test_cache_strategies()
        
        print("\n✅ 所有测试完成！")
        
    except KeyboardInterrupt:
        print("\n⏹️ 测试被用户中断")
    except Exception as e:
        print(f"\n❌ 测试过程中出现错误: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
```

### 步骤5：运行测试

```bash
# 运行缓存系统测试
python test_cache_system.py
```

### 步骤6：性能对比测试

创建 `performance_comparison.py`：

```python
import time
import statistics
from cached_rag_system import CachedRAGSystem

def simulate_no_cache_system(query: str) -> dict:
    """模拟无缓存的RAG系统"""
    print(f"🔍 无缓存查询: {query}")
    
    # 模拟各个步骤的耗时
    time.sleep(0.5)  # 向量检索
    time.sleep(0.3)  # 重排序
    time.sleep(1.0)  # LLM生成
    
    return {
        'answer': f'关于"{query}"的回答（无缓存）',
        'from_cache': False
    }

def performance_comparison():
    """性能对比测试"""
    print("⚡ 缓存vs无缓存性能对比测试\n")
    
    # 初始化缓存系统
    cached_system = CachedRAGSystem()
    
    # 测试查询
    test_queries = [
        "什么是机器学习",
        "深度学习原理",
        "自然语言处理",
        "什么是机器学习",  # 重复
        "计算机视觉",
        "深度学习原理",   # 重复
        "什么是机器学习",  # 再次重复
    ]
    
    # 无缓存测试
    print("🚫 无缓存系统测试:")
    no_cache_times = []
    
    for i, query in enumerate(test_queries, 1):
        start_time = time.time()
        result = simulate_no_cache_system(query)
        end_time = time.time()
        
        query_time = end_time - start_time
        no_cache_times.append(query_time)
        
        print(f"   {i}. {query} - {query_time:.3f}s")
    
    # 缓存系统测试
    print("\n💾 缓存系统测试:")
    cached_times = []
    
    for i, query in enumerate(test_queries, 1):
        start_time = time.time()
        result = cached_system.search_with_cache(query)
        end_time = time.time()
        
        query_time = end_time - start_time
        cached_times.append(query_time)
        
        status = "🎯缓存" if result.get('from_cache') else "⚡计算"
        print(f"   {i}. {query} - {query_time:.3f}s - {status}")
    
    # 统计对比
    print("\n📊 性能对比统计:")
    print(f"{'指标':<15} {'无缓存':<10} {'有缓存':<10} {'提升':<10}")
    print("-" * 50)
    
    # 总时间
    total_no_cache = sum(no_cache_times)
    total_cached = sum(cached_times)
    improvement = (total_no_cache - total_cached) / total_no_cache * 100
    
    print(f"{'总时间':<15} {total_no_cache:<10.3f} {total_cached:<10.3f} {improvement:<10.1f}%")
    
    # 平均时间
    avg_no_cache = statistics.mean(no_cache_times)
    avg_cached = statistics.mean(cached_times)
    avg_improvement = (avg_no_cache - avg_cached) / avg_no_cache * 100
    
    print(f"{'平均时间':<15} {avg_no_cache:<10.3f} {avg_cached:<10.3f} {avg_improvement:<10.1f}%")
    
    # 缓存统计
    cache_stats = cached_system.get_cache_stats()
    print(f"\n🎯 缓存命中率: {cache_stats['hit_rate']}")
    print(f"📈 总请求数: {cache_stats['total_requests']}")
    
    return {
        'no_cache_times': no_cache_times,
        'cached_times': cached_times,
        'improvement': improvement,
        'cache_stats': cache_stats
    }

if __name__ == "__main__":
    performance_comparison()
```

## 实验验证

### 1. 运行性能对比
```bash
python performance_comparison.py
```

### 2. 检查Redis缓存
```bash
# 连接Redis查看缓存数据
redis-cli

# 查看所有键
KEYS *

# 查看特定键的值
GET query_result:xxxxx

# 查看键的TTL
TTL query_result:xxxxx

# 退出
EXIT
```

### 3. 监控缓存性能
创建 `cache_monitor.py`：

```python
import time
from cached_rag_system import CachedRAGSystem

def monitor_cache_performance():
    """监控缓存性能"""
    rag_system = CachedRAGSystem()
    
    queries = [
        "人工智能发展历史",
        "机器学习算法分类", 
        "深度学习网络结构",
        "人工智能发展历史",  # 重复
        "自然语言处理应用",
        "机器学习算法分类",  # 重复
    ]
    
    print("📊 实时缓存性能监控\n")
    
    for i, query in enumerate(queries, 1):
        print(f"\n--- 查询 {i} ---")
        
        # 执行查询
        start_time = time.time()
        result = rag_system.search_with_cache(query)
        end_time = time.time()
        
        # 显示结果
        print(f"查询: {query}")
        print(f"耗时: {end_time - start_time:.3f}s")
        print(f"来源: {'缓存' if result.get('from_cache') else '实时计算'}")
        
        # 显示实时统计
        stats = rag_system.get_cache_stats()
        print(f"当前命中率: {stats['hit_rate']}")
        print(f"L1缓存大小: {stats['l1_cache_size']}")
        
        time.sleep(1)

if __name__ == "__main__":
    monitor_cache_performance()
```

## 实验总结

### 预期结果
完成实验后，你应该观察到：

1. **性能提升**：
   - 缓存命中的查询响应时间显著降低
   - 重复查询几乎瞬时返回结果
   - 整体系统吞吐量提升50%以上

2. **缓存效果**：
   - 缓存命中率逐步提升
   - L1和L2缓存协同工作
   - 内存使用合理，无明显泄漏

3. **系统稳定性**：
   - Redis连接稳定
   - 缓存失效机制正常工作
   - 错误处理机制有效

### 常见问题

**Q1: Redis连接失败怎么办？**
A1: 检查Redis服务是否启动，端口是否正确，防火墙设置等。

**Q2: 缓存命中率很低怎么办？**
A2: 检查查询标准化逻辑，调整TTL设置，增加预热数据。

**Q3: 内存使用过高怎么办？**
A3: 调整L1缓存大小限制，优化数据结构，增加清理频率。

### 扩展实验

1. **实现缓存预热**：在系统启动时预加载热门查询
2. **添加缓存监控**：实现详细的性能指标收集
3. **优化缓存策略**：实现更智能的LRU算法
4. **分布式缓存**：配置Redis集群测试

## 提交要求

请提交以下文件：
- `cache_manager.py` - 缓存管理器实现
- `cached_rag_system.py` - 集成缓存的RAG系统
- `test_cache_system.py` - 基础测试脚本
- `performance_comparison.py` - 性能对比测试
- 测试运行截图和性能数据
- 实验总结报告（包含性能提升数据和问题分析）

---

**实验完成标志**：
✅ 缓存系统正常运行  
✅ 性能提升达到预期  
✅ 缓存命中率>60%  
✅ 所有测试通过