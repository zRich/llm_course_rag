#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAGç³»ç»Ÿå®¹é”™é›†æˆæ¼”ç¤º
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from src.fault_injection import fault_injection_decorator, FaultType
from src.recovery import (
    retry_with_backoff, RetryStrategy,
    CircuitBreaker, FallbackService, FallbackStrategy
)
from src.monitoring import global_metrics_collector, global_alert_manager
import time
import random

class RobustRAGService:
    """å®¹é”™çš„RAGæœåŠ¡"""
    
    def __init__(self):
        self.vector_circuit_breaker = CircuitBreaker(failure_threshold=3)
        self.llm_circuit_breaker = CircuitBreaker(failure_threshold=2)
        self.fallback_service = FallbackService()
        self.fallback_service.configure(FallbackStrategy.CACHE, cache_ttl=300)
        
        # åˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†
        self.metrics = global_metrics_collector
        
        print("ğŸ¤– RobustRAGService åˆå§‹åŒ–å®Œæˆ")
    
    @fault_injection_decorator(FaultType.NETWORK_TIMEOUT, probability=0.1)
    @retry_with_backoff(max_attempts=3, strategy=RetryStrategy.EXPONENTIAL_BACKOFF)
    def query_vector_store(self, query):
        """æŸ¥è¯¢å‘é‡å­˜å‚¨"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿå‘é‡æŸ¥è¯¢
            if random.random() < 0.2:  # 20%å¤±è´¥ç‡
                raise Exception("å‘é‡å­˜å‚¨æŸ¥è¯¢å¤±è´¥")
            
            # æ¨¡æ‹ŸæŸ¥è¯¢å»¶è¿Ÿ
            time.sleep(random.uniform(0.1, 0.5))
            
            docs = [
                f"æ–‡æ¡£1: å…³äº{query}çš„ç›¸å…³å†…å®¹...",
                f"æ–‡æ¡£2: {query}çš„è¯¦ç»†è¯´æ˜...",
                f"æ–‡æ¡£3: {query}çš„åº”ç”¨æ¡ˆä¾‹..."
            ]
            
            # è®°å½•æˆåŠŸæŒ‡æ ‡
            duration = time.time() - start_time
            self.metrics.record_timer("vector_query_duration", duration)
            self.metrics.record_counter("vector_queries_total", 1, {"status": "success"})
            
            return docs
            
        except Exception as e:
            # è®°å½•å¤±è´¥æŒ‡æ ‡
            duration = time.time() - start_time
            self.metrics.record_timer("vector_query_duration", duration)
            self.metrics.record_counter("vector_queries_total", 1, {"status": "error"})
            raise e
    
    @fault_injection_decorator(FaultType.SLOW_RESPONSE, probability=0.15)
    def generate_response(self, context, query):
        """ç”Ÿæˆå›ç­”"""
        start_time = time.time()
        
        try:
            # ä½¿ç”¨ç†”æ–­å™¨ä¿æŠ¤LLMè°ƒç”¨
            def llm_call():
                if random.random() < 0.25:  # 25%å¤±è´¥ç‡
                    raise Exception("LLMæœåŠ¡ä¸å¯ç”¨")
                
                # æ¨¡æ‹ŸLLMå¤„ç†æ—¶é—´
                time.sleep(random.uniform(0.2, 1.0))
                
                return f"åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ï¼Œå…³äº'{query}'çš„å›ç­”æ˜¯ï¼šè¿™æ˜¯ä¸€ä¸ªè¯¦ç»†çš„è§£ç­”ï¼Œç»“åˆäº†ç›¸å…³æ–‡æ¡£çš„ä¿¡æ¯ã€‚"
            
            response = self.llm_circuit_breaker.call(llm_call)
            
            # è®°å½•æˆåŠŸæŒ‡æ ‡
            duration = time.time() - start_time
            self.metrics.record_timer("llm_response_duration", duration)
            self.metrics.record_counter("llm_calls_total", 1, {"status": "success"})
            
            return response
            
        except Exception as e:
            # è®°å½•å¤±è´¥æŒ‡æ ‡
            duration = time.time() - start_time
            self.metrics.record_timer("llm_response_duration", duration)
            self.metrics.record_counter("llm_calls_total", 1, {"status": "error"})
            raise e
    
    def search_with_fallback(self, query):
        """å¸¦é™çº§çš„æœç´¢"""
        def primary_search():
            # æŸ¥è¯¢å‘é‡å­˜å‚¨
            docs = self.query_vector_store(query)
            
            # ç”Ÿæˆå›ç­”
            response = self.generate_response(docs, query)
            
            return {
                "success": True,
                "response": response,
                "source": "primary",
                "documents": len(docs)
            }
        
        # ä½¿ç”¨é™çº§æœåŠ¡
        try:
            result = self.fallback_service.execute_with_fallback(
                f"search_{hash(query) % 1000}",  # ç®€å•çš„ç¼“å­˜é”®
                primary_search,
                default_value={
                    "success": True,
                    "response": f"æŠ±æ­‰ï¼Œç”±äºç³»ç»Ÿç¹å¿™ï¼Œæ— æ³•æä¾›å…³äº'{query}'çš„è¯¦ç»†å›ç­”ã€‚è¯·ç¨åé‡è¯•ã€‚",
                    "source": "fallback",
                    "documents": 0
                }
            )
            
            # è®°å½•æœç´¢æŒ‡æ ‡
            self.metrics.record_counter("searches_total", 1, {"source": result["source"]})
            
            return result
            
        except Exception as e:
            # æœ€ç»ˆé™çº§
            self.metrics.record_counter("searches_total", 1, {"source": "error"})
            return {
                "success": False,
                "error": str(e),
                "response": "ç³»ç»Ÿæš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                "source": "error"
            }

def demo_rag_integration():
    """æ¼”ç¤ºRAGç³»ç»Ÿé›†æˆ"""
    print("=== RAGç³»ç»Ÿå®¹é”™é›†æˆæ¼”ç¤º ===")
    
    # åˆ›å»ºå®¹é”™RAGæœåŠ¡
    rag_service = RobustRAGService()
    
    # æµ‹è¯•æŸ¥è¯¢
    queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "æ·±åº¦å­¦ä¹ çš„åº”ç”¨åœºæ™¯",
        "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯",
        "æ¨èç³»ç»Ÿç®—æ³•",
        "è®¡ç®—æœºè§†è§‰å‘å±•",
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",  # é‡å¤æŸ¥è¯¢æµ‹è¯•ç¼“å­˜
        "äººå·¥æ™ºèƒ½ä¼¦ç†",
        "å¤§æ•°æ®åˆ†ææ–¹æ³•"
    ]
    
    print(f"ğŸ” å¼€å§‹æ‰§è¡Œ {len(queries)} ä¸ªæŸ¥è¯¢...\n")
    
    for i, query in enumerate(queries):
        print(f"ğŸ“ æŸ¥è¯¢ {i+1}: {query}")
        
        start_time = time.time()
        result = rag_service.search_with_fallback(query)
        duration = time.time() - start_time
        
        if result["success"]:
            source_icon = {
                "primary": "ğŸ¯",
                "fallback": "ğŸ”„",
                "cache": "ğŸ’¾"
            }.get(result["source"], "â“")
            
            print(f"   {source_icon} æˆåŠŸ ({result['source']}) - è€—æ—¶: {duration:.2f}s")
            print(f"   ğŸ“„ æ–‡æ¡£æ•°: {result.get('documents', 0)}")
            print(f"   ğŸ’¬ å›ç­”: {result['response'][:100]}...")
        else:
            print(f"   âŒ å¤±è´¥ - {result['error']} (è€—æ—¶: {duration:.2f}s)")
            print(f"   ğŸ’¬ é™çº§å›ç­”: {result['response']}")
        
        print()
        time.sleep(0.5)
    
    # æ˜¾ç¤ºæœåŠ¡ç»Ÿè®¡
    print("ğŸ“Š æœåŠ¡ç»Ÿè®¡:")
    
    # ç†”æ–­å™¨çŠ¶æ€
    print(f"   ğŸ”Œ å‘é‡å­˜å‚¨ç†”æ–­å™¨: {rag_service.vector_circuit_breaker.state.value}")
    print(f"   ğŸ¤– LLMç†”æ–­å™¨: {rag_service.llm_circuit_breaker.state.value}")
    
    # é™çº§æœåŠ¡ç»Ÿè®¡
    fallback_stats = rag_service.fallback_service.get_statistics()
    print(f"   ğŸ”„ é™çº§æœåŠ¡è°ƒç”¨: {fallback_stats['total_calls']}")
    print(f"   ğŸ’¾ ç¼“å­˜å‘½ä¸­: {fallback_stats['cache_hits']}")
    
    # æŒ‡æ ‡ç»Ÿè®¡
    metrics = rag_service.metrics.get_metrics_summary()
    print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
    for name, data in metrics.items():
        if 'count' in data:
            print(f"   {name}: {data['count']} æ¬¡")
        elif 'avg' in data:
            print(f"   {name}: å¹³å‡ {data['avg']:.2f}s")

if __name__ == "__main__":
    demo_rag_integration()
    
    print("\nğŸ¯ å®éªŒå››å®Œæˆï¼RAGç³»ç»Ÿå®¹é”™æœºåˆ¶é›†æˆæ¼”ç¤ºç»“æŸã€‚")