#!/usr/bin/env python3
"""
å®éªŒå››ï¼šæ€§èƒ½æµ‹è¯•æ¼”ç¤ºï¼ˆç®€åŒ–ç‰ˆï¼‰

æœ¬å®éªŒæ¼”ç¤ºè´Ÿè½½æµ‹è¯•ã€å‹åŠ›æµ‹è¯•å’Œæ€§èƒ½åˆ†æåŠŸèƒ½ã€‚
"""

import time
import random
import threading
from enum import Enum
from typing import Dict, List, Any, Optional, Callable
from dataclasses import dataclass, field
from collections import defaultdict, deque
import statistics
import concurrent.futures

# æµ‹è¯•ç±»å‹
class TestType(Enum):
    LOAD_TEST = "load_test"        # è´Ÿè½½æµ‹è¯•
    STRESS_TEST = "stress_test"    # å‹åŠ›æµ‹è¯•
    SPIKE_TEST = "spike_test"      # å³°å€¼æµ‹è¯•
    VOLUME_TEST = "volume_test"    # å®¹é‡æµ‹è¯•

# æµ‹è¯•çŠ¶æ€
class TestStatus(Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"

@dataclass
class TestResult:
    """æµ‹è¯•ç»“æœ"""
    request_id: str
    start_time: float
    end_time: float
    duration: float
    success: bool
    error_message: Optional[str] = None
    response_size: int = 0

@dataclass
class TestConfig:
    """æµ‹è¯•é…ç½®"""
    test_type: TestType
    concurrent_users: int
    requests_per_user: int
    ramp_up_time: float  # å¯åŠ¨æ—¶é—´ï¼ˆç§’ï¼‰
    test_duration: float  # æµ‹è¯•æŒç»­æ—¶é—´ï¼ˆç§’ï¼‰
    think_time: float = 0.0  # ç”¨æˆ·æ€è€ƒæ—¶é—´ï¼ˆç§’ï¼‰

class SimplePerformanceTester:
    """ç®€åŒ–çš„æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.results: List[TestResult] = []
        self.active_users = 0
        self.total_requests = 0
        self.successful_requests = 0
        self.failed_requests = 0
        self.start_time = 0
        self.end_time = 0
        self._lock = threading.RLock()
        self.status = TestStatus.PENDING
    
    def run_test(self, target_func: Callable, config: TestConfig, test_data: List[Any] = None):
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        print(f"ğŸš€ å¼€å§‹ {config.test_type.value} æµ‹è¯•")
        print(f"   å¹¶å‘ç”¨æˆ·: {config.concurrent_users}")
        print(f"   æ¯ç”¨æˆ·è¯·æ±‚æ•°: {config.requests_per_user}")
        print(f"   å¯åŠ¨æ—¶é—´: {config.ramp_up_time}s")
        print(f"   æµ‹è¯•æŒç»­æ—¶é—´: {config.test_duration}s")
        print("\n" + "="*50)
        
        self.status = TestStatus.RUNNING
        self.start_time = time.time()
        
        try:
            # å‡†å¤‡æµ‹è¯•æ•°æ®
            if test_data is None:
                test_data = [f"test_query_{i}" for i in range(config.requests_per_user * config.concurrent_users)]
            
            # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå¹¶å‘æµ‹è¯•
            with concurrent.futures.ThreadPoolExecutor(max_workers=config.concurrent_users) as executor:
                futures = []
                
                for user_id in range(config.concurrent_users):
                    # è®¡ç®—ç”¨æˆ·å¯åŠ¨å»¶è¿Ÿ
                    start_delay = (config.ramp_up_time / config.concurrent_users) * user_id
                    
                    future = executor.submit(
                        self._simulate_user,
                        user_id,
                        target_func,
                        config,
                        test_data[user_id * config.requests_per_user:(user_id + 1) * config.requests_per_user],
                        start_delay
                    )
                    futures.append(future)
                
                # ç­‰å¾…æ‰€æœ‰ç”¨æˆ·å®Œæˆ
                concurrent.futures.wait(futures, timeout=config.test_duration + config.ramp_up_time + 30)
            
            self.end_time = time.time()
            self.status = TestStatus.COMPLETED
            
        except Exception as e:
            self.end_time = time.time()
            self.status = TestStatus.FAILED
            print(f"âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
            raise e
    
    def _simulate_user(self, user_id: int, target_func: Callable, config: TestConfig, 
                      user_data: List[Any], start_delay: float):
        """æ¨¡æ‹Ÿå•ä¸ªç”¨æˆ·è¡Œä¸º"""
        # ç­‰å¾…å¯åŠ¨å»¶è¿Ÿ
        time.sleep(start_delay)
        
        with self._lock:
            self.active_users += 1
        
        print(f"ğŸ‘¤ ç”¨æˆ· {user_id} å¼€å§‹æµ‹è¯• (å»¶è¿Ÿ {start_delay:.2f}s)")
        
        try:
            for i, data in enumerate(user_data):
                request_id = f"user_{user_id}_req_{i}"
                
                # æ‰§è¡Œè¯·æ±‚
                result = self._execute_request(request_id, target_func, data)
                
                with self._lock:
                    self.results.append(result)
                    self.total_requests += 1
                    if result.success:
                        self.successful_requests += 1
                    else:
                        self.failed_requests += 1
                
                # ç”¨æˆ·æ€è€ƒæ—¶é—´
                if config.think_time > 0:
                    time.sleep(config.think_time)
                
                # æ£€æŸ¥æµ‹è¯•æ˜¯å¦åº”è¯¥ç»“æŸ
                if time.time() - self.start_time > config.test_duration:
                    break
        
        finally:
            with self._lock:
                self.active_users -= 1
            print(f"ğŸ‘¤ ç”¨æˆ· {user_id} å®Œæˆæµ‹è¯•")
    
    def _execute_request(self, request_id: str, target_func: Callable, data: Any) -> TestResult:
        """æ‰§è¡Œå•ä¸ªè¯·æ±‚"""
        start_time = time.time()
        
        try:
            response = target_func(data)
            end_time = time.time()
            
            return TestResult(
                request_id=request_id,
                start_time=start_time,
                end_time=end_time,
                duration=end_time - start_time,
                success=True,
                response_size=len(str(response)) if response else 0
            )
        
        except Exception as e:
            end_time = time.time()
            
            return TestResult(
                request_id=request_id,
                start_time=start_time,
                end_time=end_time,
                duration=end_time - start_time,
                success=False,
                error_message=str(e)
            )
    
    def get_statistics(self) -> Dict[str, Any]:
        """è·å–æµ‹è¯•ç»Ÿè®¡ä¿¡æ¯"""
        if not self.results:
            return {}
        
        # æˆåŠŸè¯·æ±‚çš„å“åº”æ—¶é—´
        successful_durations = [r.duration for r in self.results if r.success]
        all_durations = [r.duration for r in self.results]
        
        # è®¡ç®—ååé‡
        test_duration = self.end_time - self.start_time if self.end_time > self.start_time else 1
        throughput = len(self.results) / test_duration
        
        stats = {
            'total_requests': self.total_requests,
            'successful_requests': self.successful_requests,
            'failed_requests': self.failed_requests,
            'success_rate': (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0,
            'test_duration': test_duration,
            'throughput': throughput,
            'concurrent_users_peak': max([self.active_users, len(set(r.request_id.split('_')[1] for r in self.results))])
        }
        
        if successful_durations:
            stats.update({
                'avg_response_time': statistics.mean(successful_durations),
                'min_response_time': min(successful_durations),
                'max_response_time': max(successful_durations),
                'median_response_time': statistics.median(successful_durations),
                'p95_response_time': self._percentile(successful_durations, 95),
                'p99_response_time': self._percentile(successful_durations, 99)
            })
        
        if all_durations:
            stats['avg_response_time_all'] = statistics.mean(all_durations)
        
        return stats
    
    def _percentile(self, data: List[float], percentile: float) -> float:
        """è®¡ç®—ç™¾åˆ†ä½æ•°"""
        if not data:
            return 0.0
        
        sorted_data = sorted(data)
        index = int(len(sorted_data) * percentile / 100)
        if index >= len(sorted_data):
            index = len(sorted_data) - 1
        return sorted_data[index]
    
    def get_error_summary(self) -> Dict[str, int]:
        """è·å–é”™è¯¯æ±‡æ€»"""
        error_counts = defaultdict(int)
        
        for result in self.results:
            if not result.success and result.error_message:
                error_counts[result.error_message] += 1
        
        return dict(error_counts)
    
    def reset(self):
        """é‡ç½®æµ‹è¯•å™¨"""
        with self._lock:
            self.results.clear()
            self.active_users = 0
            self.total_requests = 0
            self.successful_requests = 0
            self.failed_requests = 0
            self.start_time = 0
            self.end_time = 0
            self.status = TestStatus.PENDING

# æ¨¡æ‹Ÿç›®æ ‡æœåŠ¡
class MockRAGService:
    """æ¨¡æ‹ŸRAGæœåŠ¡ï¼ˆç”¨äºæ€§èƒ½æµ‹è¯•ï¼‰"""
    
    def __init__(self):
        self.request_count = 0
        self.overload_threshold = 50  # è¿‡è½½é˜ˆå€¼
        self._lock = threading.RLock()
    
    def process_query(self, query: str) -> str:
        """å¤„ç†æŸ¥è¯¢"""
        with self._lock:
            self.request_count += 1
            current_load = self.request_count
        
        # æ¨¡æ‹Ÿå¤„ç†æ—¶é—´ï¼ˆéšè´Ÿè½½å¢åŠ ï¼‰
        base_time = 0.1
        load_factor = min(current_load / self.overload_threshold, 3.0)
        processing_time = base_time * (1 + load_factor) + random.uniform(0, 0.1)
        
        time.sleep(processing_time)
        
        # æ¨¡æ‹Ÿåœ¨é«˜è´Ÿè½½ä¸‹çš„é”™è¯¯
        if current_load > self.overload_threshold:
            error_rate = min((current_load - self.overload_threshold) / self.overload_threshold * 0.3, 0.5)
            if random.random() < error_rate:
                raise Exception(f"Service overloaded (load: {current_load})")
        
        # æ¨¡æ‹Ÿéšæœºé”™è¯¯
        if random.random() < 0.05:  # 5% éšæœºé”™è¯¯ç‡
            raise Exception("Random service error")
        
        with self._lock:
            self.request_count = max(0, self.request_count - 1)
        
        return f"Processed: {query} (load: {current_load})"
    
    def reset_load(self):
        """é‡ç½®è´Ÿè½½è®¡æ•°"""
        with self._lock:
            self.request_count = 0

def run_performance_demo():
    """è¿è¡Œæ€§èƒ½æµ‹è¯•æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸƒ æ€§èƒ½æµ‹è¯•æ¼”ç¤ºå®éªŒ")
    print("=" * 60)
    
    # åˆ›å»ºæœåŠ¡å’Œæµ‹è¯•å™¨
    rag_service = MockRAGService()
    tester = SimplePerformanceTester()
    
    # æµ‹è¯•åœºæ™¯
    test_scenarios = [
        {
            'name': 'è´Ÿè½½æµ‹è¯•',
            'config': TestConfig(
                test_type=TestType.LOAD_TEST,
                concurrent_users=5,
                requests_per_user=4,
                ramp_up_time=2.0,
                test_duration=10.0,
                think_time=0.5
            )
        },
        {
            'name': 'å‹åŠ›æµ‹è¯•',
            'config': TestConfig(
                test_type=TestType.STRESS_TEST,
                concurrent_users=10,
                requests_per_user=3,
                ramp_up_time=1.0,
                test_duration=8.0,
                think_time=0.2
            )
        }
    ]
    
    # æ‰§è¡Œæµ‹è¯•åœºæ™¯
    for i, scenario in enumerate(test_scenarios, 1):
        print(f"\nğŸ¯ åœºæ™¯ {i}: {scenario['name']}")
        print("-" * 40)
        
        # é‡ç½®æœåŠ¡å’Œæµ‹è¯•å™¨
        rag_service.reset_load()
        tester.reset()
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_queries = [
            "æœºå™¨å­¦ä¹ åŸºç¡€", "æ·±åº¦å­¦ä¹ åŸç†", "è‡ªç„¶è¯­è¨€å¤„ç†", "è®¡ç®—æœºè§†è§‰",
            "æ¨èç³»ç»Ÿ", "å¼ºåŒ–å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "æ•°æ®æŒ–æ˜",
            "æ¨¡å¼è¯†åˆ«", "çŸ¥è¯†å›¾è°±", "è¯­éŸ³è¯†åˆ«", "å›¾åƒåˆ†ç±»"
        ]
        
        try:
            # è¿è¡Œæµ‹è¯•
            tester.run_test(
                target_func=rag_service.process_query,
                config=scenario['config'],
                test_data=test_queries * 10  # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æµ‹è¯•æ•°æ®
            )
            
            # æ˜¾ç¤ºç»“æœ
            print(f"\nğŸ“Š {scenario['name']} ç»“æœ:")
            stats = tester.get_statistics()
            
            print(f"  æ€»è¯·æ±‚æ•°: {stats.get('total_requests', 0)}")
            print(f"  æˆåŠŸè¯·æ±‚: {stats.get('successful_requests', 0)}")
            print(f"  å¤±è´¥è¯·æ±‚: {stats.get('failed_requests', 0)}")
            print(f"  æˆåŠŸç‡: {stats.get('success_rate', 0):.1f}%")
            print(f"  æµ‹è¯•æ—¶é•¿: {stats.get('test_duration', 0):.2f}s")
            print(f"  ååé‡: {stats.get('throughput', 0):.2f} req/s")
            
            if 'avg_response_time' in stats:
                print(f"\n  å“åº”æ—¶é—´ç»Ÿè®¡:")
                print(f"    å¹³å‡: {stats['avg_response_time']:.3f}s")
                print(f"    æœ€å°: {stats['min_response_time']:.3f}s")
                print(f"    æœ€å¤§: {stats['max_response_time']:.3f}s")
                print(f"    ä¸­ä½æ•°: {stats['median_response_time']:.3f}s")
                print(f"    95åˆ†ä½: {stats['p95_response_time']:.3f}s")
                print(f"    99åˆ†ä½: {stats['p99_response_time']:.3f}s")
            
            # æ˜¾ç¤ºé”™è¯¯æ±‡æ€»
            errors = tester.get_error_summary()
            if errors:
                print(f"\n  é”™è¯¯æ±‡æ€»:")
                for error_msg, count in errors.items():
                    print(f"    {error_msg}: {count}æ¬¡")
        
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ‰§è¡Œå¤±è´¥: {str(e)}")
        
        print("\n" + "="*50)
    
    print("\nâœ… æ€§èƒ½æµ‹è¯•æ¼”ç¤ºå®Œæˆï¼")
    
    # æ€§èƒ½å»ºè®®
    print("\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
    print("  1. ç›‘æ§å“åº”æ—¶é—´ï¼Œä¿æŒåœ¨å¯æ¥å—èŒƒå›´å†…")
    print("  2. è®¾ç½®åˆç†çš„å¹¶å‘é™åˆ¶ï¼Œé¿å…æœåŠ¡è¿‡è½½")
    print("  3. å®æ–½ç†”æ–­å™¨æ¨¡å¼ï¼Œå¿«é€Ÿå¤±è´¥ä¿æŠ¤ç³»ç»Ÿ")
    print("  4. ä½¿ç”¨ç¼“å­˜å‡å°‘é‡å¤è®¡ç®—")
    print("  5. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢å’Œç½‘ç»œè°ƒç”¨")
    print("  6. å®šæœŸè¿›è¡Œæ€§èƒ½æµ‹è¯•ï¼ŒåŠæ—¶å‘ç°ç“¶é¢ˆ")

if __name__ == "__main__":
    run_performance_demo()