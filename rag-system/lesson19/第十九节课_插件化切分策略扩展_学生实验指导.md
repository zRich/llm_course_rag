# 第十九节课：插件化切分策略扩展 - 学生实验指导

## 实验目标

通过本次实验，你将：
1. 创建一个自定义的智能段落切分策略
2. 学会使用插件注册系统
3. 掌握策略性能监控方法
4. 理解插件化架构的实际应用

## 实验环境准备

### 1. 切换到lesson19分支
```bash
cd /path/to/rag-system
git checkout -b lesson19
```

### 2. 确认现有插件系统
检查以下文件是否存在：
- `src/chunking/strategy_interface.py`
- `src/chunking/plugin_registry.py`
- `src/chunking/semantic_chunker.py`
- `src/chunking/sentence_chunker.py`
- `src/chunking/structure_chunker.py`

## 实验步骤

### 步骤1: 创建智能段落切分策略（10分钟）

在 `src/chunking/` 目录下创建 `smart_paragraph_chunker.py` 文件：

```python
"""智能段落切分策略

结合段落结构和长度控制的智能切分策略，适用于技术文档。
"""

import re
from typing import List, Optional, Tuple
import logging

from .strategy_interface import ChunkingStrategy, StrategyMetrics
from .chunker import DocumentChunk, ChunkMetadata, ChunkingConfig

logger = logging.getLogger(__name__)

class SmartParagraphStrategy(ChunkingStrategy):
    """智能段落切分策略
    
    特点：
    1. 识别段落边界
    2. 智能合并短段落
    3. 分割过长段落
    4. 保持语义完整性
    """
    
    def __init__(self, config: Optional[ChunkingConfig] = None, **kwargs):
        super().__init__(config, **kwargs)
        
        # 策略特定参数
        self.min_paragraph_length = kwargs.get('min_paragraph_length', 50)
        self.max_paragraph_length = kwargs.get('max_paragraph_length', self.config.chunk_size)
        self.merge_threshold = kwargs.get('merge_threshold', 0.3)  # 合并阈值
        self.split_sentences = kwargs.get('split_sentences', True)  # 是否按句子分割长段落
        
        # 段落识别模式
        self.paragraph_patterns = [
            r'\n\s*\n',  # 双换行
            r'\n\s*[-*•]\s+',  # 列表项
            r'\n\s*\d+[.).]\s+',  # 数字列表
            r'\n\s*[a-zA-Z][.).]\s+',  # 字母列表
        ]
    
    def get_strategy_name(self) -> str:
        return "smart_paragraph"
    
    def get_strategy_description(self) -> str:
        return "智能段落切分策略，结合段落结构和长度控制，适用于技术文档"
    
    def chunk_text(self, text: str, source_file: str = "") -> List[DocumentChunk]:
        """执行智能段落切分
        
        Args:
            text: 要切分的文本
            source_file: 源文件路径
            
        Returns:
            List[DocumentChunk]: 切分后的文档块列表
        """
        try:
            # 步骤1: 识别段落
            paragraphs = self._identify_paragraphs(text)
            
            # 步骤2: 智能合并短段落
            merged_paragraphs = self._merge_short_paragraphs(paragraphs)
            
            # 步骤3: 分割过长段落
            final_paragraphs = self._split_long_paragraphs(merged_paragraphs)
            
            # 步骤4: 创建文档块
            chunks = self._create_chunks_from_paragraphs(final_paragraphs, source_file)
            
            self.logger.info(f"智能段落切分完成: {len(paragraphs)} -> {len(merged_paragraphs)} -> {len(final_paragraphs)} -> {len(chunks)} 块")
            return chunks
            
        except Exception as e:
            self.logger.error(f"智能段落切分失败: {e}")
            raise
    
    def _identify_paragraphs(self, text: str) -> List[Tuple[str, int, int]]:
        """识别段落边界
        
        Returns:
            List[Tuple[str, int, int]]: (段落内容, 开始位置, 结束位置)
        """
        paragraphs = []
        
        # 合并所有段落模式
        combined_pattern = '|'.join(f'({pattern})' for pattern in self.paragraph_patterns)
        
        # 分割文本
        parts = re.split(combined_pattern, text)
        
        current_pos = 0
        current_paragraph = ""
        
        for part in parts:
            if not part:
                continue
            
            # 检查是否是分隔符
            is_separator = any(re.match(pattern, part) for pattern in self.paragraph_patterns)
            
            if is_separator and current_paragraph.strip():
                # 结束当前段落
                start_pos = current_pos - len(current_paragraph)
                paragraphs.append((current_paragraph.strip(), start_pos, current_pos))
                current_paragraph = ""
            else:
                current_paragraph += part
            
            current_pos += len(part)
        
        # 添加最后一个段落
        if current_paragraph.strip():
            start_pos = current_pos - len(current_paragraph)
            paragraphs.append((current_paragraph.strip(), start_pos, current_pos))
        
        return paragraphs
    
    def _merge_short_paragraphs(self, paragraphs: List[Tuple[str, int, int]]) -> List[Tuple[str, int, int]]:
        """合并过短的段落"""
        if not paragraphs:
            return []
        
        merged = []
        current_group = [paragraphs[0]]
        current_length = len(paragraphs[0][0])
        
        for i in range(1, len(paragraphs)):
            para_content, para_start, para_end = paragraphs[i]
            para_length = len(para_content)
            
            # 判断是否需要合并
            should_merge = (
                current_length < self.min_paragraph_length or
                para_length < self.min_paragraph_length or
                (current_length + para_length) < self.max_paragraph_length * self.merge_threshold
            )
            
            if should_merge and (current_length + para_length) <= self.max_paragraph_length:
                # 合并到当前组
                current_group.append((para_content, para_start, para_end))
                current_length += para_length
            else:
                # 完成当前组，开始新组
                merged.append(self._merge_paragraph_group(current_group))
                current_group = [(para_content, para_start, para_end)]
                current_length = para_length
        
        # 添加最后一组
        if current_group:
            merged.append(self._merge_paragraph_group(current_group))
        
        return merged
    
    def _merge_paragraph_group(self, group: List[Tuple[str, int, int]]) -> Tuple[str, int, int]:
        """合并段落组"""
        if len(group) == 1:
            return group[0]
        
        contents = [para[0] for para in group]
        start_pos = group[0][1]
        end_pos = group[-1][2]
        
        # 使用双换行连接段落
        merged_content = '\n\n'.join(contents)
        
        return (merged_content, start_pos, end_pos)
    
    def _split_long_paragraphs(self, paragraphs: List[Tuple[str, int, int]]) -> List[Tuple[str, int, int]]:
        """分割过长的段落"""
        result = []
        
        for content, start_pos, end_pos in paragraphs:
            if len(content) <= self.max_paragraph_length:
                result.append((content, start_pos, end_pos))
            else:
                # 分割长段落
                split_parts = self._split_paragraph_by_sentences(content, start_pos)
                result.extend(split_parts)
        
        return result
    
    def _split_paragraph_by_sentences(self, content: str, start_pos: int) -> List[Tuple[str, int, int]]:
        """按句子分割长段落"""
        if not self.split_sentences:
            # 简单按长度分割
            return self._split_by_length(content, start_pos)
        
        # 按句子分割
        sentence_pattern = r'[.!?。！？]\s+'
        sentences = re.split(f'({sentence_pattern})', content)
        
        parts = []
        current_part = ""
        current_start = start_pos
        
        for i, sentence in enumerate(sentences):
            if not sentence:
                continue
            
            if len(current_part + sentence) <= self.max_paragraph_length:
                current_part += sentence
            else:
                if current_part.strip():
                    parts.append((current_part.strip(), current_start, current_start + len(current_part)))
                    current_start += len(current_part)
                current_part = sentence
        
        # 添加最后一部分
        if current_part.strip():
            parts.append((current_part.strip(), current_start, current_start + len(current_part)))
        
        return parts if parts else [(content, start_pos, start_pos + len(content))]
    
    def _split_by_length(self, content: str, start_pos: int) -> List[Tuple[str, int, int]]:
        """按长度简单分割"""
        parts = []
        current_pos = 0
        
        while current_pos < len(content):
            end_pos = min(current_pos + self.max_paragraph_length, len(content))
            part_content = content[current_pos:end_pos]
            
            parts.append((
                part_content,
                start_pos + current_pos,
                start_pos + end_pos
            ))
            
            current_pos = end_pos
        
        return parts
    
    def _create_chunks_from_paragraphs(self, paragraphs: List[Tuple[str, int, int]], 
                                     source_file: str) -> List[DocumentChunk]:
        """从段落创建文档块"""
        chunks = []
        
        for i, (content, start_pos, end_pos) in enumerate(paragraphs):
            metadata = ChunkMetadata(
                chunk_id=f"smart_para_{i}",
                source_file=source_file,
                chunk_index=i,
                start_position=start_pos,
                end_position=end_pos,
                chunk_type="smart_paragraph",
                language=self.config.language,
                metadata={
                    'paragraph_length': len(content),
                    'strategy': self.get_strategy_name()
                }
            )
            
            chunk = DocumentChunk(
                content=content,
                metadata=metadata
            )
            
            chunks.append(chunk)
        
        return chunks
```

### 步骤2: 注册策略（8分钟）

#### 2.1 更新 `__init__.py`

在 `src/chunking/__init__.py` 中添加新策略的导入和注册：

```python
# 在现有导入后添加
from .smart_paragraph_chunker import SmartParagraphStrategy
from .plugin_registry import StrategyRegistry

# 在 __all__ 列表中添加
__all__ = [
    # ... 现有导出
    'SmartParagraphStrategy',
]

# 自动注册策略
def _register_default_strategies():
    """注册默认策略"""
    registry = StrategyRegistry()
    
    # 注册现有策略
    registry.register_strategy(SemanticChunker, "semantic")
    registry.register_strategy(SentenceChunker, "sentence")
    registry.register_strategy(StructureChunker, "structure")
    
    # 注册新策略
    registry.register_strategy(SmartParagraphStrategy, "smart_paragraph", {
        'description': '智能段落切分策略',
        'suitable_for': ['技术文档', '长文本', '结构化内容'],
        'parameters': {
            'min_paragraph_length': '最小段落长度',
            'max_paragraph_length': '最大段落长度',
            'merge_threshold': '合并阈值',
            'split_sentences': '是否按句子分割'
        }
    })

# 模块加载时自动注册
_register_default_strategies()
```

#### 2.2 创建测试脚本

在 `lesson19/` 目录下创建 `test_smart_paragraph.py`：

```python
#!/usr/bin/env python3
"""测试智能段落切分策略"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.chunking import StrategyRegistry, ChunkingConfig

def test_smart_paragraph_strategy():
    """测试智能段落策略"""
    
    # 测试文本
    test_text = """
    # 人工智能简介
    
    人工智能（Artificial Intelligence，AI）是计算机科学的一个分支。它企图了解智能的实质，并生产出一种新的能以人类智能相似的方式做出反应的智能机器。
    
    ## 发展历史
    
    人工智能的发展可以追溯到1950年代。阿兰·图灵提出了著名的图灵测试。
    
    1956年，达特茅斯会议标志着人工智能学科的正式诞生。会议上，约翰·麦卡锡首次提出了"人工智能"这个术语。
    
    ## 主要技术
    
    • 机器学习：让计算机能够自动学习和改进
    • 深度学习：模拟人脑神经网络的学习方式
    • 自然语言处理：让计算机理解和生成人类语言
    • 计算机视觉：让计算机能够"看懂"图像和视频
    
    这些技术相互结合，推动了人工智能的快速发展。现在AI已经在各个领域得到广泛应用，包括医疗、金融、教育、交通等。
    
    ## 未来展望
    
    人工智能的未来充满无限可能。随着技术的不断进步，我们可以期待更加智能、更加人性化的AI系统出现。
    
    同时，我们也需要关注AI发展带来的伦理和社会问题，确保AI技术能够造福人类。
    """
    
    # 获取策略注册器
    registry = StrategyRegistry()
    
    # 列出所有可用策略
    print("可用策略:")
    for strategy_name in registry.list_strategies():
        info = registry.get_strategy_info(strategy_name)
        print(f"  - {strategy_name}: {info['description']}")
    
    print("\n" + "="*50)
    
    # 测试智能段落策略
    print("\n测试智能段落策略:")
    
    config = ChunkingConfig(
        chunk_size=300,
        overlap_size=50,
        language="zh"
    )
    
    # 获取策略实例
    strategy = registry.get_strategy(
        "smart_paragraph", 
        config=config,
        min_paragraph_length=80,
        max_paragraph_length=400,
        merge_threshold=0.4
    )
    
    # 执行切分并收集指标
    chunks, metrics = strategy.chunk_with_metrics(test_text, "test.md")
    
    print(f"\n切分结果:")
    print(f"  - 总块数: {len(chunks)}")
    print(f"  - 执行时间: {metrics.execution_time:.3f}秒")
    print(f"  - 平均块大小: {metrics.avg_chunk_size:.1f}字符")
    print(f"  - 块大小范围: {metrics.min_chunk_size} - {metrics.max_chunk_size}")
    print(f"  - 重叠率: {metrics.overlap_ratio:.2%}")
    print(f"  - 质量评分: {metrics.quality_score:.2f}")
    
    print("\n各块内容:")
    for i, chunk in enumerate(chunks):
        print(f"\n块 {i+1} (长度: {len(chunk.content)})")
        print("-" * 30)
        print(chunk.content[:200] + ("..." if len(chunk.content) > 200 else ""))
        print(f"元数据: {chunk.metadata.metadata}")

def compare_strategies():
    """对比不同策略的效果"""
    
    test_text = """
    深度学习是机器学习的一个子领域，它基于人工神经网络进行学习和决策。深度学习模型通常包含多个隐藏层，能够学习数据的复杂模式和特征。
    
    卷积神经网络（CNN）是深度学习中最重要的架构之一。CNN特别适合处理图像数据，通过卷积层、池化层和全连接层的组合，能够有效提取图像特征。
    
    循环神经网络（RNN）则擅长处理序列数据。LSTM和GRU是RNN的改进版本，解决了传统RNN的梯度消失问题，在自然语言处理任务中表现出色。
    
    Transformer架构的出现彻底改变了自然语言处理领域。注意力机制使得模型能够更好地理解长距离依赖关系，BERT、GPT等预训练模型都基于Transformer架构。
    """
    
    registry = StrategyRegistry()
    config = ChunkingConfig(chunk_size=200, overlap_size=30)
    
    strategies_to_test = ["sentence", "smart_paragraph", "structure"]
    
    print("策略对比测试:")
    print("="*60)
    
    for strategy_name in strategies_to_test:
        try:
            strategy = registry.get_strategy(strategy_name, config=config)
            chunks, metrics = strategy.chunk_with_metrics(test_text)
            
            print(f"\n{strategy_name.upper()} 策略:")
            print(f"  块数: {len(chunks)}")
            print(f"  执行时间: {metrics.execution_time:.3f}s")
            print(f"  平均块大小: {metrics.avg_chunk_size:.1f}")
            print(f"  质量评分: {metrics.quality_score:.2f}")
            
        except Exception as e:
            print(f"\n{strategy_name} 策略测试失败: {e}")

if __name__ == "__main__":
    print("智能段落切分策略测试")
    print("="*50)
    
    test_smart_paragraph_strategy()
    
    print("\n\n")
    compare_strategies()
```

### 步骤3: 运行测试（7分钟）

#### 3.1 执行测试
```bash
cd lesson19
python test_smart_paragraph.py
```

#### 3.2 预期输出
你应该看到类似以下的输出：

```
可用策略:
  - semantic: 基于语义相似性的智能切分
  - sentence: 基于句子边界的切分
  - structure: 基于文档结构的切分
  - smart_paragraph: 智能段落切分策略

测试智能段落策略:
切分结果:
  - 总块数: 4
  - 执行时间: 0.012秒
  - 平均块大小: 245.3字符
  - 块大小范围: 180 - 320
  - 重叠率: 0.00%
  - 质量评分: 0.85
```

#### 3.3 调试常见问题

**问题1**: 导入错误
- 检查文件路径是否正确
- 确认 `__init__.py` 中的导入语句

**问题2**: 策略注册失败
- 检查策略类是否正确继承 `ChunkingStrategy`
- 确认必需方法是否已实现

**问题3**: 切分结果不理想
- 调整策略参数（`min_paragraph_length`, `max_paragraph_length`等）
- 检查段落识别模式是否适合测试文本

## 实验总结

### 完成检查清单
- [ ] 成功创建 `SmartParagraphStrategy` 类
- [ ] 正确实现所有必需方法
- [ ] 成功注册策略到插件系统
- [ ] 测试脚本运行无错误
- [ ] 理解插件化架构的工作原理
- [ ] 能够对比不同策略的效果

### 关键学习点
1. **策略模式**: 如何使用抽象基类定义统一接口
2. **插件注册**: 如何动态注册和管理插件
3. **性能监控**: 如何收集和分析策略执行指标
4. **错误处理**: 如何实现健壮的异常处理机制

### 扩展练习
1. 为策略添加更多配置参数
2. 实现策略的配置文件支持
3. 添加更详细的性能监控指标
4. 创建策略效果的可视化展示

## 提交要求

请将以下文件提交到lesson19分支：
1. `src/chunking/smart_paragraph_chunker.py`
2. 更新后的 `src/chunking/__init__.py`
3. `lesson19/test_smart_paragraph.py`
4. 测试运行的截图或日志文件

提交命令：
```bash
git add .
git commit -m "lesson19: 实现智能段落切分策略插件"
git push origin lesson19
```