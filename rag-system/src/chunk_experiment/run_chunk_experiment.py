#!/usr/bin/env python3
"""Chunkå‚æ•°ä¼˜åŒ–å®éªŒä¸»è„šæœ¬"""

import argparse
import json
import time
from pathlib import Path
import sys
from typing import Dict, List, Optional

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from chunk_optimizer import ChunkOptimizer, ExperimentResult
from experiment_visualizer import ExperimentVisualizer
from mock_rag_system import MockRAGSystem, MockDocumentGenerator

class ChunkExperimentRunner:
    """Chunkå®éªŒè¿è¡Œå™¨"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.rag_system = None
        self.optimizer = None
        self.results = []
        
    def setup_system(self):
        """è®¾ç½®RAGç³»ç»Ÿå’Œæµ‹è¯•æ•°æ®"""
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # åˆ›å»ºRAGç³»ç»Ÿ
        self.rag_system = MockRAGSystem()
        
        # ç”Ÿæˆæµ‹è¯•æ–‡æ¡£
        print(f"ğŸ“š ç”Ÿæˆ {self.config['num_documents']} ä¸ªæµ‹è¯•æ–‡æ¡£...")
        documents = MockDocumentGenerator.generate_test_documents(
            self.config['num_documents'],
            self.config['document_length']
        )
        
        # æ·»åŠ æ–‡æ¡£åˆ°ç³»ç»Ÿ
        for doc_id, content in documents.items():
            self.rag_system.add_document(doc_id, content)
        
        # ç”Ÿæˆæµ‹è¯•æŸ¥è¯¢
        print(f"â“ ç”Ÿæˆ {self.config['num_queries']} ä¸ªæµ‹è¯•æŸ¥è¯¢...")
        test_queries = MockDocumentGenerator.generate_test_queries(
            documents, self.config['num_queries']
        )
        
        # åˆ›å»ºä¼˜åŒ–å™¨
        self.optimizer = ChunkOptimizer(
            rag_system=self.rag_system,
            test_documents=list(documents.keys()),
            evaluation_queries=test_queries
        )
        
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆï¼æ–‡æ¡£æ•°: {len(documents)}, æŸ¥è¯¢æ•°: {len(test_queries)}")
        
    def run_grid_search(self) -> List[ExperimentResult]:
        """è¿è¡Œç½‘æ ¼æœç´¢å®éªŒ"""
        chunk_sizes = self.config['chunk_sizes']
        overlap_ratios = self.config['overlap_ratios']
        
        total_experiments = len(chunk_sizes) * len(overlap_ratios)
        print(f"ğŸ”¬ å¼€å§‹ç½‘æ ¼æœç´¢å®éªŒï¼Œå…± {total_experiments} ä¸ªå®éªŒ...")
        
        results = []
        current_experiment = 0
        start_time = time.time()
        
        for chunk_size in chunk_sizes:
            for overlap_ratio in overlap_ratios:
                current_experiment += 1
                
                print(f"\n[{current_experiment}/{total_experiments}] "
                      f"Chunkå¤§å°: {chunk_size}, é‡å æ¯”ä¾‹: {overlap_ratio:.2f}")
                
                # è¿è¡Œå•ä¸ªå®éªŒ
                experiment_start = time.time()
                result = self.optimizer._run_single_experiment(chunk_size, overlap_ratio)
                experiment_time = time.time() - experiment_start
                
                results.append(result)
                
                # æ˜¾ç¤ºç»“æœ
                print(f"  âœ… å‡†ç¡®ç‡: {result.retrieval_accuracy:.3f}, "
                      f"å¬å›ç‡: {result.retrieval_recall:.3f}, "
                      f"å“åº”æ—¶é—´: {result.response_time:.2f}ms, "
                      f"å®éªŒè€—æ—¶: {experiment_time:.2f}s")
        
        total_time = time.time() - start_time
        print(f"\nğŸ‰ ç½‘æ ¼æœç´¢å®Œæˆï¼æ€»è€—æ—¶: {total_time:.2f}s")
        
        self.results = results
        return results
    
    def analyze_results(self) -> Dict:
        """åˆ†æå®éªŒç»“æœ"""
        if not self.results:
            raise ValueError("æ²¡æœ‰å®éªŒç»“æœå¯åˆ†æ")
        
        print("\nğŸ“Š æ­£åœ¨åˆ†æå®éªŒç»“æœ...")
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = ExperimentVisualizer(self.results)
        
        # ç”Ÿæˆåˆ†ææŠ¥å‘Š
        report = visualizer.generate_summary_report()
        
        # æ˜¾ç¤ºå…³é”®ç»“æœ
        print("\nğŸ† å…³é”®ç»“æœ:")
        
        best_configs = report['best_configurations']
        
        print(f"  æœ€é«˜å‡†ç¡®ç‡: {best_configs['highest_accuracy']['accuracy']:.3f} "
              f"(Chunk: {best_configs['highest_accuracy']['chunk_size']}, "
              f"é‡å : {best_configs['highest_accuracy']['overlap_ratio']:.2f})")
        
        print(f"  æœ€é«˜å¬å›ç‡: {best_configs['highest_recall']['recall']:.3f} "
              f"(Chunk: {best_configs['highest_recall']['chunk_size']}, "
              f"é‡å : {best_configs['highest_recall']['overlap_ratio']:.2f})")
        
        print(f"  æœ€é«˜F1åˆ†æ•°: {best_configs['highest_f1']['f1_score']:.3f} "
              f"(Chunk: {best_configs['highest_f1']['chunk_size']}, "
              f"é‡å : {best_configs['highest_f1']['overlap_ratio']:.2f})")
        
        print(f"  æœ€å¿«å“åº”: {best_configs['fastest_response']['response_time']:.2f}ms "
              f"(Chunk: {best_configs['fastest_response']['chunk_size']}, "
              f"é‡å : {best_configs['fastest_response']['overlap_ratio']:.2f})")
        
        return report
    
    def save_results(self, output_dir: Path):
        """ä¿å­˜å®éªŒç»“æœ"""
        if not self.results:
            print("âš ï¸ æ²¡æœ‰ç»“æœå¯ä¿å­˜")
            return
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜åŸå§‹ç»“æœ
        results_file = output_dir / f"experiment_results_{int(time.time())}.json"
        
        results_data = [
            {
                'chunk_size': r.chunk_size,
                'overlap_ratio': r.overlap_ratio,
                'retrieval_accuracy': r.retrieval_accuracy,
                'retrieval_recall': r.retrieval_recall,
                'response_time': r.response_time,
                'storage_overhead': r.storage_overhead,
                'chunk_count': r.chunk_count,
                'total_tokens': r.total_tokens
            }
            for r in self.results
        ]
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ å®éªŒç»“æœå·²ä¿å­˜åˆ°: {results_file}")
        
        # ç”Ÿæˆå¹¶ä¿å­˜åˆ†ææŠ¥å‘Š
        report = self.analyze_results()
        report_file = output_dir / f"analysis_report_{int(time.time())}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ“‹ åˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        if self.config.get('generate_plots', True):
            self.generate_visualizations(output_dir)
    
    def generate_visualizations(self, output_dir: Path):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
        print("\nğŸ“ˆ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        
        visualizer = ExperimentVisualizer(self.results)
        
        try:
            # ç”Ÿæˆçƒ­åŠ›å›¾
            heatmap_file = output_dir / "accuracy_heatmap.png"
            visualizer.create_heatmap('retrieval_accuracy', save_path=str(heatmap_file))
            print(f"  âœ… å‡†ç¡®ç‡çƒ­åŠ›å›¾: {heatmap_file}")
            
            # ç”Ÿæˆæ€§èƒ½æ›²çº¿
            curves_file = output_dir / "performance_curves.png"
            visualizer.create_performance_curves(save_path=str(curves_file))
            print(f"  âœ… æ€§èƒ½æ›²çº¿å›¾: {curves_file}")
            
            # ç”Ÿæˆ3Dè¡¨é¢å›¾
            surface_file = output_dir / "3d_surface.png"
            visualizer.create_3d_surface('retrieval_accuracy', save_path=str(surface_file))
            print(f"  âœ… 3Dè¡¨é¢å›¾: {surface_file}")
            
            # ç”Ÿæˆç›¸å…³æ€§çŸ©é˜µ
            corr_file = output_dir / "correlation_matrix.png"
            visualizer.create_correlation_matrix(save_path=str(corr_file))
            print(f"  âœ… ç›¸å…³æ€§çŸ©é˜µ: {corr_file}")
            
        except Exception as e:
            print(f"âš ï¸ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
    
    def run_experiment(self, output_dir: Optional[Path] = None):
        """è¿è¡Œå®Œæ•´å®éªŒæµç¨‹"""
        try:
            # è®¾ç½®ç³»ç»Ÿ
            self.setup_system()
            
            # è¿è¡Œç½‘æ ¼æœç´¢
            self.run_grid_search()
            
            # åˆ†æç»“æœ
            self.analyze_results()
            
            # ä¿å­˜ç»“æœ
            if output_dir:
                self.save_results(output_dir)
            
            print("\nğŸ‰ å®éªŒå®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ å®éªŒå¤±è´¥: {str(e)}")
            raise

def load_config(config_file: Optional[Path] = None) -> Dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    default_config = {
        'num_documents': 20,
        'document_length': 2000,
        'num_queries': 30,
        'chunk_sizes': [300, 500, 800, 1000, 1200],
        'overlap_ratios': [0.1, 0.15, 0.2, 0.25, 0.3],
        'generate_plots': True
    }
    
    if config_file and config_file.exists():
        with open(config_file, 'r', encoding='utf-8') as f:
            user_config = json.load(f)
        default_config.update(user_config)
    
    return default_config

def create_sample_config(config_file: Path):
    """åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶"""
    sample_config = {
        "num_documents": 20,
        "document_length": 2000,
        "num_queries": 30,
        "chunk_sizes": [300, 500, 800, 1000, 1200],
        "overlap_ratios": [0.1, 0.15, 0.2, 0.25, 0.3],
        "generate_plots": True,
        "description": "Chunkå‚æ•°ä¼˜åŒ–å®éªŒé…ç½®æ–‡ä»¶"
    }
    
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(sample_config, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ“ ç¤ºä¾‹é…ç½®æ–‡ä»¶å·²åˆ›å»º: {config_file}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='Chunkå‚æ•°ä¼˜åŒ–å®éªŒ')
    parser.add_argument('--config', type=Path, help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', type=Path, default=Path('./results'), help='è¾“å‡ºç›®å½•')
    parser.add_argument('--create-config', type=Path, help='åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶')
    parser.add_argument('--quick', action='store_true', help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¤ºä¾‹é…ç½®æ–‡ä»¶
    if args.create_config:
        create_sample_config(args.create_config)
        return
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # å¿«é€Ÿæµ‹è¯•æ¨¡å¼
    if args.quick:
        config.update({
            'num_documents': 5,
            'num_queries': 10,
            'chunk_sizes': [400, 800],
            'overlap_ratios': [0.1, 0.2],
            'generate_plots': False
        })
        print("ğŸš€ å¿«é€Ÿæµ‹è¯•æ¨¡å¼")
    
    # æ˜¾ç¤ºé…ç½®
    print("ğŸ“‹ å®éªŒé…ç½®:")
    for key, value in config.items():
        print(f"  {key}: {value}")
    
    # è¿è¡Œå®éªŒ
    runner = ChunkExperimentRunner(config)
    runner.run_experiment(args.output)

if __name__ == '__main__':
    main()