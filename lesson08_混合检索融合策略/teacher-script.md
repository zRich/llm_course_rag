# Lesson 08 教师讲稿：混合检索融合策略

## 开场（2 分钟）
- 今天目标：实现关键词检索（BM25/全文检索）与向量检索的融合，提升 Top-K 命中质量与稳定性。
- 产出：一套可运行的融合脚本与提交物（包含结果与说明）。

## 术语与背景（5 分钟）
- 关键词检索：基于倒排索引与文本匹配，优势是精确命中、可控性高。
- 向量检索：基于语义嵌入与相似度检索，优势是泛化语义、召回长尾。
- 融合动机：将两者优点叠加，兼顾精确度与语义泛化。

## 方法讲解（10 分钟）
- RRF（Reciprocal Rank Fusion）：`score = Σ 1/(k + rank_i)`，k 取值建议 60-120。
- 线性加权：对两路分数做 min-max 归一化后，`score = w_k * s_k + w_v * s_v`，权重建议 `w_k=0.5`、`w_v=0.5` 起步。
- 去重策略：优先使用 `id`；无唯一 id 时使用 `source+offset` 组合键。
- 排序稳定性：同分时按关键词 rank 优先，确保输出一致。

## 演示脚本（10 分钟）
- 打开 `examples/fusion_demo.py`，逐步演示：
  1) 加载两路检索结果（模拟数据）。
  2) 切换 `method='rrf'` 与 `method='weighted'`。
  3) 打印 Top-10 输出，并展示 `fused_score` 与来源。
- 强调：当一路为空时的兜底逻辑与警告记录。

## 互动提问（5 分钟）
- 为什么需要分数归一化？如果不归一化会发生什么？
- RRF 相比线性加权的优势与劣势是什么？
- 如何设计合理的去重键以避免误合并？

## 练习安排（8 分钟）
- 任务 1：调整权重 `w_k/w_v`，观察 Top-10 变化并记录原因。
- 任务 2：修改 k 值（如 30/90/150），对比 RRF 的稳定性与头部偏好。
- 任务 3：实现自定义去重键（如 `id` 缺失时基于 `source+start_offset`）。

## 总结与提交（5 分钟）
- 总结：融合提高了鲁棒性与整体召回/精确度的平衡。
- 提交物：按 `templates/lab_submission_template.md` 填写，附上运行截图或输出片段。

## 话术备忘
- 当学生问“为什么我融合后精度下降？”：检查归一化、权重设置、去重是否正确，以及是否出现同文档多片段冲突。
- 当学生问“性能变慢如何处理？”：建议预取 Top-K、做并发检索、引入缓存、限制融合集合大小与做渐进式展示。