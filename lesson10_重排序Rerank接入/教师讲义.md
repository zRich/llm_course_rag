# 第十节课：重排序(Rerank)接入 - 教师讲义

## 课程信息
- **课程时长**：45分钟
- **课程结构**：15分钟理论讲解 + 15分钟演示操作 + 15分钟学生实验
- **课程目标**：集成重排序模型提升检索精度
- **前置知识**：向量检索、关键词检索、混合检索融合策略

## 1. 课程概述（2分钟）

### 1.1 什么是重排序(Rerank)
重排序是在初步检索结果基础上，使用更精细的模型对候选文档进行重新排序的技术。它是RAG系统中提升检索精度的关键环节。

### 1.2 为什么需要重排序
- **检索精度提升**：初步检索可能存在语义理解偏差
- **上下文相关性**：重排序模型能更好理解查询与文档的相关性
- **计算效率平衡**：对少量候选结果进行精细排序，兼顾效果与性能

## 2. 理论讲解（13分钟）

### 2.1 重排序原理（4分钟）

#### 检索-重排序两阶段架构
```
用户查询 → 初步检索(召回) → 候选文档集 → 重排序模型 → 最终排序结果
```

#### 重排序模型特点
- **Cross-Encoder架构**：同时处理查询和文档，捕获交互信息
- **更深层语义理解**：相比向量检索的双塔模型，交互更充分
- **计算成本较高**：需要对每个查询-文档对单独计算

### 2.2 bge-reranker-v2-m3模型介绍（3分钟）

#### 模型特性
- **多语言支持**：中英文等多语言重排序
- **高精度**：在多个基准测试中表现优异
- **适中规模**：平衡效果与推理速度

#### 输入输出格式
```python
# 输入：查询-文档对列表
pairs = [("查询文本", "文档内容1"), ("查询文本", "文档内容2")]
# 输出：相关性得分列表
scores = [0.85, 0.23]  # 分数越高越相关
```

### 2.3 重排序策略设计（3分钟）

#### 前向重排序 vs 批量重排序
- **前向重排序**：逐个处理查询-文档对，适合实时场景
- **批量重排序**：批量处理多个对，提高GPU利用率

#### 重排序范围选择
- **Top-K选择**：通常对前10-50个结果重排序
- **阈值过滤**：只对初步得分超过阈值的结果重排序
- **分层重排序**：先粗排再精排

### 2.4 性能优化策略（3分钟）

#### 缓存策略
- **查询缓存**：相同查询直接返回缓存结果
- **文档缓存**：常用文档的embedding缓存
- **结果缓存**：重排序结果缓存

#### 性能平衡
- **异步处理**：重排序与其他操作并行
- **模型量化**：使用量化模型减少内存占用
- **批处理优化**：合理设置batch_size

## 3. 演示操作（15分钟）

### 3.1 环境准备（3分钟）

#### 安装依赖
```bash
# 安装sentence-transformers
uv pip install sentence-transformers torch

# 下载模型（首次使用会自动下载）
python -c "from sentence_transformers import CrossEncoder; CrossEncoder('BAAI/bge-reranker-v2-m3')"
```

### 3.2 基础重排序实现（5分钟）

#### 创建重排序服务类
```python
from sentence_transformers import CrossEncoder
import time
from typing import List, Tuple, Dict, Any
import logging

class RerankService:
    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3"):
        self.model = CrossEncoder(model_name)
        self.logger = logging.getLogger(__name__)
        
    def rerank_documents(
        self, 
        query: str, 
        documents: List[Dict[str, Any]], 
        top_k: int = 10
    ) -> List[Tuple[Dict[str, Any], float]]:
        """重排序文档列表"""
        if not documents:
            return []
            
        # 准备查询-文档对
        pairs = [(query, doc.get('content', '')) for doc in documents[:top_k]]
        
        # 计算重排序得分
        start_time = time.time()
        scores = self.model.predict(pairs)
        rerank_time = time.time() - start_time
        
        self.logger.info(f"重排序{len(pairs)}个文档，耗时{rerank_time:.3f}秒")
        
        # 组合结果并排序
        reranked_results = list(zip(documents[:top_k], scores))
        reranked_results.sort(key=lambda x: x[1], reverse=True)
        
        return reranked_results
```

### 3.3 集成到RAG系统（4分钟）

#### 修改查询接口
```python
# 在现有RAG查询中集成重排序
def enhanced_rag_query(query: str, use_rerank: bool = True):
    # 1. 初步检索（向量+关键词融合）
    initial_results = hybrid_search(query, top_k=20)
    
    # 2. 重排序（可选）
    if use_rerank and initial_results:
        rerank_service = RerankService()
        reranked_results = rerank_service.rerank_documents(
            query, initial_results, top_k=10
        )
        final_results = [doc for doc, score in reranked_results[:5]]
    else:
        final_results = initial_results[:5]
    
    # 3. 生成回答
    context = "\n\n".join([doc['content'] for doc in final_results])
    answer = generate_answer(query, context)
    
    return {
        "answer": answer,
        "sources": final_results,
        "rerank_used": use_rerank
    }
```

### 3.4 性能监控实现（3分钟）

#### 添加性能指标
```python
class RerankMetrics:
    def __init__(self):
        self.total_queries = 0
        self.total_rerank_time = 0
        self.cache_hits = 0
        
    def record_rerank(self, rerank_time: float, cache_hit: bool = False):
        self.total_queries += 1
        self.total_rerank_time += rerank_time
        if cache_hit:
            self.cache_hits += 1
            
    def get_stats(self) -> Dict[str, float]:
        if self.total_queries == 0:
            return {"avg_rerank_time": 0, "cache_hit_rate": 0}
            
        return {
            "avg_rerank_time": self.total_rerank_time / self.total_queries,
            "cache_hit_rate": self.cache_hits / self.total_queries,
            "total_queries": self.total_queries
        }
```

## 4. 关键技术点讲解（课程重点）

### 4.1 为什么Rerank能显著提升精度

#### 语义理解深度差异
- **双塔模型局限**：查询和文档分别编码，交互信息有限
- **Cross-Encoder优势**：查询和文档联合编码，捕获细粒度交互
- **上下文感知**：能理解查询意图与文档内容的匹配程度

#### 实际效果对比
```
初步检索：基于向量相似度，可能存在语义偏差
重排序后：基于深度语义理解，相关性判断更准确
典型提升：NDCG@10 提升10-20%，MRR提升15-25%
```

### 4.2 大规模检索结果的性能处理

#### 分层重排序策略
```python
# 三层重排序架构
def hierarchical_rerank(query: str, documents: List[Dict]):
    # 第一层：快速粗排（简单模型）
    coarse_ranked = coarse_rerank(query, documents[:100])
    
    # 第二层：精细重排（复杂模型）
    fine_ranked = fine_rerank(query, coarse_ranked[:20])
    
    # 第三层：最终排序（业务规则）
    final_ranked = apply_business_rules(fine_ranked)
    
    return final_ranked
```

#### 异步处理优化
```python
import asyncio

async def async_rerank_batch(query: str, doc_batches: List[List[Dict]]):
    tasks = []
    for batch in doc_batches:
        task = asyncio.create_task(rerank_single_batch(query, batch))
        tasks.append(task)
    
    results = await asyncio.gather(*tasks)
    return merge_batch_results(results)
```

## 5. 常见问题与解决方案

### 5.1 性能问题
- **问题**：重排序延迟过高
- **解决**：批处理、模型量化、缓存策略

### 5.2 内存占用
- **问题**：大模型内存消耗
- **解决**：模型共享、动态加载、分布式部署

### 5.3 效果评估
- **问题**：如何量化重排序效果
- **解决**：A/B测试、离线评估指标、用户反馈

## 6. 课程小结

### 核心要点
1. 重排序是RAG系统精度提升的关键技术
2. bge-reranker-v2-m3提供了优秀的中英文重排序能力
3. 性能优化需要在效果和速度间找到平衡
4. 分层架构和缓存策略是处理大规模数据的有效方法

### 下节预告
下节课将学习Chunk尺寸与重叠实验，探索文本分块策略对检索效果的影响。