# 第十节课：重排序(Rerank)接入 - 学生实验指导

## 实验概述
- **实验时长**：15分钟
- **实验目标**：实现重排序功能，提升RAG系统检索精度
- **技术栈**：sentence-transformers, bge-reranker-v2-m3
- **前置条件**：完成前面课程的向量检索和混合检索实验

## 实验环境准备

### 1. 安装依赖包
```bash
# 安装重排序相关依赖
uv pip install sentence-transformers torch transformers

# 验证安装
python -c "from sentence_transformers import CrossEncoder; print('安装成功')"
```

### 2. 模型下载（首次运行会自动下载）
```python
# 预下载模型（可选，首次使用时会自动下载）
from sentence_transformers import CrossEncoder

print("正在下载bge-reranker-v2-m3模型...")
model = CrossEncoder("BAAI/bge-reranker-v2-m3")
print("模型下载完成！")
```

## 实验任务

### 任务1：基础重排序实现（5分钟）

#### 1.1 创建重排序服务类
创建文件 `rerank_service.py`：

```python
from sentence_transformers import CrossEncoder
import time
from typing import List, Tuple, Dict, Any
import logging

# 配置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RerankService:
    """重排序服务类"""
    
    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3"):
        """初始化重排序模型"""
        print(f"正在加载重排序模型: {model_name}")
        self.model = CrossEncoder(model_name)
        self.model_name = model_name
        print("重排序模型加载完成")
        
    def rerank_documents(
        self, 
        query: str, 
        documents: List[Dict[str, Any]], 
        top_k: int = 10,
        score_threshold: float = 0.0
    ) -> List[Tuple[Dict[str, Any], float]]:
        """对文档进行重排序
        
        Args:
            query: 查询文本
            documents: 文档列表，每个文档需包含'content'字段
            top_k: 重排序的文档数量
            score_threshold: 最低分数阈值
            
        Returns:
            重排序后的(文档, 分数)元组列表
        """
        if not documents:
            return []
            
        # 限制重排序数量
        docs_to_rerank = documents[:top_k]
        
        # 准备查询-文档对
        pairs = []
        for doc in docs_to_rerank:
            content = doc.get('content', '')
            if content.strip():  # 确保内容不为空
                pairs.append((query, content))
            else:
                pairs.append((query, doc.get('title', '')))
        
        if not pairs:
            return []
            
        # 计算重排序得分
        start_time = time.time()
        scores = self.model.predict(pairs)
        rerank_time = time.time() - start_time
        
        logger.info(f"重排序{len(pairs)}个文档，耗时{rerank_time:.3f}秒")
        
        # 组合结果并排序
        reranked_results = []
        for i, (doc, score) in enumerate(zip(docs_to_rerank, scores)):
            if score >= score_threshold:
                reranked_results.append((doc, float(score)))
        
        # 按分数降序排序
        reranked_results.sort(key=lambda x: x[1], reverse=True)
        
        return reranked_results
    
    def batch_rerank(
        self, 
        queries: List[str], 
        documents_list: List[List[Dict[str, Any]]], 
        top_k: int = 10
    ) -> List[List[Tuple[Dict[str, Any], float]]]:
        """批量重排序"""
        results = []
        for query, documents in zip(queries, documents_list):
            reranked = self.rerank_documents(query, documents, top_k)
            results.append(reranked)
        return results
```

#### 1.2 测试基础重排序功能
创建测试文件 `test_basic_rerank.py`：

```python
from rerank_service import RerankService

# 模拟检索结果
sample_documents = [
    {
        "id": "doc1",
        "title": "人工智能基础",
        "content": "人工智能是计算机科学的一个分支，致力于创建能够执行通常需要人类智能的任务的系统。",
        "score": 0.8
    },
    {
        "id": "doc2", 
        "title": "机器学习算法",
        "content": "机器学习是人工智能的一个子领域，通过算法让计算机从数据中学习模式。",
        "score": 0.7
    },
    {
        "id": "doc3",
        "title": "深度学习网络", 
        "content": "深度学习使用多层神经网络来模拟人脑的工作方式，在图像识别等领域表现出色。",
        "score": 0.6
    },
    {
        "id": "doc4",
        "title": "自然语言处理",
        "content": "自然语言处理是人工智能的一个重要分支，专注于让计算机理解和生成人类语言。",
        "score": 0.5
    },
    {
        "id": "doc5",
        "title": "计算机视觉",
        "content": "计算机视觉让机器能够识别和理解图像内容，广泛应用于自动驾驶等领域。",
        "score": 0.4
    }
]

def test_basic_rerank():
    """测试基础重排序功能"""
    print("=== 基础重排序测试 ===")
    
    # 初始化重排序服务
    rerank_service = RerankService()
    
    # 测试查询
    query = "什么是人工智能？"
    print(f"查询: {query}")
    
    # 显示原始排序
    print("\n原始检索结果排序:")
    for i, doc in enumerate(sample_documents, 1):
        print(f"{i}. [{doc['id']}] {doc['title']} (原始分数: {doc['score']})")
    
    # 执行重排序
    reranked_results = rerank_service.rerank_documents(
        query, sample_documents, top_k=5
    )
    
    # 显示重排序结果
    print("\n重排序后结果:")
    for i, (doc, score) in enumerate(reranked_results, 1):
        print(f"{i}. [{doc['id']}] {doc['title']} (重排序分数: {score:.4f})")
    
    return reranked_results

if __name__ == "__main__":
    test_basic_rerank()
```

**运行测试**：
```bash
python test_basic_rerank.py
```

### 任务2：性能优化实现（4分钟）

#### 2.1 添加缓存机制
创建文件 `cached_rerank_service.py`：

```python
from rerank_service import RerankService
import hashlib
import json
from typing import Dict, Any, List, Tuple
import time

class CachedRerankService(RerankService):
    """带缓存的重排序服务"""
    
    def __init__(self, model_name: str = "BAAI/bge-reranker-v2-m3", cache_size: int = 1000):
        super().__init__(model_name)
        self.cache = {}  # 简单内存缓存
        self.cache_size = cache_size
        self.cache_hits = 0
        self.cache_misses = 0
        
    def _generate_cache_key(self, query: str, doc_ids: List[str]) -> str:
        """生成缓存键"""
        content = f"{query}:{':'.join(sorted(doc_ids))}"
        return hashlib.md5(content.encode()).hexdigest()
    
    def _clean_cache(self):
        """清理缓存（简单LRU）"""
        if len(self.cache) >= self.cache_size:
            # 删除最旧的一半缓存项
            items = list(self.cache.items())
            for key, _ in items[:len(items)//2]:
                del self.cache[key]
    
    def rerank_documents(
        self, 
        query: str, 
        documents: List[Dict[str, Any]], 
        top_k: int = 10,
        score_threshold: float = 0.0,
        use_cache: bool = True
    ) -> List[Tuple[Dict[str, Any], float]]:
        """带缓存的重排序"""
        if not documents or not use_cache:
            return super().rerank_documents(query, documents, top_k, score_threshold)
        
        # 生成缓存键
        doc_ids = [doc.get('id', str(i)) for i, doc in enumerate(documents[:top_k])]
        cache_key = self._generate_cache_key(query, doc_ids)
        
        # 检查缓存
        if cache_key in self.cache:
            self.cache_hits += 1
            print(f"缓存命中! 键: {cache_key[:8]}...")
            return self.cache[cache_key]
        
        # 缓存未命中，执行重排序
        self.cache_misses += 1
        result = super().rerank_documents(query, documents, top_k, score_threshold)
        
        # 存入缓存
        self._clean_cache()
        self.cache[cache_key] = result
        
        return result
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """获取缓存统计信息"""
        total_requests = self.cache_hits + self.cache_misses
        hit_rate = self.cache_hits / total_requests if total_requests > 0 else 0
        
        return {
            "cache_hits": self.cache_hits,
            "cache_misses": self.cache_misses,
            "hit_rate": hit_rate,
            "cache_size": len(self.cache)
        }
```

#### 2.2 测试缓存性能
创建测试文件 `test_cached_rerank.py`：

```python
from cached_rerank_service import CachedRerankService
from test_basic_rerank import sample_documents
import time

def test_cache_performance():
    """测试缓存性能"""
    print("=== 缓存性能测试 ===")
    
    # 初始化缓存重排序服务
    cached_service = CachedRerankService()
    
    queries = [
        "什么是人工智能？",
        "机器学习的基本原理",
        "深度学习的应用场景",
        "什么是人工智能？",  # 重复查询，应该命中缓存
        "自然语言处理技术"
    ]
    
    print("执行多次查询测试缓存效果...")
    
    for i, query in enumerate(queries, 1):
        print(f"\n查询 {i}: {query}")
        
        start_time = time.time()
        results = cached_service.rerank_documents(query, sample_documents, top_k=3)
        end_time = time.time()
        
        print(f"耗时: {end_time - start_time:.3f}秒")
        print(f"前3个结果: {[doc['title'] for doc, _ in results[:3]]}")
    
    # 显示缓存统计
    stats = cached_service.get_cache_stats()
    print(f"\n=== 缓存统计 ===")
    print(f"缓存命中: {stats['cache_hits']}")
    print(f"缓存未命中: {stats['cache_misses']}")
    print(f"命中率: {stats['hit_rate']:.2%}")
    print(f"缓存大小: {stats['cache_size']}")

if __name__ == "__main__":
    test_cache_performance()
```

### 任务3：集成到RAG系统（4分钟）

#### 3.1 创建增强的RAG查询接口
创建文件 `enhanced_rag_query.py`：

```python
from cached_rerank_service import CachedRerankService
from typing import Dict, List, Any, Optional
import json

class EnhancedRAGSystem:
    """集成重排序的增强RAG系统"""
    
    def __init__(self):
        self.rerank_service = CachedRerankService()
        
    def simulate_initial_search(self, query: str, top_k: int = 20) -> List[Dict[str, Any]]:
        """模拟初步检索（向量+关键词融合）"""
        # 这里使用示例数据模拟检索结果
        # 实际应用中应该调用真实的检索服务
        from test_basic_rerank import sample_documents
        
        # 模拟更多文档
        extended_docs = sample_documents * 4  # 扩展到20个文档
        for i, doc in enumerate(extended_docs):
            doc['id'] = f"{doc['id']}_copy_{i//5}"
            doc['score'] = doc['score'] * (0.9 ** (i//5))  # 逐渐降低分数
            
        return extended_docs[:top_k]
    
    def simulate_answer_generation(self, query: str, context: str) -> str:
        """模拟答案生成"""
        return f"基于提供的上下文，关于'{query}'的回答是：{context[:100]}..."
    
    def enhanced_query(
        self, 
        query: str, 
        use_rerank: bool = True,
        initial_top_k: int = 20,
        rerank_top_k: int = 10,
        final_top_k: int = 5
    ) -> Dict[str, Any]:
        """增强的RAG查询
        
        Args:
            query: 用户查询
            use_rerank: 是否使用重排序
            initial_top_k: 初步检索数量
            rerank_top_k: 重排序数量
            final_top_k: 最终使用的文档数量
            
        Returns:
            包含答案、来源和元信息的字典
        """
        # 1. 初步检索
        print(f"执行初步检索，获取前{initial_top_k}个结果...")
        initial_results = self.simulate_initial_search(query, initial_top_k)
        
        # 2. 重排序（可选）
        if use_rerank and initial_results:
            print(f"执行重排序，处理前{rerank_top_k}个结果...")
            reranked_results = self.rerank_service.rerank_documents(
                query, initial_results, top_k=rerank_top_k
            )
            final_results = [doc for doc, score in reranked_results[:final_top_k]]
            rerank_scores = [score for doc, score in reranked_results[:final_top_k]]
        else:
            print("跳过重排序，直接使用初步检索结果...")
            final_results = initial_results[:final_top_k]
            rerank_scores = [None] * len(final_results)
        
        # 3. 生成上下文
        context = "\n\n".join([
            f"文档{i+1}: {doc['content']}" 
            for i, doc in enumerate(final_results)
        ])
        
        # 4. 生成回答
        answer = self.simulate_answer_generation(query, context)
        
        # 5. 返回结果
        return {
            "query": query,
            "answer": answer,
            "sources": [
                {
                    "id": doc['id'],
                    "title": doc['title'],
                    "content": doc['content'][:200] + "...",
                    "original_score": doc.get('score'),
                    "rerank_score": rerank_scores[i] if rerank_scores[i] is not None else None
                }
                for i, doc in enumerate(final_results)
            ],
            "metadata": {
                "rerank_used": use_rerank,
                "initial_count": len(initial_results),
                "final_count": len(final_results),
                "cache_stats": self.rerank_service.get_cache_stats() if use_rerank else None
            }
        }
    
    def compare_with_without_rerank(self, query: str) -> Dict[str, Any]:
        """对比使用和不使用重排序的效果"""
        print("=== 对比测试：使用 vs 不使用重排序 ===")
        
        # 不使用重排序
        result_without = self.enhanced_query(query, use_rerank=False)
        
        # 使用重排序
        result_with = self.enhanced_query(query, use_rerank=True)
        
        return {
            "query": query,
            "without_rerank": result_without,
            "with_rerank": result_with
        }

def test_enhanced_rag():
    """测试增强的RAG系统"""
    rag_system = EnhancedRAGSystem()
    
    test_queries = [
        "什么是人工智能？",
        "机器学习和深度学习的区别是什么？",
        "自然语言处理有哪些应用？"
    ]
    
    for query in test_queries:
        print(f"\n{'='*50}")
        print(f"查询: {query}")
        print(f"{'='*50}")
        
        # 执行增强查询
        result = rag_system.enhanced_query(query)
        
        print(f"\n回答: {result['answer']}")
        print(f"\n使用的文档来源:")
        for i, source in enumerate(result['sources'], 1):
            rerank_info = f" (重排序分数: {source['rerank_score']:.4f})" if source['rerank_score'] else ""
            print(f"{i}. {source['title']}{rerank_info}")
        
        print(f"\n元信息: {json.dumps(result['metadata'], indent=2, ensure_ascii=False)}")

if __name__ == "__main__":
    test_enhanced_rag()
```

### 任务4：A/B测试框架（2分钟）

#### 4.1 创建简单的A/B测试框架
创建文件 `ab_test_rerank.py`：

```python
from enhanced_rag_query import EnhancedRAGSystem
import time
import statistics
from typing import List, Dict, Any

class RerankABTest:
    """重排序A/B测试框架"""
    
    def __init__(self):
        self.rag_system = EnhancedRAGSystem()
        
    def run_ab_test(
        self, 
        queries: List[str], 
        iterations: int = 3
    ) -> Dict[str, Any]:
        """运行A/B测试
        
        Args:
            queries: 测试查询列表
            iterations: 每个查询的重复次数
            
        Returns:
            测试结果统计
        """
        results = {
            "with_rerank": {"times": [], "results": []},
            "without_rerank": {"times": [], "results": []}
        }
        
        print(f"开始A/B测试，{len(queries)}个查询，每个重复{iterations}次")
        
        for query in queries:
            print(f"\n测试查询: {query}")
            
            # 测试不使用重排序
            for i in range(iterations):
                start_time = time.time()
                result = self.rag_system.enhanced_query(query, use_rerank=False)
                end_time = time.time()
                
                results["without_rerank"]["times"].append(end_time - start_time)
                results["without_rerank"]["results"].append(result)
            
            # 测试使用重排序
            for i in range(iterations):
                start_time = time.time()
                result = self.rag_system.enhanced_query(query, use_rerank=True)
                end_time = time.time()
                
                results["with_rerank"]["times"].append(end_time - start_time)
                results["with_rerank"]["results"].append(result)
        
        # 计算统计信息
        stats = self._calculate_stats(results)
        return stats
    
    def _calculate_stats(self, results: Dict[str, Any]) -> Dict[str, Any]:
        """计算测试统计信息"""
        stats = {}
        
        for method in ["with_rerank", "without_rerank"]:
            times = results[method]["times"]
            stats[method] = {
                "avg_time": statistics.mean(times),
                "median_time": statistics.median(times),
                "min_time": min(times),
                "max_time": max(times),
                "std_time": statistics.stdev(times) if len(times) > 1 else 0,
                "total_queries": len(times)
            }
        
        # 计算性能对比
        time_diff = stats["with_rerank"]["avg_time"] - stats["without_rerank"]["avg_time"]
        time_ratio = stats["with_rerank"]["avg_time"] / stats["without_rerank"]["avg_time"]
        
        stats["comparison"] = {
            "time_difference_seconds": time_diff,
            "time_ratio": time_ratio,
            "rerank_slower_by_percent": (time_ratio - 1) * 100
        }
        
        return stats
    
    def print_test_results(self, stats: Dict[str, Any]):
        """打印测试结果"""
        print("\n" + "="*60)
        print("A/B测试结果统计")
        print("="*60)
        
        for method in ["without_rerank", "with_rerank"]:
            method_name = "不使用重排序" if method == "without_rerank" else "使用重排序"
            print(f"\n{method_name}:")
            print(f"  平均耗时: {stats[method]['avg_time']:.3f}秒")
            print(f"  中位数耗时: {stats[method]['median_time']:.3f}秒")
            print(f"  最小耗时: {stats[method]['min_time']:.3f}秒")
            print(f"  最大耗时: {stats[method]['max_time']:.3f}秒")
            print(f"  标准差: {stats[method]['std_time']:.3f}秒")
            print(f"  总查询数: {stats[method]['total_queries']}")
        
        print(f"\n性能对比:")
        print(f"  重排序增加耗时: {stats['comparison']['time_difference_seconds']:.3f}秒")
        print(f"  重排序耗时倍数: {stats['comparison']['time_ratio']:.2f}x")
        print(f"  重排序增加百分比: {stats['comparison']['rerank_slower_by_percent']:.1f}%")

def run_ab_test():
    """运行A/B测试"""
    ab_test = RerankABTest()
    
    test_queries = [
        "什么是人工智能？",
        "机器学习的基本原理",
        "深度学习在计算机视觉中的应用"
    ]
    
    # 运行测试
    stats = ab_test.run_ab_test(test_queries, iterations=2)
    
    # 打印结果
    ab_test.print_test_results(stats)
    
    # 获取缓存统计
    cache_stats = ab_test.rag_system.rerank_service.get_cache_stats()
    print(f"\n缓存统计: {cache_stats}")

if __name__ == "__main__":
    run_ab_test()
```

## 实验验证

### 运行所有测试
```bash
# 1. 基础重排序测试
python test_basic_rerank.py

# 2. 缓存性能测试
python test_cached_rerank.py

# 3. 增强RAG系统测试
python enhanced_rag_query.py

# 4. A/B测试
python ab_test_rerank.py
```

### 预期结果
1. **基础重排序**：应该看到文档排序发生变化，更相关的文档排在前面
2. **缓存性能**：重复查询应该显示缓存命中，响应时间明显减少
3. **增强RAG**：集成重排序后的回答质量应该有所提升
4. **A/B测试**：可以量化重排序对性能和效果的影响

## 思考题

1. **重排序效果分析**：
   - 观察重排序前后文档排序的变化，分析哪些类型的查询重排序效果更明显？
   - 重排序分数与原始检索分数的相关性如何？

2. **性能优化思考**：
   - 缓存策略如何影响系统性能？在什么情况下缓存效果最好？
   - 如果要处理1000个文档的重排序，你会采用什么策略？

3. **实际应用考虑**：
   - 在生产环境中，如何平衡重排序效果和响应时间？
   - 如何设计更智能的重排序策略（如分层重排序）？

## 扩展实验（可选）

1. **模型对比实验**：
   - 尝试使用不同的重排序模型（如ms-marco-MiniLM-L-6-v2）
   - 对比不同模型的效果和性能

2. **分层重排序**：
   - 实现粗排+精排的两阶段重排序
   - 测试分层策略对大规模数据的处理效果

3. **动态阈值**：
   - 实现基于查询复杂度的动态重排序阈值
   - 简单查询跳过重排序，复杂查询使用重排序

## 实验总结

完成本实验后，你应该掌握：
1. 重排序模型的基本使用方法
2. 缓存策略对性能的影响
3. 重排序在RAG系统中的集成方式
4. A/B测试框架的设计和使用
5. 重排序效果的量化评估方法

重排序是提升RAG系统精度的重要技术，合理使用可以显著改善用户体验。