# 第16节课：增量更新 - 学生实验指导

## 实验目标
通过本实验，学生将：
1. 理解增量更新的核心概念和实现原理
2. 掌握文档变更检测算法的实现
3. 学会设计文档版本控制系统
4. 实现增量索引更新功能
5. 了解冲突解决策略的应用

## 实验环境准备

### 环境要求
- Python 3.8+
- 已完成前面课程的RAG系统基础代码
- 文本编辑器或IDE

### 依赖安装
```bash
pip install hashlib datetime json os typing dataclasses logging
```

## 实验步骤

### 步骤1：创建变更检测器（10分钟）

创建文件 `change_detector.py`：

```python
import hashlib
import os
import json
from datetime import datetime
from typing import Dict, List, Optional

class ChangeDetector:
    """文档变更检测器"""
    
    def __init__(self, metadata_file: str = "doc_metadata.json"):
        self.metadata_file = metadata_file
        self.metadata = self.load_metadata()
    
    def load_metadata(self) -> Dict:
        """加载文档元数据"""
        try:
            with open(self.metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}
    
    def save_metadata(self):
        """保存文档元数据"""
        with open(self.metadata_file, 'w', encoding='utf-8') as f:
            json.dump(self.metadata, f, indent=2, ensure_ascii=False)
    
    def calculate_file_hash(self, file_path: str) -> str:
        """计算文件的MD5哈希值"""
        hash_md5 = hashlib.md5()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_md5.update(chunk)
            return hash_md5.hexdigest()
        except FileNotFoundError:
            return ""
    
    def get_file_info(self, file_path: str) -> Dict:
        """获取文件基本信息"""
        if not os.path.exists(file_path):
            return {}
        
        stat = os.stat(file_path)
        return {
            'path': file_path,
            'size': stat.st_size,
            'mtime': stat.st_mtime,
            'hash': self.calculate_file_hash(file_path),
            'last_check': datetime.now().isoformat()
        }
    
    def detect_changes(self, file_paths: List[str]) -> Dict[str, List[str]]:
        """检测文件变更"""
        changes = {
            'added': [],      # 新增文件
            'modified': [],   # 修改文件
            'deleted': [],    # 删除文件
            'unchanged': []   # 未变更文件
        }
        
        current_files = set(file_paths)
        previous_files = set(self.metadata.keys())
        
        # 检测新增文件
        for file_path in current_files - previous_files:
            changes['added'].append(file_path)
            print(f"检测到新增文件: {file_path}")
        
        # 检测删除文件
        for file_path in previous_files - current_files:
            changes['deleted'].append(file_path)
            print(f"检测到删除文件: {file_path}")
        
        # 检测修改文件
        for file_path in current_files & previous_files:
            current_info = self.get_file_info(file_path)
            previous_info = self.metadata.get(file_path, {})
            
            if current_info.get('hash') != previous_info.get('hash'):
                changes['modified'].append(file_path)
                print(f"检测到修改文件: {file_path}")
            else:
                changes['unchanged'].append(file_path)
        
        return changes
    
    def update_metadata(self, file_paths: List[str]):
        """更新文件元数据"""
        for file_path in file_paths:
            if os.path.exists(file_path):
                self.metadata[file_path] = self.get_file_info(file_path)
        
        # 清理不存在的文件
        existing_files = set(file_paths)
        self.metadata = {k: v for k, v in self.metadata.items() 
                        if k in existing_files}
        
        self.save_metadata()
        print(f"元数据已更新，共{len(self.metadata)}个文件")
```

### 步骤2：实现版本管理器（10分钟）

创建文件 `version_manager.py`：

```python
from dataclasses import dataclass, asdict
from typing import Optional, Dict
import json
from datetime import datetime

@dataclass
class DocumentVersion:
    """文档版本信息"""
    doc_id: str
    version: int
    hash: str
    timestamp: str
    file_path: str
    size: int
    
    def to_dict(self) -> Dict:
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'DocumentVersion':
        return cls(**data)

class VersionManager:
    """文档版本管理器"""
    
    def __init__(self, version_file: str = "versions.json"):
        self.version_file = version_file
        self.versions = self.load_versions()
    
    def load_versions(self) -> Dict[str, DocumentVersion]:
        """加载版本信息"""
        try:
            with open(self.version_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            return {k: DocumentVersion.from_dict(v) for k, v in data.items()}
        except FileNotFoundError:
            return {}
    
    def save_versions(self):
        """保存版本信息"""
        data = {k: v.to_dict() for k, v in self.versions.items()}
        with open(self.version_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def get_version(self, doc_id: str) -> Optional[DocumentVersion]:
        """获取文档版本"""
        return self.versions.get(doc_id)
    
    def update_version(self, doc_id: str, file_path: str, 
                      file_hash: str, file_size: int) -> int:
        """更新文档版本"""
        current_version = self.versions.get(doc_id)
        new_version = 1 if current_version is None else current_version.version + 1
        
        self.versions[doc_id] = DocumentVersion(
            doc_id=doc_id,
            version=new_version,
            hash=file_hash,
            timestamp=datetime.now().isoformat(),
            file_path=file_path,
            size=file_size
        )
        self.save_versions()
        print(f"文档 {doc_id} 版本更新为 v{new_version}")
        return new_version
    
    def delete_version(self, doc_id: str) -> bool:
        """删除文档版本"""
        if doc_id in self.versions:
            del self.versions[doc_id]
            self.save_versions()
            print(f"文档 {doc_id} 版本信息已删除")
            return True
        return False
    
    def list_versions(self) -> Dict[str, DocumentVersion]:
        """列出所有版本"""
        return self.versions.copy()
```

### 步骤3：创建增量索引更新器（15分钟）

创建文件 `incremental_indexer.py`：

```python
import os
import logging
from typing import Dict, List
from change_detector import ChangeDetector
from version_manager import VersionManager

# 配置日志
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger('IncrementalIndexer')

class MockRAGSystem:
    """模拟RAG系统（用于演示）"""
    
    def __init__(self):
        self.documents = {}
    
    def add_document(self, doc_id: str, content: str):
        """添加文档"""
        self.documents[doc_id] = content
        logger.info(f"添加文档到RAG系统: {doc_id}")
    
    def update_document(self, doc_id: str, content: str):
        """更新文档"""
        self.documents[doc_id] = content
        logger.info(f"更新RAG系统中的文档: {doc_id}")
    
    def delete_document(self, doc_id: str):
        """删除文档"""
        if doc_id in self.documents:
            del self.documents[doc_id]
            logger.info(f"从RAG系统删除文档: {doc_id}")
    
    def get_document_count(self) -> int:
        """获取文档数量"""
        return len(self.documents)

class IncrementalIndexer:
    """增量索引更新器"""
    
    def __init__(self, rag_system=None):
        self.rag_system = rag_system or MockRAGSystem()
        self.change_detector = ChangeDetector()
        self.version_manager = VersionManager()
    
    def update_index(self, file_paths: List[str]) -> Dict[str, int]:
        """增量更新索引"""
        logger.info(f"开始增量更新，检查{len(file_paths)}个文件")
        
        # 检测变更
        changes = self.change_detector.detect_changes(file_paths)
        
        results = {
            'added': 0,
            'modified': 0,
            'deleted': 0,
            'unchanged': 0,
            'errors': 0
        }
        
        # 处理新增文档
        for file_path in changes['added']:
            try:
                self.add_document(file_path)
                results['added'] += 1
            except Exception as e:
                logger.error(f"添加文档失败 {file_path}: {e}")
                results['errors'] += 1
        
        # 处理修改文档
        for file_path in changes['modified']:
            try:
                self.update_document(file_path)
                results['modified'] += 1
            except Exception as e:
                logger.error(f"更新文档失败 {file_path}: {e}")
                results['errors'] += 1
        
        # 处理删除文档
        for file_path in changes['deleted']:
            try:
                self.delete_document(file_path)
                results['deleted'] += 1
            except Exception as e:
                logger.error(f"删除文档失败 {file_path}: {e}")
                results['errors'] += 1
        
        results['unchanged'] = len(changes['unchanged'])
        
        # 更新元数据
        self.change_detector.update_metadata(file_paths)
        
        # 记录结果
        self.log_update_results(results)
        
        return results
    
    def add_document(self, file_path: str):
        """添加新文档到索引"""
        doc_id = os.path.basename(file_path)
        
        # 读取文档内容
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 添加到RAG系统
        self.rag_system.add_document(doc_id, content)
        
        # 更新版本信息
        file_info = self.change_detector.get_file_info(file_path)
        self.version_manager.update_version(
            doc_id, file_path, file_info['hash'], file_info['size']
        )
    
    def update_document(self, file_path: str):
        """更新文档索引"""
        doc_id = os.path.basename(file_path)
        
        # 读取新内容
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # 更新RAG系统
        self.rag_system.update_document(doc_id, content)
        
        # 更新版本信息
        file_info = self.change_detector.get_file_info(file_path)
        self.version_manager.update_version(
            doc_id, file_path, file_info['hash'], file_info['size']
        )
    
    def delete_document(self, file_path: str):
        """从索引中删除文档"""
        doc_id = os.path.basename(file_path)
        
        # 从RAG系统删除
        self.rag_system.delete_document(doc_id)
        
        # 删除版本信息
        self.version_manager.delete_version(doc_id)
    
    def log_update_results(self, results: Dict[str, int]):
        """记录更新结果"""
        logger.info(f"增量更新完成: 新增{results['added']}个, "
                   f"修改{results['modified']}个, "
                   f"删除{results['deleted']}个, "
                   f"未变更{results['unchanged']}个, "
                   f"错误{results['errors']}个")
        
        total_docs = self.rag_system.get_document_count()
        logger.info(f"当前索引中共有{total_docs}个文档")
    
    def get_status(self) -> Dict:
        """获取系统状态"""
        return {
            'total_documents': self.rag_system.get_document_count(),
            'total_versions': len(self.version_manager.versions),
            'metadata_files': len(self.change_detector.metadata)
        }
```

### 步骤4：实现冲突解决器（5分钟）

创建文件 `conflict_resolver.py`：

```python
from version_manager import DocumentVersion
from typing import Literal

class ConflictResolver:
    """冲突解决器"""
    
    def __init__(self, strategy: Literal["timestamp", "version", "size", "local"] = "timestamp"):
        self.strategy = strategy
    
    def resolve_conflict(self, local_version: DocumentVersion, 
                        remote_version: DocumentVersion) -> Literal["local", "remote"]:
        """解决版本冲突"""
        if self.strategy == "timestamp":
            # 基于时间戳的策略：选择最新的版本
            if local_version.timestamp > remote_version.timestamp:
                return "local"
            else:
                return "remote"
        
        elif self.strategy == "version":
            # 基于版本号的策略：选择版本号更高的
            if local_version.version > remote_version.version:
                return "local"
            else:
                return "remote"
        
        elif self.strategy == "size":
            # 基于文件大小的策略：选择更大的文件
            if local_version.size > remote_version.size:
                return "local"
            else:
                return "remote"
        
        else:
            # 默认选择本地版本
            return "local"
    
    def get_conflict_info(self, local_version: DocumentVersion, 
                         remote_version: DocumentVersion) -> dict:
        """获取冲突信息"""
        return {
            'doc_id': local_version.doc_id,
            'local_version': local_version.version,
            'remote_version': remote_version.version,
            'local_timestamp': local_version.timestamp,
            'remote_timestamp': remote_version.timestamp,
            'resolution': self.resolve_conflict(local_version, remote_version),
            'strategy': self.strategy
        }
```

### 步骤5：创建测试脚本（5分钟）

创建文件 `test_incremental_update.py`：

```python
import os
import time
import tempfile
from incremental_indexer import IncrementalIndexer

def create_test_files():
    """创建测试文件"""
    test_dir = "test_docs"
    os.makedirs(test_dir, exist_ok=True)
    
    # 创建初始文件
    files = {
        "doc1.txt": "这是第一个文档的内容",
        "doc2.txt": "这是第二个文档的内容",
        "doc3.txt": "这是第三个文档的内容"
    }
    
    file_paths = []
    for filename, content in files.items():
        file_path = os.path.join(test_dir, filename)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        file_paths.append(file_path)
    
    return file_paths

def test_incremental_update():
    """测试增量更新功能"""
    print("=== 增量更新测试开始 ===")
    
    # 创建测试文件
    file_paths = create_test_files()
    
    # 创建增量索引器
    indexer = IncrementalIndexer()
    
    # 第一次更新（全部是新文件）
    print("\n1. 第一次更新（初始化）")
    results = indexer.update_index(file_paths)
    print(f"结果: {results}")
    
    # 等待一秒，然后修改一个文件
    time.sleep(1)
    print("\n2. 修改文件测试")
    with open(file_paths[0], 'w', encoding='utf-8') as f:
        f.write("这是修改后的第一个文档内容")
    
    results = indexer.update_index(file_paths)
    print(f"结果: {results}")
    
    # 添加新文件
    print("\n3. 添加新文件测试")
    new_file = os.path.join("test_docs", "doc4.txt")
    with open(new_file, 'w', encoding='utf-8') as f:
        f.write("这是新添加的第四个文档")
    file_paths.append(new_file)
    
    results = indexer.update_index(file_paths)
    print(f"结果: {results}")
    
    # 删除文件
    print("\n4. 删除文件测试")
    os.remove(file_paths[1])  # 删除doc2.txt
    file_paths.remove(file_paths[1])
    
    results = indexer.update_index(file_paths)
    print(f"结果: {results}")
    
    # 无变更测试
    print("\n5. 无变更测试")
    results = indexer.update_index(file_paths)
    print(f"结果: {results}")
    
    # 显示系统状态
    print("\n6. 系统状态")
    status = indexer.get_status()
    print(f"状态: {status}")
    
    # 显示版本信息
    print("\n7. 版本信息")
    versions = indexer.version_manager.list_versions()
    for doc_id, version in versions.items():
        print(f"{doc_id}: v{version.version} ({version.timestamp})")
    
    print("\n=== 增量更新测试完成 ===")

if __name__ == "__main__":
    test_incremental_update()
```

## 实验验证

### 运行测试
```bash
python test_incremental_update.py
```

### 预期输出
测试应该显示：
1. 初始化时所有文件被标记为"新增"
2. 修改文件后被正确检测为"修改"
3. 新增文件被正确检测
4. 删除文件被正确检测
5. 无变更时所有文件被标记为"未变更"
6. 版本信息正确更新

### 检查生成的文件
实验完成后，检查以下文件：
- `doc_metadata.json` - 文档元数据
- `versions.json` - 版本信息
- `test_docs/` - 测试文档目录

## 实验扩展（可选）

### 扩展1：性能测试
创建大量文件测试增量更新的性能：

```python
def performance_test():
    """性能测试"""
    import time
    
    # 创建1000个测试文件
    test_dir = "perf_test_docs"
    os.makedirs(test_dir, exist_ok=True)
    
    file_paths = []
    for i in range(1000):
        file_path = os.path.join(test_dir, f"doc_{i}.txt")
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(f"这是第{i}个文档的内容")
        file_paths.append(file_path)
    
    indexer = IncrementalIndexer()
    
    # 测试初始化时间
    start_time = time.time()
    results = indexer.update_index(file_paths)
    init_time = time.time() - start_time
    
    print(f"初始化1000个文档耗时: {init_time:.2f}秒")
    
    # 修改10个文件
    for i in range(10):
        with open(file_paths[i], 'w', encoding='utf-8') as f:
            f.write(f"修改后的第{i}个文档内容")
    
    # 测试增量更新时间
    start_time = time.time()
    results = indexer.update_index(file_paths)
    update_time = time.time() - start_time
    
    print(f"增量更新10个文档耗时: {update_time:.2f}秒")
    print(f"更新结果: {results}")
```

### 扩展2：监控文件系统变化
使用watchdog库实现实时文件监控：

```python
# 需要安装: pip install watchdog
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

class DocumentHandler(FileSystemEventHandler):
    def __init__(self, indexer):
        self.indexer = indexer
    
    def on_modified(self, event):
        if not event.is_directory:
            print(f"文件修改: {event.src_path}")
            # 触发增量更新
    
    def on_created(self, event):
        if not event.is_directory:
            print(f"文件创建: {event.src_path}")
    
    def on_deleted(self, event):
        if not event.is_directory:
            print(f"文件删除: {event.src_path}")
```

## 实验总结

通过本实验，你应该掌握了：
1. 如何实现文档变更检测
2. 如何设计版本控制系统
3. 如何实现增量索引更新
4. 如何处理文件操作中的各种情况

## 常见问题

**Q: 为什么使用MD5而不是SHA256？**
A: MD5计算速度更快，对于文档变更检测已经足够。如果需要更高安全性，可以使用SHA256。

**Q: 如何处理大文件的哈希计算？**
A: 可以分块计算哈希，或者只计算文件的部分内容（如前1KB）。

**Q: 如何在分布式环境中使用增量更新？**
A: 需要考虑分布式锁、一致性哈希等技术，确保多个节点间的数据一致性。

## 下节课预告
下节课将学习"结构化数据接入"，探讨如何将数据库、API等结构化数据源集成到RAG系统中。