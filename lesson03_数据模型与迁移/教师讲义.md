# Lesson 03 - 数据模型与迁移

## 课程概述

本课程将深入讲解企业级RAG系统的数据模型设计与数据库迁移实践。学生将学习如何使用SQLModel设计高效的数据模型，掌握PostgreSQL数据库的高级特性，并实现自动化的数据迁移系统。

## 教学目标

### 知识目标
- 理解企业级应用的数据模型设计原则
- 掌握SQLModel的核心概念和使用方法
- 学习PostgreSQL的高级特性和优化技巧
- 了解数据迁移的最佳实践和版本控制

### 技能目标
- 能够设计符合业务需求的数据模型
- 熟练使用SQLModel进行ORM操作
- 掌握数据库连接池的配置和管理
- 实现自动化的数据迁移系统

### 素养目标
- 培养系统性思维和架构设计能力
- 建立数据安全和性能优化意识
- 养成代码规范和文档编写习惯

## 核心内容

### 1. SQLModel基础与进阶

#### 1.1 SQLModel概述
- **定义**: SQLModel是FastAPI作者开发的现代Python SQL工具包
- **特点**: 类型安全、自动补全、运行时验证
- **优势**: 统一Pydantic和SQLAlchemy的优点

#### 1.2 核心概念
```python
# 基础模型定义
from sqlmodel import SQLModel, Field
from typing import Optional
from datetime import datetime
from uuid import UUID, uuid4

class UserBase(SQLModel):
    email: str = Field(unique=True, index=True)
    username: str = Field(unique=True, index=True)
    is_active: bool = Field(default=True)

class User(UserBase, table=True):
    id: Optional[UUID] = Field(default_factory=uuid4, primary_key=True)
    password_hash: str
    created_at: datetime = Field(default_factory=datetime.utcnow)
    updated_at: datetime = Field(default_factory=datetime.utcnow)

class UserCreate(UserBase):
    password: str

class UserRead(UserBase):
    id: UUID
    created_at: datetime
```

#### 1.3 关系映射
```python
# 一对多关系
class Document(SQLModel, table=True):
    id: Optional[UUID] = Field(default_factory=uuid4, primary_key=True)
    title: str
    user_id: UUID = Field(foreign_key="user.id")
    
    # 关系定义
    chunks: List["DocumentChunk"] = Relationship(back_populates="document")
    user: Optional[User] = Relationship(back_populates="documents")

class DocumentChunk(SQLModel, table=True):
    id: Optional[UUID] = Field(default_factory=uuid4, primary_key=True)
    document_id: UUID = Field(foreign_key="document.id")
    content: str
    
    # 反向关系
    document: Optional[Document] = Relationship(back_populates="chunks")
```

### 2. PostgreSQL高级特性

#### 2.1 数据类型选择
- **UUID**: 分布式系统的主键选择
- **JSONB**: 半结构化数据存储
- **全文搜索**: tsvector和GIN索引
- **数组类型**: 标签和分类存储

#### 2.2 索引策略
```sql
-- 复合索引
CREATE INDEX idx_documents_user_status ON documents(user_id, status);

-- 部分索引
CREATE INDEX idx_documents_active ON documents(created_at) 
WHERE status = 'active';

-- 全文搜索索引
CREATE INDEX idx_documents_content_gin 
ON documents USING gin(to_tsvector('english', content));
```

#### 2.3 约束和触发器
```sql
-- 检查约束
ALTER TABLE documents ADD CONSTRAINT check_file_size 
CHECK (file_size > 0 AND file_size < 100000000);

-- 更新时间触发器
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$$ language 'plpgsql';

CREATE TRIGGER update_documents_updated_at 
BEFORE UPDATE ON documents 
FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
```

### 3. 数据库连接管理

#### 3.1 连接池配置
```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    database_url,
    poolclass=QueuePool,
    pool_size=20,          # 连接池大小
    max_overflow=30,       # 最大溢出连接
    pool_pre_ping=True,    # 连接前检查
    pool_recycle=3600,     # 连接回收时间
    echo=False             # SQL日志
)
```

#### 3.2 会话管理
```python
from contextlib import contextmanager
from sqlmodel import Session

@contextmanager
def get_db_session():
    session = Session(engine)
    try:
        yield session
        session.commit()
    except Exception:
        session.rollback()
        raise
    finally:
        session.close()
```

### 4. 数据迁移系统

#### 4.1 Alembic集成
```python
# alembic/env.py
from sqlmodel import SQLModel
from myapp.models import *  # 导入所有模型

target_metadata = SQLModel.metadata

def run_migrations_online():
    connectable = engine_from_config(
        config.get_section(config.config_ini_section),
        prefix="sqlalchemy.",
        poolclass=pool.NullPool,
    )
    
    with connectable.connect() as connection:
        context.configure(
            connection=connection,
            target_metadata=target_metadata,
            compare_type=True,
            compare_server_default=True
        )
        
        with context.begin_transaction():
            context.run_migrations()
```

#### 4.2 迁移脚本管理
```bash
# 初始化Alembic
alembic init alembic

# 生成迁移脚本
alembic revision --autogenerate -m "Add user table"

# 应用迁移
alembic upgrade head

# 查看迁移历史
alembic history

# 回滚到指定版本
alembic downgrade -1

# 查看当前版本
alembic current
```

#### 4.3 版本控制最佳实践
- **命名规范**: 使用描述性的迁移消息
- **原子性**: 每个迁移应该是独立且可回滚的
- **测试**: 在开发环境充分测试迁移脚本
- **备份**: 生产环境迁移前必须备份数据

#### 4.4 实践案例
```python
# 复杂迁移示例：添加全文搜索
def upgrade():
    # 添加tsvector列
    op.add_column('documents', 
        sa.Column('search_vector', postgresql.TSVECTOR()))
    
    # 创建GIN索引
    op.create_index('idx_documents_search', 'documents', 
        ['search_vector'], postgresql_using='gin')
    
    # 更新现有数据
    op.execute("""
        UPDATE documents 
        SET search_vector = to_tsvector('english', title || ' ' || content)
    """)
    
    # 创建触发器
    op.execute("""
        CREATE TRIGGER documents_search_update 
        BEFORE INSERT OR UPDATE ON documents 
        FOR EACH ROW EXECUTE FUNCTION 
        tsvector_update_trigger(search_vector, 'pg_catalog.english', title, content);
    """)

def downgrade():
    op.execute("DROP TRIGGER IF EXISTS documents_search_update ON documents")
    op.drop_index('idx_documents_search')
    op.drop_column('documents', 'search_vector')
```

## 教学重点

### 1. 核心概念强调
- **类型安全**: SQLModel的核心优势
- **关系映射**: 正确理解ORM关系
- **索引策略**: 性能优化的关键
- **迁移管理**: 数据库版本控制

### 2. 实践技能培养
- **模型设计**: 从业务需求到数据模型
- **性能优化**: 查询优化和索引设计
- **错误处理**: 数据库异常处理
- **测试驱动**: 数据模型的单元测试

### 3. 工程实践
- **代码规范**: 模型定义的最佳实践
- **文档编写**: 数据模型文档化
- **团队协作**: 迁移脚本的协作管理

## 课堂活动

### 1. 模型设计Exercise（20分钟）
- 分组设计电商系统的数据模型
- 包含用户、商品、订单等核心实体
- 考虑性能和扩展性

### 2. 迁移脚本编写（15分钟）
- 为设计的模型编写迁移脚本
- 包含索引和约束的创建
- 考虑数据迁移的安全性

### 3. 性能优化讨论（10分钟）
- 分析常见的性能瓶颈
- 讨论索引策略的选择
- 分享优化经验

## 评估方式

### 1. 实践评估（70%）
- **模型设计**: 数据模型的合理性和完整性
- **代码质量**: 代码规范和最佳实践
- **功能实现**: 基本功能的正确实现
- **性能考虑**: 索引和查询优化

### 2. 理论评估（30%）
- **概念理解**: SQLModel和PostgreSQL概念
- **设计原则**: 数据模型设计原则
- **最佳实践**: 迁移和版本控制

### 3. 评分标准
- **优秀（90-100分）**: 完整实现所有功能，代码规范，有创新点
- **良好（80-89分）**: 实现主要功能，代码质量较好
- **及格（60-79分）**: 实现基本功能，存在一些问题
- **不及格（<60分）**: 功能不完整或存在严重问题

## 课后作业

### 1. 扩展Exercise
- 为RAG系统设计完整的数据模型
- 包含用户管理、文档管理、向量存储等模块
- 考虑多租户和权限控制

### 2. 性能优化
- 分析现有模型的性能瓶颈
- 设计合适的索引策略
- 编写性能测试脚本

### 3. 迁移实践
- 设计一个复杂的数据库迁移场景
- 编写完整的迁移脚本
- 包含数据迁移和回滚策略

## 下节课预告

下节课我们将学习**PDF解析与Chunk拆分**，内容包括：
- PDF文档解析技术
- 文本分块策略
- 元数据提取
- 内容预处理

请同学们提前准备一些PDF文档用于Exercise，并思考如何将长文档拆分为适合向量化的片段。