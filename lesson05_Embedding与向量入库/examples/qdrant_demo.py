#!/usr/bin/env python3
"""
Lesson 05: Embeddingä¸å‘é‡å…¥åº“ - Qdrantæ•°æ®åº“æ“ä½œæ¼”ç¤º

æœ¬æ–‡ä»¶æ¼”ç¤ºQdrantå‘é‡æ•°æ®åº“çš„åŸºæœ¬æ“ä½œï¼ŒåŒ…æ‹¬ï¼š
1. æ•°æ®åº“è¿æ¥å’Œé›†åˆç®¡ç†
2. å‘é‡æ•°æ®çš„å¢åˆ æ”¹æŸ¥
3. å‘é‡ç›¸ä¼¼åº¦æœç´¢
4. æ‰¹é‡æ•°æ®æ“ä½œ
5. è¿‡æ»¤æŸ¥è¯¢å’Œå…ƒæ•°æ®ç®¡ç†

ä½œè€…: RAGè¯¾ç¨‹å›¢é˜Ÿ
æ—¥æœŸ: 2024-01-01
ç”¨é€”: Lesson 05è¯¾å ‚æ¼”ç¤º
"""

import time
import uuid
from typing import List, Dict, Any, Optional, Tuple
from qdrant_client import QdrantClient
from qdrant_client.models import (
    Distance, VectorParams, PointStruct, Filter, 
    FieldCondition, MatchValue, SearchRequest
)
from sentence_transformers import SentenceTransformer
import numpy as np


class QdrantDemo:
    """Qdrantå‘é‡æ•°æ®åº“æ“ä½œæ¼”ç¤ºç±»"""
    
    def __init__(self, host: str = "localhost", port: int = 6333):
        """
        åˆå§‹åŒ–Qdrantæ¼”ç¤ºå™¨
        
        Args:
            host: QdrantæœåŠ¡å™¨åœ°å€
            port: QdrantæœåŠ¡å™¨ç«¯å£
        """
        self.host = host
        self.port = port
        self.client = None
        self.model = None
        self.collection_name = "lesson05_demo"
        
        self.connect_to_qdrant()
        self.load_embedding_model()
    
    def connect_to_qdrant(self) -> None:
        """è¿æ¥åˆ°Qdrantæ•°æ®åº“"""
        print(f"ğŸ”— è¿æ¥Qdrantæ•°æ®åº“: {self.host}:{self.port}")
        
        try:
            self.client = QdrantClient(host=self.host, port=self.port)
            
            # æµ‹è¯•è¿æ¥
            collections = self.client.get_collections()
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
            print(f"   - æœåŠ¡å™¨åœ°å€: {self.host}:{self.port}")
            print(f"   - ç°æœ‰é›†åˆæ•°é‡: {len(collections.collections)}")
            
            if collections.collections:
                print("   - ç°æœ‰é›†åˆ:")
                for collection in collections.collections:
                    print(f"     â€¢ {collection.name}")
                    
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿QdrantæœåŠ¡æ­£åœ¨è¿è¡Œ")
            raise
    
    def load_embedding_model(self) -> None:
        """åŠ è½½å‘é‡åŒ–æ¨¡å‹"""
        print(f"\nğŸ§  åŠ è½½å‘é‡åŒ–æ¨¡å‹...")
        try:
            self.model = SentenceTransformer('BAAI/bge-m3')
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def create_collection_demo(self) -> None:
        """åˆ›å»ºé›†åˆæ¼”ç¤º"""
        print(f"\nğŸ“ åˆ›å»ºé›†åˆæ¼”ç¤º")
        print(f"é›†åˆåç§°: {self.collection_name}")
        
        try:
            # æ£€æŸ¥é›†åˆæ˜¯å¦å·²å­˜åœ¨
            existing_collections = self.client.get_collections()
            collection_names = [col.name for col in existing_collections.collections]
            
            if self.collection_name in collection_names:
                print(f"âš ï¸  é›†åˆ '{self.collection_name}' å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤...")
                self.client.delete_collection(self.collection_name)
            
            # åˆ›å»ºæ–°é›†åˆ
            self.client.create_collection(
                collection_name=self.collection_name,
                vectors_config=VectorParams(
                    size=768,  # bge-m3æ¨¡å‹çš„å‘é‡ç»´åº¦
                    distance=Distance.COSINE  # ä½¿ç”¨ä½™å¼¦è·ç¦»
                )
            )
            
            print(f"âœ… é›†åˆåˆ›å»ºæˆåŠŸï¼")
            print(f"   - é›†åˆåç§°: {self.collection_name}")
            print(f"   - å‘é‡ç»´åº¦: 768")
            print(f"   - è·ç¦»åº¦é‡: ä½™å¼¦è·ç¦»")
            
            # è·å–é›†åˆä¿¡æ¯
            collection_info = self.client.get_collection(self.collection_name)
            print(f"   - é›†åˆçŠ¶æ€: {collection_info.status}")
            print(f"   - å‘é‡æ•°é‡: {collection_info.points_count}")
            
        except Exception as e:
            print(f"âŒ é›†åˆåˆ›å»ºå¤±è´¥: {e}")
            raise
    
    def insert_vectors_demo(self, texts: List[str]) -> List[str]:
        """æ’å…¥å‘é‡æ¼”ç¤º"""
        print(f"\nğŸ“¥ å‘é‡æ’å…¥æ¼”ç¤º")
        print(f"æ’å…¥æ–‡æœ¬æ•°é‡: {len(texts)}")
        
        # æ˜¾ç¤ºéƒ¨åˆ†æ–‡æœ¬
        print("æ’å…¥æ–‡æœ¬ç¤ºä¾‹:")
        for i, text in enumerate(texts[:3]):
            print(f"  {i+1}. '{text}'")
        if len(texts) > 3:
            print(f"  ... è¿˜æœ‰{len(texts)-3}ä¸ªæ–‡æœ¬")
        
        try:
            # å‘é‡åŒ–æ–‡æœ¬
            print("ğŸ”„ æ­£åœ¨è¿›è¡Œå‘é‡åŒ–...")
            embeddings = self.model.encode(texts)
            
            # æ„é€ Points
            points = []
            point_ids = []
            
            for i, (text, embedding) in enumerate(zip(texts, embeddings)):
                point_id = str(uuid.uuid4())
                point_ids.append(point_id)
                
                point = PointStruct(
                    id=point_id,
                    vector=embedding.tolist(),
                    payload={
                        "text": text,
                        "index": i,
                        "category": "demo_data",
                        "timestamp": time.time(),
                        "length": len(text),
                        "language": "zh" if any('\u4e00' <= char <= '\u9fff' for char in text) else "en"
                    }
                )
                points.append(point)
            
            # æ‰¹é‡æ’å…¥
            print("ğŸ”„ æ­£åœ¨æ’å…¥å‘é‡æ•°æ®åº“...")
            start_time = time.time()
            result = self.client.upsert(
                collection_name=self.collection_name,
                points=points
            )
            insert_time = time.time() - start_time
            
            print(f"âœ… å‘é‡æ’å…¥æˆåŠŸï¼")
            print(f"   - æ’å…¥æ•°é‡: {len(points)}")
            print(f"   - æ“ä½œçŠ¶æ€: {result.status}")
            print(f"   - æ’å…¥è€—æ—¶: {insert_time:.2f}ç§’")
            print(f"   - å¹³å‡é€Ÿåº¦: {len(points)/insert_time:.1f}å‘é‡/ç§’")
            
            # éªŒè¯æ’å…¥ç»“æœ
            collection_info = self.client.get_collection(self.collection_name)
            print(f"   - é›†åˆä¸­æ€»å‘é‡æ•°: {collection_info.points_count}")
            
            return point_ids
            
        except Exception as e:
            print(f"âŒ å‘é‡æ’å…¥å¤±è´¥: {e}")
            raise
    
    def search_vectors_demo(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """å‘é‡æœç´¢æ¼”ç¤º"""
        print(f"\nğŸ” å‘é‡æœç´¢æ¼”ç¤º")
        print(f"æŸ¥è¯¢æ–‡æœ¬: '{query}'")
        print(f"è¿”å›ç»“æœæ•°: {limit}")
        
        try:
            # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
            print("ğŸ”„ æ­£åœ¨å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬...")
            query_embedding = self.model.encode([query])[0]
            
            # æ‰§è¡Œå‘é‡æœç´¢
            print("ğŸ”„ æ­£åœ¨æ‰§è¡Œå‘é‡æœç´¢...")
            start_time = time.time()
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding.tolist(),
                limit=limit,
                with_payload=True,
                with_vectors=False  # ä¸è¿”å›å‘é‡æ•°æ®ä»¥èŠ‚çœå¸¦å®½
            )
            search_time = time.time() - start_time
            
            print(f"âœ… æœç´¢å®Œæˆï¼è€—æ—¶: {search_time*1000:.2f}æ¯«ç§’")
            print(f"\nğŸ¯ æœç´¢ç»“æœ:")
            
            results = []
            for i, result in enumerate(search_results, 1):
                result_data = {
                    'rank': i,
                    'id': result.id,
                    'score': result.score,
                    'text': result.payload.get('text', ''),
                    'category': result.payload.get('category', ''),
                    'language': result.payload.get('language', ''),
                    'length': result.payload.get('length', 0)
                }
                results.append(result_data)
                
                print(f"  æ’å {i}:")
                print(f"    ç›¸ä¼¼åº¦: {result.score:.4f}")
                print(f"    æ–‡æœ¬: '{result.payload['text']}'")
                print(f"    è¯­è¨€: {result.payload.get('language', 'unknown')}")
                print(f"    é•¿åº¦: {result.payload.get('length', 0)}å­—ç¬¦")
                print()
            
            return results
            
        except Exception as e:
            print(f"âŒ å‘é‡æœç´¢å¤±è´¥: {e}")
            raise
    
    def filter_search_demo(self, query: str, category_filter: str = None, language_filter: str = None) -> List[Dict[str, Any]]:
        """è¿‡æ»¤æœç´¢æ¼”ç¤º"""
        print(f"\nğŸ¯ è¿‡æ»¤æœç´¢æ¼”ç¤º")
        print(f"æŸ¥è¯¢æ–‡æœ¬: '{query}'")
        if category_filter:
            print(f"ç±»åˆ«è¿‡æ»¤: {category_filter}")
        if language_filter:
            print(f"è¯­è¨€è¿‡æ»¤: {language_filter}")
        
        try:
            # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
            query_embedding = self.model.encode([query])[0]
            
            # æ„å»ºè¿‡æ»¤æ¡ä»¶
            filter_conditions = []
            if category_filter:
                filter_conditions.append(
                    FieldCondition(key="category", match=MatchValue(value=category_filter))
                )
            if language_filter:
                filter_conditions.append(
                    FieldCondition(key="language", match=MatchValue(value=language_filter))
                )
            
            search_filter = Filter(must=filter_conditions) if filter_conditions else None
            
            # æ‰§è¡Œè¿‡æ»¤æœç´¢
            search_results = self.client.search(
                collection_name=self.collection_name,
                query_vector=query_embedding.tolist(),
                query_filter=search_filter,
                limit=5,
                with_payload=True
            )
            
            print(f"âœ… è¿‡æ»¤æœç´¢å®Œæˆï¼æ‰¾åˆ° {len(search_results)} ä¸ªç»“æœ")
            
            results = []
            for i, result in enumerate(search_results, 1):
                result_data = {
                    'rank': i,
                    'score': result.score,
                    'text': result.payload['text'],
                    'category': result.payload.get('category', ''),
                    'language': result.payload.get('language', '')
                }
                results.append(result_data)
                
                print(f"  æ’å {i}: (ç›¸ä¼¼åº¦: {result.score:.4f})")
                print(f"    æ–‡æœ¬: '{result.payload['text']}'")
                print(f"    ç±»åˆ«: {result.payload.get('category', 'unknown')}")
                print(f"    è¯­è¨€: {result.payload.get('language', 'unknown')}")
                print()
            
            return results
            
        except Exception as e:
            print(f"âŒ è¿‡æ»¤æœç´¢å¤±è´¥: {e}")
            raise
    
    def update_vectors_demo(self, point_ids: List[str]) -> None:
        """æ›´æ–°å‘é‡æ¼”ç¤º"""
        print(f"\nğŸ”„ å‘é‡æ›´æ–°æ¼”ç¤º")
        
        if not point_ids:
            print("âš ï¸  æ²¡æœ‰å¯æ›´æ–°çš„å‘é‡ç‚¹")
            return
        
        try:
            # é€‰æ‹©ç¬¬ä¸€ä¸ªç‚¹è¿›è¡Œæ›´æ–°æ¼”ç¤º
            update_id = point_ids[0]
            print(f"æ›´æ–°å‘é‡ID: {update_id}")
            
            # è·å–åŸå§‹æ•°æ®
            original_point = self.client.retrieve(
                collection_name=self.collection_name,
                ids=[update_id],
                with_payload=True
            )[0]
            
            print(f"åŸå§‹æ–‡æœ¬: '{original_point.payload['text']}'")
            
            # æ›´æ–°æ–‡æœ¬å’Œå‘é‡
            new_text = original_point.payload['text'] + " [å·²æ›´æ–°]"
            new_embedding = self.model.encode([new_text])[0]
            
            # æ‰§è¡Œæ›´æ–°
            updated_point = PointStruct(
                id=update_id,
                vector=new_embedding.tolist(),
                payload={
                    **original_point.payload,
                    "text": new_text,
                    "updated": True,
                    "update_timestamp": time.time()
                }
            )
            
            result = self.client.upsert(
                collection_name=self.collection_name,
                points=[updated_point]
            )
            
            print(f"âœ… å‘é‡æ›´æ–°æˆåŠŸï¼")
            print(f"   - æ›´æ–°çŠ¶æ€: {result.status}")
            print(f"   - æ–°æ–‡æœ¬: '{new_text}'")
            
            # éªŒè¯æ›´æ–°ç»“æœ
            updated_point_check = self.client.retrieve(
                collection_name=self.collection_name,
                ids=[update_id],
                with_payload=True
            )[0]
            
            print(f"   - éªŒè¯æ–‡æœ¬: '{updated_point_check.payload['text']}'")
            print(f"   - æ›´æ–°æ ‡è®°: {updated_point_check.payload.get('updated', False)}")
            
        except Exception as e:
            print(f"âŒ å‘é‡æ›´æ–°å¤±è´¥: {e}")
            raise
    
    def delete_vectors_demo(self, point_ids: List[str], delete_count: int = 1) -> None:
        """åˆ é™¤å‘é‡æ¼”ç¤º"""
        print(f"\nğŸ—‘ï¸  å‘é‡åˆ é™¤æ¼”ç¤º")
        
        if len(point_ids) < delete_count:
            print(f"âš ï¸  å¯åˆ é™¤å‘é‡æ•°é‡ä¸è¶³ï¼Œéœ€è¦{delete_count}ä¸ªï¼Œå®é™…{len(point_ids)}ä¸ª")
            return
        
        try:
            # é€‰æ‹©è¦åˆ é™¤çš„å‘é‡
            delete_ids = point_ids[-delete_count:]
            print(f"åˆ é™¤å‘é‡æ•°é‡: {delete_count}")
            print(f"åˆ é™¤å‘é‡IDs: {delete_ids}")
            
            # è·å–åˆ é™¤å‰çš„é›†åˆä¿¡æ¯
            collection_info_before = self.client.get_collection(self.collection_name)
            points_before = collection_info_before.points_count
            
            # æ‰§è¡Œåˆ é™¤
            result = self.client.delete(
                collection_name=self.collection_name,
                points_selector=delete_ids
            )
            
            print(f"âœ… å‘é‡åˆ é™¤æˆåŠŸï¼")
            print(f"   - åˆ é™¤çŠ¶æ€: {result.status}")
            
            # éªŒè¯åˆ é™¤ç»“æœ
            collection_info_after = self.client.get_collection(self.collection_name)
            points_after = collection_info_after.points_count
            
            print(f"   - åˆ é™¤å‰å‘é‡æ•°: {points_before}")
            print(f"   - åˆ é™¤åå‘é‡æ•°: {points_after}")
            print(f"   - å®é™…åˆ é™¤æ•°: {points_before - points_after}")
            
        except Exception as e:
            print(f"âŒ å‘é‡åˆ é™¤å¤±è´¥: {e}")
            raise
    
    def collection_stats_demo(self) -> Dict[str, Any]:
        """é›†åˆç»Ÿè®¡ä¿¡æ¯æ¼”ç¤º"""
        print(f"\nğŸ“Š é›†åˆç»Ÿè®¡ä¿¡æ¯")
        
        try:
            # è·å–é›†åˆä¿¡æ¯
            collection_info = self.client.get_collection(self.collection_name)
            
            stats = {
                'name': self.collection_name,
                'status': collection_info.status,
                'points_count': collection_info.points_count,
                'vector_size': collection_info.config.params.vectors.size,
                'distance': collection_info.config.params.vectors.distance
            }
            
            print(f"é›†åˆåç§°: {stats['name']}")
            print(f"é›†åˆçŠ¶æ€: {stats['status']}")
            print(f"å‘é‡æ•°é‡: {stats['points_count']}")
            print(f"å‘é‡ç»´åº¦: {stats['vector_size']}")
            print(f"è·ç¦»åº¦é‡: {stats['distance']}")
            
            # å¦‚æœæœ‰å‘é‡ï¼Œè·å–ä¸€äº›æ ·æœ¬ç»Ÿè®¡
            if stats['points_count'] > 0:
                # éšæœºè·å–ä¸€äº›ç‚¹è¿›è¡Œåˆ†æ
                sample_points = self.client.scroll(
                    collection_name=self.collection_name,
                    limit=min(10, stats['points_count']),
                    with_payload=True
                )[0]
                
                if sample_points:
                    categories = [point.payload.get('category', 'unknown') for point in sample_points]
                    languages = [point.payload.get('language', 'unknown') for point in sample_points]
                    text_lengths = [point.payload.get('length', 0) for point in sample_points]
                    
                    print(f"\næ ·æœ¬åˆ†æ (åŸºäº{len(sample_points)}ä¸ªæ ·æœ¬):")
                    print(f"  ç±»åˆ«åˆ†å¸ƒ: {dict(zip(*np.unique(categories, return_counts=True)))}")
                    print(f"  è¯­è¨€åˆ†å¸ƒ: {dict(zip(*np.unique(languages, return_counts=True)))}")
                    print(f"  æ–‡æœ¬é•¿åº¦: å¹³å‡{np.mean(text_lengths):.1f}å­—ç¬¦, èŒƒå›´[{min(text_lengths)}-{max(text_lengths)}]")
            
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            raise
    
    def cleanup_demo(self) -> None:
        """æ¸…ç†æ¼”ç¤ºæ•°æ®"""
        print(f"\nğŸ§¹ æ¸…ç†æ¼”ç¤ºæ•°æ®")
        
        try:
            # åˆ é™¤æ¼”ç¤ºé›†åˆ
            self.client.delete_collection(self.collection_name)
            print(f"âœ… æ¼”ç¤ºé›†åˆ '{self.collection_name}' å·²åˆ é™¤")
            
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†å¤±è´¥: {e}")


def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("=" * 60)
    print("ğŸš€ Lesson 05: Qdrantå‘é‡æ•°æ®åº“æ“ä½œæ¼”ç¤º")
    print("=" * 60)
    
    # åˆå§‹åŒ–æ¼”ç¤ºå™¨
    demo = QdrantDemo()
    
    # 1. åˆ›å»ºé›†åˆ
    demo.create_collection_demo()
    
    # 2. å‡†å¤‡æ¼”ç¤ºæ•°æ®
    demo_texts = [
        "äººå·¥æ™ºèƒ½æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè‡´åŠ›äºåˆ›å»ºæ™ºèƒ½æœºå™¨",
        "æœºå™¨å­¦ä¹ æ˜¯å®ç°äººå·¥æ™ºèƒ½çš„é‡è¦æ–¹æ³•ï¼Œè®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ ",
        "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ ",
        "è‡ªç„¶è¯­è¨€å¤„ç†è®©è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€",
        "è®¡ç®—æœºè§†è§‰ä½¿æœºå™¨èƒ½å¤Ÿè¯†åˆ«å’Œç†è§£å›¾åƒå†…å®¹",
        "å¼ºåŒ–å­¦ä¹ é€šè¿‡å¥–åŠ±æœºåˆ¶è®­ç»ƒæ™ºèƒ½ä½“åšå‡ºæœ€ä¼˜å†³ç­–",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥å’Œè¿åŠ¨",
        "Machine learning is a subset of artificial intelligence",
        "Deep learning uses neural networks with multiple layers",
        "Natural language processing helps computers understand text"
    ]
    
    # 3. æ’å…¥å‘é‡æ•°æ®
    point_ids = demo.insert_vectors_demo(demo_texts)
    
    # 4. å‘é‡æœç´¢æ¼”ç¤º
    search_queries = [
        "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
        "äººå·¥æ™ºèƒ½çš„åº”ç”¨",
        "å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ"
    ]
    
    for query in search_queries:
        demo.search_vectors_demo(query, limit=3)
    
    # 5. è¿‡æ»¤æœç´¢æ¼”ç¤º
    demo.filter_search_demo("artificial intelligence", language_filter="en")
    demo.filter_search_demo("äººå·¥æ™ºèƒ½", language_filter="zh")
    
    # 6. æ›´æ–°å‘é‡æ¼”ç¤º
    demo.update_vectors_demo(point_ids)
    
    # 7. é›†åˆç»Ÿè®¡ä¿¡æ¯
    stats = demo.collection_stats_demo()
    
    # 8. åˆ é™¤å‘é‡æ¼”ç¤º
    demo.delete_vectors_demo(point_ids, delete_count=2)
    
    # 9. æœ€ç»ˆç»Ÿè®¡
    final_stats = demo.collection_stats_demo()
    
    print("\n" + "=" * 60)
    print("âœ… Qdrantæ¼”ç¤ºå®Œæˆï¼")
    print("=" * 60)
    
    # å…³é”®è¦ç‚¹æ€»ç»“
    print("\nğŸ¯ å…³é”®è¦ç‚¹æ€»ç»“:")
    print("1. Qdrantæ”¯æŒé«˜æ•ˆçš„å‘é‡å­˜å‚¨å’Œæ£€ç´¢")
    print("2. æ”¯æŒä¸°å¯Œçš„å…ƒæ•°æ®å’Œè¿‡æ»¤æŸ¥è¯¢")
    print("3. æä¾›å®Œæ•´çš„CRUDæ“ä½œæ¥å£")
    print("4. ä½™å¼¦è·ç¦»é€‚åˆæ–‡æœ¬è¯­ä¹‰ç›¸ä¼¼åº¦è®¡ç®—")
    print("5. æ‰¹é‡æ“ä½œå¯ä»¥æé«˜æ•°æ®å¤„ç†æ•ˆç‡")
    print("6. åˆç†çš„ç´¢å¼•é…ç½®å¯ä»¥ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½")
    
    # è¯¢é—®æ˜¯å¦æ¸…ç†æ•°æ®
    cleanup = input("\næ˜¯å¦æ¸…ç†æ¼”ç¤ºæ•°æ®ï¼Ÿ(y/N): ").lower().strip()
    if cleanup == 'y':
        demo.cleanup_demo()
    else:
        print(f"æ¼”ç¤ºæ•°æ®ä¿ç•™åœ¨é›†åˆ '{demo.collection_name}' ä¸­")


if __name__ == "__main__":
    main()